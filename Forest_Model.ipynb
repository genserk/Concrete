{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3409613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f551659",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_csv('data/concrete.csv')\n",
    "co2 = pd.read_csv('data/co2.csv')\n",
    "\n",
    "concrete['co2_lower'] = sum([concrete[col] * co2.loc[co2.ingredient == col, 'lower_bound'].values[0] for col in concrete.columns[:7]])\n",
    "concrete['co2_upper'] = sum([concrete[col] * co2.loc[co2.ingredient == col, 'upper_bound'].values[0] for col in concrete.columns[:7]])\n",
    "\n",
    "concrete = concrete[concrete['age'] < 120]\n",
    "\n",
    "concrete_as = concrete[(concrete['ash'] > 0) & (concrete['slag'] > 0)]\n",
    "concrete_a = concrete[(concrete['ash'] > 0) & (concrete['slag'] == 0)]\n",
    "concrete_s = concrete[(concrete['ash'] == 0) & (concrete['slag'] > 0)]\n",
    "concrete_ = concrete[(concrete['ash'] == 0) & (concrete['slag'] == 0)]\n",
    "\n",
    "concrete_train, concrete_test = train_test_split(concrete,\n",
    "                                                 shuffle=True,\n",
    "                                                 random_state=487)\n",
    "\n",
    "features = concrete.columns[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91713513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was modified from stackexchange user hughdbrown \n",
    "# at this link, \n",
    "# https://stackoverflow.com/questions/1482308/how-to-get-all-subsets-of-a-set-powerset\n",
    "\n",
    "# This returns the power set of a set minus the empty set\n",
    "def powerset(s):\n",
    "    power_set = []\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        power_set.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "        \n",
    "    return power_set[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc399992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b1c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_grid(max_depths,features,n_trees,concrete_train):\n",
    "\n",
    "    grid_cv = GridSearchCV(RandomForestRegressor(), # first put the model object here\n",
    "                              param_grid = {'max_depth':max_depths, # place the grid values for max_depth and\n",
    "                                            'n_estimators':n_trees}, # and n_estimators here\n",
    "                              scoring = 'neg_mean_squared_error', # put the metric we are trying to optimize here as a string, \"accuracy\"\n",
    "                              cv = 5) # put the number of cv splits here\n",
    "\n",
    "    ## you fit it just like a model\n",
    "    grid_cv.fit(concrete_train[features], concrete_train['strength'])\n",
    "\n",
    "    return grid_cv.best_params_, -grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70dbfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 12, 'n_estimators': 100}\n",
      "29.249699627404482\n",
      "0.01 ({'max_depth': 12, 'n_estimators': 100}, 29.249699627404482)\n",
      "{'max_depth': 12, 'n_estimators': 100}\n",
      "29.522849057716957\n",
      "0.02 ({'max_depth': 12, 'n_estimators': 100}, 29.522849057716957)\n",
      "{'max_depth': 50, 'n_estimators': 500}\n",
      "29.56590868283339\n",
      "0.03 ({'max_depth': 50, 'n_estimators': 500}, 29.56590868283339)\n",
      "{'max_depth': 13, 'n_estimators': 100}\n",
      "29.482969961263166\n",
      "0.04 ({'max_depth': 13, 'n_estimators': 100}, 29.482969961263166)\n",
      "{'max_depth': 50, 'n_estimators': 500}\n",
      "29.664542906290357\n",
      "0.05 ({'max_depth': 50, 'n_estimators': 500}, 29.664542906290357)\n",
      "{'max_depth': 12, 'n_estimators': 500}\n",
      "29.661545634949835\n",
      "0.060000000000000005 ({'max_depth': 12, 'n_estimators': 500}, 29.661545634949835)\n",
      "{'max_depth': 13, 'n_estimators': 500}\n",
      "29.498994101089256\n",
      "0.06999999999999999 ({'max_depth': 13, 'n_estimators': 500}, 29.498994101089256)\n",
      "{'max_depth': 50, 'n_estimators': 100}\n",
      "29.259107475953282\n",
      "0.08 ({'max_depth': 50, 'n_estimators': 100}, 29.259107475953282)\n",
      "{'max_depth': 50, 'n_estimators': 500}\n",
      "29.354903555363222\n",
      "0.09 ({'max_depth': 50, 'n_estimators': 500}, 29.354903555363222)\n"
     ]
    }
   ],
   "source": [
    "features_all = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']\n",
    "\n",
    "max_depths = [11,12,13,14,15,16,17,18]\n",
    "features = ['cement', 'slag', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']\n",
    "features2 = ['cement', 'slag', 'water', 'superplastic', 'coarseagg', 'fineagg', 'age']\n",
    "n_trees = [100,200,300,400,500]\n",
    "\n",
    "print(forest_grid(max_depths,features2,n_trees,concrete_train))\n",
    "for factor in np.arange(.01, .1, .01):\n",
    "    concrete_train['exp_age'] = np.exp(-factor * concrete_train['age'])\n",
    "    print(factor, forest_grid(max_depths,features,n_trees,concrete_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab56586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'max_depth': 14, 'n_estimators': 500}, 29.277755654021405)\n",
      "0.01 ({'max_depth': 15, 'n_estimators': 200}, 29.16496070087594)\n",
      "0.02 ({'max_depth': 17, 'n_estimators': 500}, 29.321819353959334)\n",
      "0.03 ({'max_depth': 17, 'n_estimators': 300}, 29.113327280204864)\n",
      "0.04 ({'max_depth': 13, 'n_estimators': 100}, 29.22803766138504)\n",
      "0.05 ({'max_depth': 13, 'n_estimators': 100}, 29.118157773206832)\n",
      "0.060000000000000005 ({'max_depth': 15, 'n_estimators': 200}, 29.406813645286398)\n",
      "0.06999999999999999 ({'max_depth': 15, 'n_estimators': 300}, 29.08688417599177)\n",
      "0.08 ({'max_depth': 13, 'n_estimators': 500}, 29.177607244480686)\n",
      "0.09 ({'max_depth': 17, 'n_estimators': 500}, 29.080181351407163)\n"
     ]
    }
   ],
   "source": [
    "features_all = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']\n",
    "\n",
    "max_depths = [12,13,14,15,16,17]\n",
    "features = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']\n",
    "features2 = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg', 'fineagg', 'age']\n",
    "n_trees = [100,200,300,400,500]\n",
    "\n",
    "print(forest_grid(max_depths,features2,n_trees,concrete_train))\n",
    "for factor in np.arange(.01, .1, .01):\n",
    "    concrete_train['exp_age'] = np.exp(-factor * concrete_train['age'])\n",
    "    print(factor, forest_grid(max_depths,features,n_trees,concrete_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8ccdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
