{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing and model selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ensemble models\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# neural networks\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras import models, layers, optimizers, losses, metrics, Sequential\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will compare the following models:\n",
    "1. `LinearRegression` as our base model\n",
    "2. `RandomForestRegressor`\n",
    "3. `XGBRegressor`\n",
    "4. `HistGradientBoostingRegressor`\n",
    "5. `MLPRegressor`\n",
    "6. `Keras`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_csv('data/concrete.csv')\n",
    "co2 = pd.read_csv('data/co2.csv')\n",
    "\n",
    "concrete['exp_age'] = np.exp(-.038 * concrete['age'])\n",
    "\n",
    "concrete['co2_lower'] = sum([concrete[col] * co2.loc[co2.ingredient == col, 'lower_bound'].values[0] for col in concrete.columns[:7]])\n",
    "concrete['co2_upper'] = sum([concrete[col] * co2.loc[co2.ingredient == col, 'upper_bound'].values[0] for col in concrete.columns[:7]])\n",
    "\n",
    "concrete = concrete[concrete['age'] < 120]\n",
    "\n",
    "concrete_train, concrete_test = train_test_split(concrete,\n",
    "                                                 shuffle=True,\n",
    "                                                 random_state=487)\n",
    "\n",
    "features = ['cement', 'ash', 'slag', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was modified from stackexchange user hughdbrown \n",
    "# at this link, \n",
    "# https://stackoverflow.com/questions/1482308/how-to-get-all-subsets-of-a-set-powerset\n",
    "\n",
    "# This returns the power set of a set minus the empty set\n",
    "def powerset(s):\n",
    "    power_set = []\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        power_set.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "        \n",
    "    return power_set[1:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for future use, this function gets mean squared error without constantly copy-pasting\n",
    "\n",
    "def get_slr_mses(data, features_list, y, n_splits=5, rs=97):\n",
    "    # data is the dataframe\n",
    "    # features_list is a list of all lists of features we wish to compare\n",
    "    # eg [[], ['feature1'], ['feature1', 'feature2, 'feature5']]\n",
    "    # if one list is [], then we make a baseline prediction\n",
    "    # y is the y feature we are predicting\n",
    "    # k is the number of cross-validation splits\n",
    "    # rs is the random_state for kfold\n",
    "    kfold = KFold(n_splits,\n",
    "              shuffle=True,\n",
    "              random_state=rs)\n",
    "    mses=np.zeros((n_splits, len(features_list)))\n",
    "\n",
    "    i = 0\n",
    "    # cross-validation\n",
    "    for train_index, test_index in kfold.split(data):\n",
    "        data_tt = data.iloc[train_index]\n",
    "        data_ho = data.iloc[test_index]\n",
    "\n",
    "        j = 0\n",
    "        for features in features_list:\n",
    "            if features == []:\n",
    "                # baseline prediction\n",
    "                pred = data_tt[y].values.mean() * np.ones(len(data_ho))\n",
    "            else:\n",
    "                reg = LinearRegression(copy_X=True)\n",
    "                reg.fit(data_tt[features], data_tt[y])\n",
    "                pred = reg.predict(data_ho[features])\n",
    "            \n",
    "            mses[i, j] = mean_squared_error(y_true=data_ho[y],\n",
    "                                            y_pred=pred)\n",
    "            j += 1\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return np.mean(mses, axis=0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt to improve the linear model a little by picking the exponential factor with all features in consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg',\n",
    "       'fineagg', 'exp_age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 57.70330104192804\n",
      "0.02 51.14081744397187\n",
      "0.03 47.781495017706575\n",
      "0.04 47.158922486225194\n",
      "0.05 48.18470524244171\n",
      "0.060000000000000005 50.0325012084111\n",
      "0.06999999999999999 52.172666716534025\n",
      "0.08 54.32070776381877\n",
      "0.09 56.351408732591054\n"
     ]
    }
   ],
   "source": [
    "features2 = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg',\n",
    "       'fineagg', 'exp_age']\n",
    "\n",
    "for factor in np.arange(.01, .1, .01):\n",
    "    concrete_train['exp_age'] = np.exp(-factor * concrete_train['age'])\n",
    "    print(factor, np.min(get_slr_mses(concrete_train, powerset(features2), 'strength')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038000000000000006 47.11634037831618\n"
     ]
    }
   ],
   "source": [
    "best_mses = []\n",
    "\n",
    "for factor in np.arange(.03, .05, .001):\n",
    "    concrete_train['exp_age'] = np.exp(-factor * concrete_train['age'])\n",
    "    best_mses.append(np.min(get_slr_mses(concrete_train, powerset(features2), 'strength')))\n",
    "\n",
    "\n",
    "print(np.arange(.03, .05, .001)[np.argmin(best_mses)], np.min(best_mses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 45, 'max_features': None, 'n_estimators': 200, 'n_jobs': 1}\n",
      "29.750892287963836\n"
     ]
    }
   ],
   "source": [
    "max_depths = [45]\n",
    "features = ['cement', 'slag', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']\n",
    "n_trees = [100, 200, 300]\n",
    "n_jobs = [1]\n",
    "max_features = [None]\n",
    "\n",
    "\n",
    "grid_cv = GridSearchCV(RandomForestRegressor(), \n",
    "                          param_grid = {'max_depth':max_depths, \n",
    "                                        'n_estimators':n_trees,\n",
    "                                        'n_jobs': n_jobs,\n",
    "                                        'max_features': max_features}, \n",
    "                          scoring = 'neg_mean_squared_error', \n",
    "                          cv = 5) \n",
    "\n",
    "## you fit it just like a model\n",
    "grid_cv.fit(concrete_train[features], concrete_train['strength'])\n",
    "\n",
    "print(grid_cv.best_params_)\n",
    "print(-grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 46, 'n_estimators': 100}\n",
      "29.206099330106305\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.arange(40, 51, 1)\n",
    "features = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg', 'fineagg', 'age', 'exp_age']\n",
    "n_trees = [100, 500]\n",
    "\n",
    "grid_cv = GridSearchCV(RandomForestRegressor(), \n",
    "                          param_grid = {'max_depth':max_depths, \n",
    "                                        'n_estimators':n_trees}, \n",
    "                          scoring = 'neg_mean_squared_error',\n",
    "                          cv = 5) \n",
    "\n",
    "## you fit it just like a model\n",
    "grid_cv.fit(concrete_train[features], concrete_train['strength'])\n",
    "\n",
    "print(grid_cv.best_params_)\n",
    "print(-grid_cv.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_grid(max_depths,features,n_trees,concrete_train, tree_methods, print_best=True):\n",
    "\n",
    "    grid_cv = GridSearchCV(XGBRegressor(),\n",
    "                              param_grid = {'max_depth':max_depths, \n",
    "                                            'n_estimators':n_trees,\n",
    "                                            'tree_method': tree_methods}, \n",
    "                              scoring = 'neg_mean_squared_error', \n",
    "                              cv = 5) \n",
    "\n",
    "    ## you fit it just like a model\n",
    "    grid_cv.fit(concrete_train[features], concrete_train['strength'])\n",
    "\n",
    "    if print_best:\n",
    "        print(f'The best set of parameters is {grid_cv.best_params_}')\n",
    "        print(f'The best set of score is {-grid_cv.best_score_}')\n",
    "\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set of parameters is {'max_depth': 2, 'n_estimators': 1200, 'tree_method': 'approx'}\n",
      "The best set of score is 19.640115527493624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2], &#x27;n_estimators&#x27;: [1200],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;approx&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2], &#x27;n_estimators&#x27;: [1200],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;approx&#x27;]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={'max_depth': [2], 'n_estimators': [1200],\n",
       "                         'tree_method': ['approx']},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depths = [2]\n",
    "features = ['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg', 'fineagg', 'exp_age']\n",
    "n_trees = [1200]\n",
    "tree_methods = ['approx']\n",
    "\n",
    "xg_grid(max_depths,features,n_trees,concrete_train, tree_methods, print_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 1200, 'tree_method': 'approx'} -305.54186741168775\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.arange(2, 11)\n",
    "n_trees = np.arange(1000, 2000, 10)\n",
    "tree_methods = ['approx', 'hist', 'gpu_hist']\n",
    "\n",
    "best_mses = []\n",
    "best_xgb_params = []\n",
    "\n",
    "for feature in powerset(features):\n",
    "    grid_cv = xg_grid(max_depths,feature,n_trees,concrete_train, tree_methods, print_best=False)\n",
    "    best_mses.append(grid_cv.best_score_)\n",
    "    best_xgb_params.append(grid_cv.best_params_)\n",
    "\n",
    "\n",
    "print(best_xgb_params[np.argmax(best_mses)], -np.max(best_mses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 1200, 'tree_method': 'approx'} 19.640115527493624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cement',\n",
       " 'slag',\n",
       " 'ash',\n",
       " 'water',\n",
       " 'superplastic',\n",
       " 'coarseagg',\n",
       " 'fineagg',\n",
       " 'exp_age']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(best_params[np.argmax(best_mses)], -np.max(best_mses))\n",
    "\n",
    "powerset(features)[np.argmax(best_mses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set of parameters is {'max_depth': 2, 'n_estimators': 1200, 'tree_method': 'approx'}\n",
      "The best set of score is 19.640115527493624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([27.68878049, 23.16157797, 21.66978768, 20.69625276, 20.3404631 ,\n",
       "       20.12452399, 19.89260176, 19.66982308, 19.72231138, 19.64968767,\n",
       "       19.67317779, 19.64011553, 19.64603412, 19.68432869, 19.65423094,\n",
       "       19.71524728, 19.73650807, 19.76519029, 19.83415522, 19.87897323])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trees = np.arange(100, 2001, 100)\n",
    "mses = - xg_grid([2],features,n_trees,concrete_train, ['approx'], print_best=True).cv_results_['mean_test_score']\n",
    "mses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=n_trees,\n",
    "y=mses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram-based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hgb_grid(max_depths,features,max_iters,concrete_train, learning_rates, print_best=True):\n",
    "\n",
    "    grid_cv = GridSearchCV(HistGradientBoostingRegressor(),\n",
    "                              param_grid = {'max_depth':max_depths, \n",
    "                                            'max_iter':max_iters,\n",
    "                                            'learning_rate': learning_rates}, \n",
    "                              scoring = 'neg_mean_squared_error', \n",
    "                              cv = 5) \n",
    "\n",
    "    ## you fit it just like a model\n",
    "    grid_cv.fit(concrete_train[features], concrete_train['strength'])\n",
    "\n",
    "    if print_best:\n",
    "        print(f'The best set of parameters is {grid_cv.best_params_}')\n",
    "        print(f'The best set of score is {-grid_cv.best_score_}')\n",
    "\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(2, 10)\n",
    "max_iters = np.arange(200, 1000, 10)\n",
    "learning_rates = np.arange(.05, .15, .01)\n",
    "\n",
    "best_mses = []\n",
    "best_hgb_params = []\n",
    "\n",
    "for feature in powerset(features):\n",
    "    grid_cv = hgb_grid(max_depths,features,max_iters,concrete_train, learning_rates, print_best=False)\n",
    "    best_mses.append(grid_cv.best_score_)\n",
    "    best_hgb_params.append(grid_cv.best_params_)\n",
    "\n",
    "\n",
    "print(best_hgb_params[np.argmax(best_mses)], -np.max(best_mses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set of parameters is {'learning_rate': 0.1, 'max_depth': 5, 'max_iter': 800}\n",
      "The best set of score is 21.90660451714236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([34.21160879, 25.58425841, 24.41561855, 23.34262051, 21.90660452,\n",
       "       23.18271334, 23.59941612, 23.81869135, 23.81494052, 23.9656131 ])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depths = np.arange(1, 11)\n",
    "mses = - hgb_grid(max_depths,features,[800],concrete_train, [.1], print_best=True).cv_results_['mean_test_score']\n",
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=max_depths,\n",
    "y=mses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best I have gotten it, after much tinkering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = scale.fit_transform(concrete_train[features]), concrete_train['strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_tt, concrete_val = train_test_split(concrete_train,\n",
    "                                             shuffle=True,\n",
    "                                             random_state=453)\n",
    "\n",
    "X_tt, y_tt = scale.fit_transform(concrete_tt[features]), concrete_tt['strength']\n",
    "X_val, y_val = scale.fit_transform(concrete_val[features]), concrete_val['strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_grid(hidden_layer_sizes,features,activations,concrete_train, learning_rates, solvers, print_best=True):\n",
    "\n",
    "    scale = StandardScaler(copy=True)\n",
    "    X_scale = scale.fit_transform(concrete_train[features])\n",
    "    grid_cv = GridSearchCV(MLPRegressor(max_iter=10000), \n",
    "                          param_grid = {'hidden_layer_sizes': hidden_layer_sizes,\n",
    "                                        'learning_rate': learning_rates,\n",
    "                                        'solver': solvers,\n",
    "                                        'activation': activations,\n",
    "                                        }, \n",
    "                          scoring = 'neg_mean_squared_error', \n",
    "                          cv = 5) \n",
    "\n",
    "    grid_cv.fit(X_scale, concrete_train['strength'])\n",
    "\n",
    "    if print_best:\n",
    "        print(f'The best set of parameters is {grid_cv.best_params_}')\n",
    "        print(f'The best set of score is {-grid_cv.best_score_}')\n",
    "\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set of parameters is {'activation': 'relu', 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "The best set of score is 31.788966162807498\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [(100, 100)]\n",
    "learning_rates = ['constant', 'adaptive']\n",
    "solvers = ['lbfgs', 'sgd', ]\n",
    "activations = ['relu', 'identity', 'logistic', 'tanh']\n",
    "alphas = [.0001]\n",
    "\n",
    "grid_cv = mlp_grid(hidden_layer_sizes,features,activations,concrete_train, learning_rates, solvers, print_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set of parameters is {'activation': 'relu', 'hidden_layer_sizes': (165, 165), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "The best set of score is 24.859101463511994\n"
     ]
    }
   ],
   "source": [
    "n_range = np.arange(120, 220, 5)\n",
    "hidden_layer_sizes = [(n, n) for n in n_range]\n",
    "learning_rates = ['adaptive']\n",
    "solvers = ['sgd']\n",
    "activations = ['relu']\n",
    "alphas = [.0001]\n",
    "\n",
    "mses = - mlp_grid(hidden_layer_sizes,features,activations,concrete_train, learning_rates, solvers, print_best=True).cv_results_['mean_test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes = [(n, n) for n in np.arange(150, 210, 5)]\n",
    "learning_rates = ['constant', 'adaptive']\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "activations = ['relu', 'identity', 'logistic', 'tanh']\n",
    "alphas = [.0001]\n",
    "\n",
    "mses = - mlp_grid(hidden_layer_sizes,features,activations,concrete_train, learning_rates, solvers, print_best=True).cv_results_['mean_test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.scatterplot(x=n_range,\n",
    "                y=mses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "12/12 [==============================] - 3s 55ms/step - loss: 1177.7344 - mse: 1177.7344 - val_loss: 653.7554 - val_mse: 653.7554\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 277.3828 - mse: 277.3828 - val_loss: 226.7487 - val_mse: 226.7487\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 170.3129 - mse: 170.3129 - val_loss: 201.7657 - val_mse: 201.7657\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 154.3048 - mse: 154.3048 - val_loss: 170.6984 - val_mse: 170.6984\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 137.1324 - mse: 137.1324 - val_loss: 202.3536 - val_mse: 202.3536\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 130.5164 - mse: 130.5164 - val_loss: 160.6778 - val_mse: 160.6778\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 120.5772 - mse: 120.5772 - val_loss: 146.1408 - val_mse: 146.1408\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 115.8055 - mse: 115.8055 - val_loss: 133.4910 - val_mse: 133.4910\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 104.9697 - mse: 104.9697 - val_loss: 125.2374 - val_mse: 125.2374\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 100.3171 - mse: 100.3171 - val_loss: 124.7129 - val_mse: 124.7129\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 96.1341 - mse: 96.1341 - val_loss: 113.5746 - val_mse: 113.5746\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 82.7052 - mse: 82.7052 - val_loss: 145.0175 - val_mse: 145.0175\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 83.4624 - mse: 83.4624 - val_loss: 98.9417 - val_mse: 98.9417\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 73.3466 - mse: 73.3466 - val_loss: 91.6173 - val_mse: 91.6173\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 67.3380 - mse: 67.3380 - val_loss: 87.6004 - val_mse: 87.6004\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 69.5772 - mse: 69.5772 - val_loss: 108.9421 - val_mse: 108.9421\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 57.3291 - mse: 57.3291 - val_loss: 86.4781 - val_mse: 86.4781\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 55.6480 - mse: 55.6480 - val_loss: 87.9950 - val_mse: 87.9950\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 53.0230 - mse: 53.0230 - val_loss: 68.4903 - val_mse: 68.4903\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 50.7764 - mse: 50.7764 - val_loss: 64.2562 - val_mse: 64.2562\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 47.1495 - mse: 47.1495 - val_loss: 64.8133 - val_mse: 64.8133\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 44.2561 - mse: 44.2561 - val_loss: 64.1583 - val_mse: 64.1583\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 42.8186 - mse: 42.8186 - val_loss: 60.3355 - val_mse: 60.3355\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 42.9285 - mse: 42.9285 - val_loss: 56.8253 - val_mse: 56.8253\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 41.1972 - mse: 41.1972 - val_loss: 59.5068 - val_mse: 59.5068\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 39.0542 - mse: 39.0542 - val_loss: 54.5404 - val_mse: 54.5404\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 35.9364 - mse: 35.9364 - val_loss: 58.1889 - val_mse: 58.1889\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 39.6914 - mse: 39.6914 - val_loss: 50.9095 - val_mse: 50.9095\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 37.3996 - mse: 37.3996 - val_loss: 50.2790 - val_mse: 50.2790\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 37.6302 - mse: 37.6302 - val_loss: 52.0780 - val_mse: 52.0780\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 30.9023 - mse: 30.9023 - val_loss: 50.5687 - val_mse: 50.5687\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 37.3325 - mse: 37.3325 - val_loss: 49.9321 - val_mse: 49.9321\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 30.5285 - mse: 30.5285 - val_loss: 72.1870 - val_mse: 72.1870\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 37.3110 - mse: 37.3110 - val_loss: 46.1159 - val_mse: 46.1159\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 35.6622 - mse: 35.6622 - val_loss: 45.0663 - val_mse: 45.0663\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 31.5890 - mse: 31.5890 - val_loss: 49.7349 - val_mse: 49.7349\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 35.3091 - mse: 35.3091 - val_loss: 62.9807 - val_mse: 62.9807\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 34.6729 - mse: 34.6729 - val_loss: 48.2564 - val_mse: 48.2564\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 29.4551 - mse: 29.4551 - val_loss: 52.5408 - val_mse: 52.5408\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 31.3986 - mse: 31.3986 - val_loss: 51.1343 - val_mse: 51.1343\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 31.7228 - mse: 31.7228 - val_loss: 59.2973 - val_mse: 59.2973\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 28.1131 - mse: 28.1131 - val_loss: 44.2331 - val_mse: 44.2331\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 30.6125 - mse: 30.6125 - val_loss: 46.9033 - val_mse: 46.9033\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 27.9767 - mse: 27.9767 - val_loss: 45.5021 - val_mse: 45.5021\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 30.7215 - mse: 30.7215 - val_loss: 58.8183 - val_mse: 58.8183\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 30.3170 - mse: 30.3170 - val_loss: 49.6442 - val_mse: 49.6442\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 24.6168 - mse: 24.6168 - val_loss: 53.8576 - val_mse: 53.8576\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 29.5985 - mse: 29.5985 - val_loss: 70.0847 - val_mse: 70.0847\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29.1609 - mse: 29.1609 - val_loss: 49.5020 - val_mse: 49.5020\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 27.8417 - mse: 27.8417 - val_loss: 58.3749 - val_mse: 58.3749\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 26.0378 - mse: 26.0378 - val_loss: 43.2147 - val_mse: 43.2147\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 27.3018 - mse: 27.3018 - val_loss: 65.4362 - val_mse: 65.4362\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 26.4384 - mse: 26.4384 - val_loss: 55.6449 - val_mse: 55.6449\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 22.7189 - mse: 22.7189 - val_loss: 58.4327 - val_mse: 58.4327\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 27.8633 - mse: 27.8633 - val_loss: 46.9273 - val_mse: 46.9273\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 29.7041 - mse: 29.7041 - val_loss: 46.4705 - val_mse: 46.4705\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 22.9792 - mse: 22.9792 - val_loss: 52.1862 - val_mse: 52.1862\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 27.9927 - mse: 27.9927 - val_loss: 42.0220 - val_mse: 42.0220\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 29.3683 - mse: 29.3683 - val_loss: 44.6345 - val_mse: 44.6345\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 25.3843 - mse: 25.3843 - val_loss: 43.0481 - val_mse: 43.0481\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 21.8774 - mse: 21.8774 - val_loss: 42.2611 - val_mse: 42.2611\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 24.5512 - mse: 24.5512 - val_loss: 43.4006 - val_mse: 43.4006\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 24.5630 - mse: 24.5630 - val_loss: 50.0186 - val_mse: 50.0186\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 27.0044 - mse: 27.0044 - val_loss: 40.8523 - val_mse: 40.8523\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.6260 - mse: 24.6260 - val_loss: 48.2997 - val_mse: 48.2997\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25.7069 - mse: 25.7069 - val_loss: 45.7105 - val_mse: 45.7105\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 22.3831 - mse: 22.3831 - val_loss: 41.7208 - val_mse: 41.7208\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 27.5300 - mse: 27.5300 - val_loss: 40.8745 - val_mse: 40.8745\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 23.5210 - mse: 23.5210 - val_loss: 42.8844 - val_mse: 42.8844\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 27.0339 - mse: 27.0339 - val_loss: 45.9766 - val_mse: 45.9766\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.1502 - mse: 19.1502 - val_loss: 55.7580 - val_mse: 55.7580\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 25.5610 - mse: 25.5610 - val_loss: 48.7404 - val_mse: 48.7404\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 22.3706 - mse: 22.3706 - val_loss: 45.2792 - val_mse: 45.2792\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 25.7510 - mse: 25.7510 - val_loss: 43.2870 - val_mse: 43.2870\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 22.9510 - mse: 22.9510 - val_loss: 59.2239 - val_mse: 59.2239\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 22.3216 - mse: 22.3216 - val_loss: 39.9265 - val_mse: 39.9265\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 21.9932 - mse: 21.9932 - val_loss: 56.8522 - val_mse: 56.8522\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.4660 - mse: 24.4660 - val_loss: 46.5172 - val_mse: 46.5172\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 22.8725 - mse: 22.8725 - val_loss: 39.9855 - val_mse: 39.9855\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.6873 - mse: 22.6873 - val_loss: 47.1988 - val_mse: 47.1988\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.3625 - mse: 22.3625 - val_loss: 41.0361 - val_mse: 41.0361\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 21.3955 - mse: 21.3955 - val_loss: 64.1928 - val_mse: 64.1928\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.0327 - mse: 24.0327 - val_loss: 52.2873 - val_mse: 52.2873\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 21.3409 - mse: 21.3409 - val_loss: 42.9180 - val_mse: 42.9180\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 20.4962 - mse: 20.4962 - val_loss: 68.6124 - val_mse: 68.6124\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 20.5825 - mse: 20.5825 - val_loss: 50.7130 - val_mse: 50.7130\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.2104 - mse: 25.2104 - val_loss: 41.4896 - val_mse: 41.4896\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.8991 - mse: 19.8991 - val_loss: 51.6117 - val_mse: 51.6117\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 23.1253 - mse: 23.1253 - val_loss: 71.0508 - val_mse: 71.0508\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 21.5812 - mse: 21.5812 - val_loss: 39.0020 - val_mse: 39.0020\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25.9677 - mse: 25.9677 - val_loss: 38.8409 - val_mse: 38.8409\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.7903 - mse: 22.7903 - val_loss: 44.9307 - val_mse: 44.9307\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.8334 - mse: 18.8334 - val_loss: 37.2438 - val_mse: 37.2438\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 15.4245 - mse: 15.4245 - val_loss: 59.7571 - val_mse: 59.7571\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 23.8261 - mse: 23.8261 - val_loss: 37.5626 - val_mse: 37.5626\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 22.9683 - mse: 22.9683 - val_loss: 38.8353 - val_mse: 38.8353\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 17.7345 - mse: 17.7345 - val_loss: 70.9172 - val_mse: 70.9172\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.9768 - mse: 20.9768 - val_loss: 36.2953 - val_mse: 36.2953\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 20.2878 - mse: 20.2878 - val_loss: 42.2241 - val_mse: 42.2241\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.2515 - mse: 19.2515 - val_loss: 40.8489 - val_mse: 40.8489\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.8647 - mse: 21.8647 - val_loss: 38.1661 - val_mse: 38.1661\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 17.9415 - mse: 17.9415 - val_loss: 38.6557 - val_mse: 38.6557\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 21.8038 - mse: 21.8038 - val_loss: 41.7454 - val_mse: 41.7454\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 20.8786 - mse: 20.8786 - val_loss: 38.2249 - val_mse: 38.2249\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 15.0754 - mse: 15.0754 - val_loss: 40.9425 - val_mse: 40.9425\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 23.3033 - mse: 23.3033 - val_loss: 37.1410 - val_mse: 37.1410\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 19.2794 - mse: 19.2794 - val_loss: 45.6995 - val_mse: 45.6995\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 18.3130 - mse: 18.3130 - val_loss: 46.2722 - val_mse: 46.2722\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 23.7138 - mse: 23.7138 - val_loss: 37.6629 - val_mse: 37.6629\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.1705 - mse: 15.1705 - val_loss: 46.0464 - val_mse: 46.0464\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 23.2178 - mse: 23.2178 - val_loss: 36.8776 - val_mse: 36.8776\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 14.7791 - mse: 14.7791 - val_loss: 36.7745 - val_mse: 36.7745\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 22.4959 - mse: 22.4959 - val_loss: 35.4640 - val_mse: 35.4640\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 21.3601 - mse: 21.3601 - val_loss: 37.8806 - val_mse: 37.8806\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 18.0098 - mse: 18.0098 - val_loss: 38.2508 - val_mse: 38.2508\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.6968 - mse: 19.6968 - val_loss: 48.2471 - val_mse: 48.2471\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 19.7060 - mse: 19.7060 - val_loss: 40.0934 - val_mse: 40.0934\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.9609 - mse: 17.9609 - val_loss: 39.9042 - val_mse: 39.9042\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.2013 - mse: 19.2013 - val_loss: 46.9403 - val_mse: 46.9403\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.9591 - mse: 17.9591 - val_loss: 36.5116 - val_mse: 36.5116\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 21.0562 - mse: 21.0562 - val_loss: 35.5894 - val_mse: 35.5894\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 14.8508 - mse: 14.8508 - val_loss: 42.8747 - val_mse: 42.8747\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 22.4992 - mse: 22.4992 - val_loss: 36.1412 - val_mse: 36.1412\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 15.2633 - mse: 15.2633 - val_loss: 64.3102 - val_mse: 64.3102\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.5237 - mse: 18.5237 - val_loss: 37.3878 - val_mse: 37.3878\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.4700 - mse: 18.4700 - val_loss: 40.2232 - val_mse: 40.2232\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.0959 - mse: 19.0959 - val_loss: 36.5434 - val_mse: 36.5434\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.7667 - mse: 18.7667 - val_loss: 38.2123 - val_mse: 38.2123\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 17.7615 - mse: 17.7615 - val_loss: 43.6157 - val_mse: 43.6157\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 20.3200 - mse: 20.3199 - val_loss: 50.0174 - val_mse: 50.0174\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 17.2724 - mse: 17.2724 - val_loss: 35.2301 - val_mse: 35.2301\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.6129 - mse: 16.6129 - val_loss: 34.7372 - val_mse: 34.7372\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.0145 - mse: 20.0145 - val_loss: 35.3426 - val_mse: 35.3426\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.8436 - mse: 13.8436 - val_loss: 47.4218 - val_mse: 47.4218\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.9334 - mse: 17.9334 - val_loss: 51.8826 - val_mse: 51.8826\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 21.6055 - mse: 21.6055 - val_loss: 37.4246 - val_mse: 37.4246\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 12.9453 - mse: 12.9453 - val_loss: 36.5415 - val_mse: 36.5415\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 21.5116 - mse: 21.5116 - val_loss: 39.0830 - val_mse: 39.0830\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 15.9058 - mse: 15.9058 - val_loss: 38.9696 - val_mse: 38.9696\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 19.8811 - mse: 19.8811 - val_loss: 34.4776 - val_mse: 34.4776\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.4397 - mse: 19.4397 - val_loss: 35.5032 - val_mse: 35.5032\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.5558 - mse: 19.5558 - val_loss: 34.7038 - val_mse: 34.7038\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11.3361 - mse: 11.3361 - val_loss: 37.8007 - val_mse: 37.8007\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.9117 - mse: 15.9117 - val_loss: 44.9041 - val_mse: 44.9041\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.7765 - mse: 17.7765 - val_loss: 40.8642 - val_mse: 40.8642\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.5320 - mse: 13.5320 - val_loss: 35.9079 - val_mse: 35.9079\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 16.7175 - mse: 16.7175 - val_loss: 45.5700 - val_mse: 45.5700\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 18.8548 - mse: 18.8548 - val_loss: 34.0131 - val_mse: 34.0131\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 20.0920 - mse: 20.0920 - val_loss: 36.5505 - val_mse: 36.5505\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12.7909 - mse: 12.7909 - val_loss: 40.7258 - val_mse: 40.7258\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 15.3488 - mse: 15.3488 - val_loss: 34.6698 - val_mse: 34.6698\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19.7067 - mse: 19.7067 - val_loss: 36.4109 - val_mse: 36.4109\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 17.5411 - mse: 17.5411 - val_loss: 35.3196 - val_mse: 35.3196\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.9973 - mse: 15.9973 - val_loss: 33.7356 - val_mse: 33.7356\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 15.3774 - mse: 15.3774 - val_loss: 38.9429 - val_mse: 38.9429\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 17.4105 - mse: 17.4105 - val_loss: 33.3132 - val_mse: 33.3132\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.6352 - mse: 15.6352 - val_loss: 32.1745 - val_mse: 32.1745\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 16.8925 - mse: 16.8925 - val_loss: 33.5664 - val_mse: 33.5664\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.7506 - mse: 19.7506 - val_loss: 34.7658 - val_mse: 34.7658\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 11.5307 - mse: 11.5307 - val_loss: 32.9428 - val_mse: 32.9428\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 19.8078 - mse: 19.8078 - val_loss: 34.6307 - val_mse: 34.6307\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.3851 - mse: 14.3851 - val_loss: 31.4624 - val_mse: 31.4624\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.7020 - mse: 16.7020 - val_loss: 48.6292 - val_mse: 48.6292\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 14.7592 - mse: 14.7592 - val_loss: 32.0230 - val_mse: 32.0230\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 12.2898 - mse: 12.2898 - val_loss: 42.1754 - val_mse: 42.1754\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 19.6273 - mse: 19.6273 - val_loss: 42.5109 - val_mse: 42.5109\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.7935 - mse: 14.7935 - val_loss: 32.4314 - val_mse: 32.4314\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.1534 - mse: 14.1534 - val_loss: 32.1988 - val_mse: 32.1988\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 17.7813 - mse: 17.7813 - val_loss: 35.0433 - val_mse: 35.0433\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 15.5638 - mse: 15.5638 - val_loss: 32.2513 - val_mse: 32.2513\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.7619 - mse: 15.7619 - val_loss: 32.7241 - val_mse: 32.7241\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 10.5382 - mse: 10.5382 - val_loss: 35.3352 - val_mse: 35.3352\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 19.2120 - mse: 19.2120 - val_loss: 33.6819 - val_mse: 33.6819\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.5791 - mse: 12.5791 - val_loss: 46.5078 - val_mse: 46.5078\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.7878 - mse: 14.7878 - val_loss: 42.8348 - val_mse: 42.8348\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 16.9632 - mse: 16.9632 - val_loss: 41.7745 - val_mse: 41.7745\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.0626 - mse: 15.0626 - val_loss: 34.9872 - val_mse: 34.9872\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.2130 - mse: 13.2130 - val_loss: 43.6776 - val_mse: 43.6776\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 15.5536 - mse: 15.5536 - val_loss: 41.2770 - val_mse: 41.2770\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 15.7039 - mse: 15.7039 - val_loss: 42.8042 - val_mse: 42.8042\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.7848 - mse: 14.7848 - val_loss: 35.2077 - val_mse: 35.2077\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.5835 - mse: 14.5835 - val_loss: 48.7627 - val_mse: 48.7627\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.6409 - mse: 16.6409 - val_loss: 37.6333 - val_mse: 37.6333\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.8933 - mse: 12.8933 - val_loss: 37.8361 - val_mse: 37.8361\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 15.8280 - mse: 15.8280 - val_loss: 33.8065 - val_mse: 33.8065\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.6093 - mse: 15.6093 - val_loss: 32.5737 - val_mse: 32.5737\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.3556 - mse: 12.3556 - val_loss: 32.0951 - val_mse: 32.0951\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 16.2251 - mse: 16.2251 - val_loss: 33.8156 - val_mse: 33.8156\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 11.4881 - mse: 11.4881 - val_loss: 38.4889 - val_mse: 38.4889\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.9792 - mse: 13.9792 - val_loss: 33.5436 - val_mse: 33.5436\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.4143 - mse: 16.4143 - val_loss: 39.3165 - val_mse: 39.3165\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.4561 - mse: 13.4561 - val_loss: 39.6564 - val_mse: 39.6564\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.6956 - mse: 15.6956 - val_loss: 40.0958 - val_mse: 40.0958\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.7439 - mse: 14.7439 - val_loss: 43.1270 - val_mse: 43.1270\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.6515 - mse: 12.6515 - val_loss: 70.8495 - val_mse: 70.8495\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 14.4577 - mse: 14.4577 - val_loss: 48.0719 - val_mse: 48.0719\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 12.0070 - mse: 12.0070 - val_loss: 33.4351 - val_mse: 33.4351\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 16.5644 - mse: 16.5644 - val_loss: 31.0716 - val_mse: 31.0716\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.2359 - mse: 15.2359 - val_loss: 30.8958 - val_mse: 30.8958\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.8781 - mse: 9.8781 - val_loss: 46.4818 - val_mse: 46.4818\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.0287 - mse: 17.0287 - val_loss: 31.3222 - val_mse: 31.3222\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.2107 - mse: 13.2107 - val_loss: 31.1431 - val_mse: 31.1431\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.7964 - mse: 12.7964 - val_loss: 36.7353 - val_mse: 36.7353\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 14.4876 - mse: 14.4876 - val_loss: 32.1829 - val_mse: 32.1829\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12.5559 - mse: 12.5559 - val_loss: 34.4354 - val_mse: 34.4354\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.8810 - mse: 14.8810 - val_loss: 31.7977 - val_mse: 31.7977\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.1175 - mse: 12.1175 - val_loss: 35.3768 - val_mse: 35.3768\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.9777 - mse: 15.9777 - val_loss: 32.4022 - val_mse: 32.4022\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.5898 - mse: 10.5898 - val_loss: 31.8317 - val_mse: 31.8317\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.7668 - mse: 14.7668 - val_loss: 31.8571 - val_mse: 31.8571\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.9962 - mse: 12.9962 - val_loss: 41.4918 - val_mse: 41.4918\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.0447 - mse: 14.0447 - val_loss: 42.5074 - val_mse: 42.5074\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12.1917 - mse: 12.1917 - val_loss: 37.2441 - val_mse: 37.2441\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 13.2970 - mse: 13.2970 - val_loss: 32.2874 - val_mse: 32.2874\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 15.2264 - mse: 15.2264 - val_loss: 32.7906 - val_mse: 32.7906\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.9340 - mse: 10.9340 - val_loss: 51.1814 - val_mse: 51.1814\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.1979 - mse: 14.1979 - val_loss: 30.4909 - val_mse: 30.4909\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.8224 - mse: 13.8224 - val_loss: 29.6574 - val_mse: 29.6574\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.4641 - mse: 13.4641 - val_loss: 30.7563 - val_mse: 30.7563\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.6364 - mse: 11.6364 - val_loss: 31.4178 - val_mse: 31.4178\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 16.2732 - mse: 16.2732 - val_loss: 38.2032 - val_mse: 38.2032\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 12.5226 - mse: 12.5226 - val_loss: 29.2582 - val_mse: 29.2582\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 12.7665 - mse: 12.7665 - val_loss: 31.1273 - val_mse: 31.1273\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 13.9161 - mse: 13.9161 - val_loss: 33.5997 - val_mse: 33.5997\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.1790 - mse: 14.1790 - val_loss: 35.6123 - val_mse: 35.6123\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.8200 - mse: 10.8200 - val_loss: 56.5927 - val_mse: 56.5927\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 13.4102 - mse: 13.4102 - val_loss: 29.8585 - val_mse: 29.8585\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 14.0601 - mse: 14.0601 - val_loss: 34.2686 - val_mse: 34.2686\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 14.3476 - mse: 14.3476 - val_loss: 34.6536 - val_mse: 34.6536\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 8.5997 - mse: 8.5997 - val_loss: 53.6020 - val_mse: 53.6020\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.4088 - mse: 14.4088 - val_loss: 34.2793 - val_mse: 34.2793\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.1530 - mse: 13.1530 - val_loss: 28.5870 - val_mse: 28.5870\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.4045 - mse: 15.4045 - val_loss: 32.7789 - val_mse: 32.7789\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.8514 - mse: 8.8514 - val_loss: 28.2462 - val_mse: 28.2462\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 16.2704 - mse: 16.2704 - val_loss: 30.2505 - val_mse: 30.2505\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 8.6728 - mse: 8.6728 - val_loss: 45.6995 - val_mse: 45.6995\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 15.6050 - mse: 15.6050 - val_loss: 41.2310 - val_mse: 41.2310\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.5625 - mse: 10.5625 - val_loss: 38.1977 - val_mse: 38.1977\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.7039 - mse: 13.7039 - val_loss: 36.6617 - val_mse: 36.6617\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.5953 - mse: 13.5953 - val_loss: 30.9630 - val_mse: 30.9630\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 12.5580 - mse: 12.5580 - val_loss: 33.9846 - val_mse: 33.9846\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 11.3477 - mse: 11.3477 - val_loss: 41.4660 - val_mse: 41.4660\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 12.6505 - mse: 12.6505 - val_loss: 30.5699 - val_mse: 30.5699\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 11.6841 - mse: 11.6841 - val_loss: 36.2434 - val_mse: 36.2434\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 13.9220 - mse: 13.9220 - val_loss: 31.9202 - val_mse: 31.9202\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 11.0653 - mse: 11.0653 - val_loss: 45.3195 - val_mse: 45.3195\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 10.7084 - mse: 10.7084 - val_loss: 31.4680 - val_mse: 31.4680\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 13.8846 - mse: 13.8846 - val_loss: 29.4716 - val_mse: 29.4716\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 10.8473 - mse: 10.8473 - val_loss: 33.9115 - val_mse: 33.9115\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 12.6085 - mse: 12.6085 - val_loss: 34.9169 - val_mse: 34.9169\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.2597 - mse: 11.2597 - val_loss: 29.4966 - val_mse: 29.4966\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11.2076 - mse: 11.2076 - val_loss: 34.1970 - val_mse: 34.1970\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 11.6687 - mse: 11.6687 - val_loss: 28.1799 - val_mse: 28.1799\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 12.3754 - mse: 12.3754 - val_loss: 29.0727 - val_mse: 29.0727\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 14.5099 - mse: 14.5099 - val_loss: 30.2467 - val_mse: 30.2467\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.2458 - mse: 12.2458 - val_loss: 42.0179 - val_mse: 42.0179\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.2301 - mse: 10.2301 - val_loss: 28.4705 - val_mse: 28.4705\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 13.2181 - mse: 13.2181 - val_loss: 29.5741 - val_mse: 29.5741\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 13.5651 - mse: 13.5651 - val_loss: 35.2851 - val_mse: 35.2851\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 8.8644 - mse: 8.8644 - val_loss: 52.2123 - val_mse: 52.2123\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 10.4226 - mse: 10.4226 - val_loss: 33.6796 - val_mse: 33.6796\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 12.3579 - mse: 12.3579 - val_loss: 27.7889 - val_mse: 27.7889\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 15.0065 - mse: 15.0065 - val_loss: 29.9571 - val_mse: 29.9571\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.1362 - mse: 8.1362 - val_loss: 34.4184 - val_mse: 34.4184\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 14.4726 - mse: 14.4726 - val_loss: 29.9228 - val_mse: 29.9228\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.8263 - mse: 7.8263 - val_loss: 34.1458 - val_mse: 34.1458\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.3880 - mse: 14.3880 - val_loss: 28.0276 - val_mse: 28.0276\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 10.7017 - mse: 10.7017 - val_loss: 28.2453 - val_mse: 28.2453\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 12.4389 - mse: 12.4389 - val_loss: 42.7190 - val_mse: 42.7190\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.6674 - mse: 12.6674 - val_loss: 32.0593 - val_mse: 32.0593\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 11.0765 - mse: 11.0765 - val_loss: 32.9226 - val_mse: 32.9226\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.5403 - mse: 12.5403 - val_loss: 39.4254 - val_mse: 39.4254\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.8540 - mse: 8.8540 - val_loss: 31.0474 - val_mse: 31.0474\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.2246 - mse: 12.2246 - val_loss: 37.8618 - val_mse: 37.8618\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.4290 - mse: 12.4290 - val_loss: 28.3851 - val_mse: 28.3851\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.8098 - mse: 9.8098 - val_loss: 37.3785 - val_mse: 37.3785\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 11.1670 - mse: 11.1670 - val_loss: 29.0164 - val_mse: 29.0164\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 10.3935 - mse: 10.3935 - val_loss: 36.9824 - val_mse: 36.9824\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 10.9266 - mse: 10.9266 - val_loss: 28.8210 - val_mse: 28.8210\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.6238 - mse: 10.6238 - val_loss: 38.4203 - val_mse: 38.4203\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 13.7729 - mse: 13.7729 - val_loss: 39.5803 - val_mse: 39.5803\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.9236 - mse: 7.9236 - val_loss: 27.9976 - val_mse: 27.9976\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.4676 - mse: 14.4676 - val_loss: 28.4997 - val_mse: 28.4997\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.5553 - mse: 8.5553 - val_loss: 41.0850 - val_mse: 41.0850\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 11.2042 - mse: 11.2042 - val_loss: 34.8726 - val_mse: 34.8726\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 7.8196 - mse: 7.8196 - val_loss: 28.9902 - val_mse: 28.9902\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.7538 - mse: 14.7538 - val_loss: 26.8908 - val_mse: 26.8908\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9.3331 - mse: 9.3331 - val_loss: 28.5704 - val_mse: 28.5704\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.8981 - mse: 12.8981 - val_loss: 31.3179 - val_mse: 31.3179\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 10.0170 - mse: 10.0170 - val_loss: 35.0309 - val_mse: 35.0309\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.4532 - mse: 9.4532 - val_loss: 31.3305 - val_mse: 31.3305\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.9188 - mse: 13.9188 - val_loss: 27.3393 - val_mse: 27.3393\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.7013 - mse: 7.7013 - val_loss: 28.9692 - val_mse: 28.9692\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 11.3444 - mse: 11.3444 - val_loss: 29.6777 - val_mse: 29.6777\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.8382 - mse: 11.8382 - val_loss: 28.5192 - val_mse: 28.5192\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.3029 - mse: 10.3029 - val_loss: 32.9500 - val_mse: 32.9500\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.8115 - mse: 9.8115 - val_loss: 32.6770 - val_mse: 32.6770\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.7074 - mse: 10.7074 - val_loss: 31.9157 - val_mse: 31.9157\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.1990 - mse: 11.1990 - val_loss: 29.9845 - val_mse: 29.9845\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.7189 - mse: 9.7189 - val_loss: 46.3863 - val_mse: 46.3863\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.2022 - mse: 10.2022 - val_loss: 29.5351 - val_mse: 29.5351\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 12.2288 - mse: 12.2288 - val_loss: 28.3555 - val_mse: 28.3555\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 7.2863 - mse: 7.2863 - val_loss: 30.6636 - val_mse: 30.6636\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.0062 - mse: 12.0062 - val_loss: 33.4576 - val_mse: 33.4576\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.8809 - mse: 10.8809 - val_loss: 33.3583 - val_mse: 33.3583\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.9386 - mse: 10.9386 - val_loss: 26.9773 - val_mse: 26.9773\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.2913 - mse: 10.2913 - val_loss: 33.2073 - val_mse: 33.2073\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11.3641 - mse: 11.3641 - val_loss: 27.4266 - val_mse: 27.4266\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.2221 - mse: 12.2221 - val_loss: 30.3416 - val_mse: 30.3416\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 7.4917 - mse: 7.4917 - val_loss: 29.7075 - val_mse: 29.7075\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 11.8976 - mse: 11.8976 - val_loss: 30.2677 - val_mse: 30.2677\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.1490 - mse: 11.1490 - val_loss: 35.6357 - val_mse: 35.6357\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 11.1805 - mse: 11.1805 - val_loss: 41.6294 - val_mse: 41.6294\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.9563 - mse: 9.9563 - val_loss: 27.3830 - val_mse: 27.3830\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.1968 - mse: 8.1968 - val_loss: 42.4461 - val_mse: 42.4461\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.3899 - mse: 13.3899 - val_loss: 29.0733 - val_mse: 29.0733\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.4307 - mse: 7.4307 - val_loss: 38.3536 - val_mse: 38.3536\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9674 - mse: 11.9674 - val_loss: 36.0314 - val_mse: 36.0314\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.1811 - mse: 9.1811 - val_loss: 36.1676 - val_mse: 36.1676\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 12.3479 - mse: 12.3479 - val_loss: 35.4997 - val_mse: 35.4997\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 9.9034 - mse: 9.9034 - val_loss: 48.0100 - val_mse: 48.0100\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8.6132 - mse: 8.6132 - val_loss: 28.1380 - val_mse: 28.1380\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.0012 - mse: 12.0012 - val_loss: 28.8014 - val_mse: 28.8014\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.1531 - mse: 9.1531 - val_loss: 30.2908 - val_mse: 30.2908\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 12.1291 - mse: 12.1291 - val_loss: 28.4301 - val_mse: 28.4301\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8.8656 - mse: 8.8656 - val_loss: 29.5358 - val_mse: 29.5358\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.1411 - mse: 10.1411 - val_loss: 29.2421 - val_mse: 29.2421\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.4398 - mse: 13.4398 - val_loss: 43.2512 - val_mse: 43.2512\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.2533 - mse: 7.2533 - val_loss: 27.6758 - val_mse: 27.6758\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 10.8514 - mse: 10.8514 - val_loss: 28.5009 - val_mse: 28.5009\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.3739 - mse: 10.3739 - val_loss: 32.8907 - val_mse: 32.8907\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.9457 - mse: 9.9457 - val_loss: 37.5438 - val_mse: 37.5438\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 10.0045 - mse: 10.0045 - val_loss: 28.2664 - val_mse: 28.2664\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 10.5584 - mse: 10.5584 - val_loss: 39.9084 - val_mse: 39.9084\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.3583 - mse: 8.3583 - val_loss: 36.0374 - val_mse: 36.0374\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.0627 - mse: 8.0627 - val_loss: 31.7983 - val_mse: 31.7983\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.8426 - mse: 10.8426 - val_loss: 28.6954 - val_mse: 28.6954\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 11.0894 - mse: 11.0894 - val_loss: 31.9067 - val_mse: 31.9067\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.4746 - mse: 9.4746 - val_loss: 39.7479 - val_mse: 39.7479\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8.0303 - mse: 8.0303 - val_loss: 27.3090 - val_mse: 27.3090\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 12.4760 - mse: 12.4760 - val_loss: 29.9506 - val_mse: 29.9506\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.6076 - mse: 7.6076 - val_loss: 43.8735 - val_mse: 43.8735\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 11.7799 - mse: 11.7799 - val_loss: 27.9330 - val_mse: 27.9330\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.1864 - mse: 10.1864 - val_loss: 32.7698 - val_mse: 32.7698\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 12.2368 - mse: 12.2368 - val_loss: 32.8131 - val_mse: 32.8131\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 8.7897 - mse: 8.7897 - val_loss: 31.7542 - val_mse: 31.7542\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 7.5494 - mse: 7.5494 - val_loss: 29.2020 - val_mse: 29.2020\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 10.7257 - mse: 10.7257 - val_loss: 29.1766 - val_mse: 29.1766\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 7.3157 - mse: 7.3157 - val_loss: 43.7980 - val_mse: 43.7980\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 12.3181 - mse: 12.3181 - val_loss: 27.6727 - val_mse: 27.6727\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 8.0131 - mse: 8.0131 - val_loss: 44.9638 - val_mse: 44.9638\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.4416 - mse: 11.4416 - val_loss: 30.2106 - val_mse: 30.2106\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 6.4316 - mse: 6.4316 - val_loss: 26.9655 - val_mse: 26.9655\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.5273 - mse: 12.5273 - val_loss: 31.3604 - val_mse: 31.3604\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 5.3816 - mse: 5.3816 - val_loss: 27.8732 - val_mse: 27.8732\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.6145 - mse: 10.6145 - val_loss: 33.4707 - val_mse: 33.4707\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.3508 - mse: 8.3508 - val_loss: 28.8570 - val_mse: 28.8570\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 9.8637 - mse: 9.8637 - val_loss: 29.2759 - val_mse: 29.2759\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 9.6684 - mse: 9.6684 - val_loss: 28.1775 - val_mse: 28.1775\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 7.7973 - mse: 7.7973 - val_loss: 34.0595 - val_mse: 34.0595\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.7680 - mse: 11.7680 - val_loss: 29.9399 - val_mse: 29.9399\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.4928 - mse: 8.4928 - val_loss: 29.1356 - val_mse: 29.1356\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 8.4871 - mse: 8.4871 - val_loss: 31.4289 - val_mse: 31.4289\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.9099 - mse: 9.9099 - val_loss: 27.1480 - val_mse: 27.1480\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.9530 - mse: 9.9530 - val_loss: 27.1295 - val_mse: 27.1295\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.2779 - mse: 8.2779 - val_loss: 34.6615 - val_mse: 34.6615\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.5887 - mse: 9.5887 - val_loss: 29.3144 - val_mse: 29.3144\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.6656 - mse: 9.6656 - val_loss: 35.1512 - val_mse: 35.1512\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.1661 - mse: 9.1661 - val_loss: 34.3913 - val_mse: 34.3913\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.2742 - mse: 8.2742 - val_loss: 35.5011 - val_mse: 35.5011\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 8.6338 - mse: 8.6338 - val_loss: 32.6083 - val_mse: 32.6083\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 9.7285 - mse: 9.7285 - val_loss: 29.6266 - val_mse: 29.6266\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.9987 - mse: 8.9987 - val_loss: 26.9573 - val_mse: 26.9573\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.6700 - mse: 9.6700 - val_loss: 31.8084 - val_mse: 31.8084\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.5083 - mse: 9.5083 - val_loss: 27.7250 - val_mse: 27.7250\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.2413 - mse: 7.2413 - val_loss: 31.7216 - val_mse: 31.7216\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.8330 - mse: 9.8330 - val_loss: 28.0825 - val_mse: 28.0825\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.1031 - mse: 10.1031 - val_loss: 32.7773 - val_mse: 32.7773\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.0135 - mse: 9.0135 - val_loss: 29.1310 - val_mse: 29.1310\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.2871 - mse: 8.2871 - val_loss: 27.0980 - val_mse: 27.0980\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.6774 - mse: 9.6774 - val_loss: 30.4492 - val_mse: 30.4492\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 6.5844 - mse: 6.5844 - val_loss: 28.3107 - val_mse: 28.3107\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.0025 - mse: 12.0025 - val_loss: 33.9345 - val_mse: 33.9345\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 6.3200 - mse: 6.3200 - val_loss: 34.3007 - val_mse: 34.3007\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.3076 - mse: 12.3076 - val_loss: 27.8265 - val_mse: 27.8265\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 7.2855 - mse: 7.2855 - val_loss: 27.8907 - val_mse: 27.8907\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 10.3888 - mse: 10.3888 - val_loss: 28.5409 - val_mse: 28.5409\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 6.8473 - mse: 6.8473 - val_loss: 41.3804 - val_mse: 41.3804\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.4950 - mse: 9.4950 - val_loss: 27.8604 - val_mse: 27.8604\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.9351 - mse: 9.9351 - val_loss: 30.5325 - val_mse: 30.5326\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.8353 - mse: 7.8353 - val_loss: 30.8022 - val_mse: 30.8022\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.5127 - mse: 9.5127 - val_loss: 27.1320 - val_mse: 27.1320\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 4.5666 - mse: 4.5666 - val_loss: 29.0185 - val_mse: 29.0185\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12.2909 - mse: 12.2909 - val_loss: 27.5359 - val_mse: 27.5359\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 5.5939 - mse: 5.5939 - val_loss: 35.5586 - val_mse: 35.5586\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11.0651 - mse: 11.0651 - val_loss: 30.0698 - val_mse: 30.0698\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8.1807 - mse: 8.1807 - val_loss: 32.5544 - val_mse: 32.5544\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.6050 - mse: 7.6050 - val_loss: 31.8577 - val_mse: 31.8577\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.3186 - mse: 8.3186 - val_loss: 33.2005 - val_mse: 33.2005\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9.7906 - mse: 9.7906 - val_loss: 28.2567 - val_mse: 28.2567\n",
      "Epoch 1/400\n",
      "12/12 [==============================] - 4s 95ms/step - loss: 1194.1178 - mse: 1194.1178 - val_loss: 482.5056 - val_mse: 482.5056\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 267.1180 - mse: 267.1180 - val_loss: 186.5361 - val_mse: 186.5361\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 172.1368 - mse: 172.1368 - val_loss: 162.0801 - val_mse: 162.0801\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 153.2055 - mse: 153.2055 - val_loss: 182.1937 - val_mse: 182.1937\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 150.7741 - mse: 150.7741 - val_loss: 139.4043 - val_mse: 139.4043\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 132.5871 - mse: 132.5871 - val_loss: 143.8727 - val_mse: 143.8727\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 123.9548 - mse: 123.9548 - val_loss: 211.7285 - val_mse: 211.7285\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 123.9293 - mse: 123.9293 - val_loss: 140.2651 - val_mse: 140.2651\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 116.1036 - mse: 116.1036 - val_loss: 141.1140 - val_mse: 141.1140\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 106.8747 - mse: 106.8747 - val_loss: 122.7557 - val_mse: 122.7557\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 107.4995 - mse: 107.4995 - val_loss: 117.6067 - val_mse: 117.6067\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 96.4208 - mse: 96.4208 - val_loss: 119.3646 - val_mse: 119.3646\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 91.2327 - mse: 91.2327 - val_loss: 133.6948 - val_mse: 133.6948\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 97.2378 - mse: 97.2378 - val_loss: 112.1894 - val_mse: 112.1894\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 85.3459 - mse: 85.3459 - val_loss: 100.3523 - val_mse: 100.3523\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 77.8881 - mse: 77.8881 - val_loss: 98.2193 - val_mse: 98.2193\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 73.5980 - mse: 73.5980 - val_loss: 96.7719 - val_mse: 96.7719\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 64.3122 - mse: 64.3122 - val_loss: 86.1492 - val_mse: 86.1492\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 66.8427 - mse: 66.8427 - val_loss: 100.0693 - val_mse: 100.0693\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 57.9731 - mse: 57.9731 - val_loss: 73.5579 - val_mse: 73.5579\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 57.8246 - mse: 57.8246 - val_loss: 76.2887 - val_mse: 76.2887\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 48.3189 - mse: 48.3189 - val_loss: 104.1329 - val_mse: 104.1329\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 50.6991 - mse: 50.6991 - val_loss: 97.3511 - val_mse: 97.3511\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 46.9635 - mse: 46.9635 - val_loss: 77.4563 - val_mse: 77.4563\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 41.5971 - mse: 41.5971 - val_loss: 100.6799 - val_mse: 100.6799\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 41.6778 - mse: 41.6778 - val_loss: 81.7467 - val_mse: 81.7467\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 38.9734 - mse: 38.9734 - val_loss: 101.9366 - val_mse: 101.9366\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 40.0613 - mse: 40.0613 - val_loss: 80.6210 - val_mse: 80.6210\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 33.8817 - mse: 33.8817 - val_loss: 66.9955 - val_mse: 66.9955\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 38.6715 - mse: 38.6715 - val_loss: 83.4819 - val_mse: 83.4819\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 32.2248 - mse: 32.2248 - val_loss: 71.5106 - val_mse: 71.5106\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 28.4150 - mse: 28.4150 - val_loss: 79.2491 - val_mse: 79.2491\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 35.2313 - mse: 35.2313 - val_loss: 61.4088 - val_mse: 61.4088\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 30.6369 - mse: 30.6369 - val_loss: 63.0421 - val_mse: 63.0421\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 34.4298 - mse: 34.4298 - val_loss: 61.0876 - val_mse: 61.0876\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 29.5863 - mse: 29.5863 - val_loss: 86.9506 - val_mse: 86.9506\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 33.0678 - mse: 33.0678 - val_loss: 62.7444 - val_mse: 62.7444\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 27.4686 - mse: 27.4686 - val_loss: 75.5470 - val_mse: 75.5470\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 32.7559 - mse: 32.7559 - val_loss: 97.1365 - val_mse: 97.1365\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 28.9002 - mse: 28.9002 - val_loss: 67.9294 - val_mse: 67.9294\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 25.8128 - mse: 25.8128 - val_loss: 93.4821 - val_mse: 93.4821\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 27.2835 - mse: 27.2835 - val_loss: 66.7362 - val_mse: 66.7362\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 29.6549 - mse: 29.6549 - val_loss: 104.3837 - val_mse: 104.3837\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 31.9254 - mse: 31.9254 - val_loss: 67.9798 - val_mse: 67.9798\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 26.3838 - mse: 26.3838 - val_loss: 74.5671 - val_mse: 74.5671\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 24.3202 - mse: 24.3202 - val_loss: 59.0932 - val_mse: 59.0932\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 24.0513 - mse: 24.0513 - val_loss: 74.6769 - val_mse: 74.6769\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 30.6240 - mse: 30.6240 - val_loss: 63.0630 - val_mse: 63.0630\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 24.8624 - mse: 24.8624 - val_loss: 87.4554 - val_mse: 87.4554\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 28.6294 - mse: 28.6294 - val_loss: 62.3437 - val_mse: 62.3437\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 25.2270 - mse: 25.2270 - val_loss: 77.5486 - val_mse: 77.5486\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 25.7073 - mse: 25.7073 - val_loss: 59.0766 - val_mse: 59.0766\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 22.3409 - mse: 22.3409 - val_loss: 59.6390 - val_mse: 59.6390\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 27.2332 - mse: 27.2332 - val_loss: 65.7449 - val_mse: 65.7449\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 25.1650 - mse: 25.1650 - val_loss: 64.7215 - val_mse: 64.7215\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 20.2213 - mse: 20.2213 - val_loss: 76.2612 - val_mse: 76.2612\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 27.0388 - mse: 27.0388 - val_loss: 59.1544 - val_mse: 59.1544\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 44ms/step - loss: 20.4400 - mse: 20.4400 - val_loss: 58.7583 - val_mse: 58.7583\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 24.6071 - mse: 24.6071 - val_loss: 58.4942 - val_mse: 58.4942\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 25.5139 - mse: 25.5139 - val_loss: 60.8464 - val_mse: 60.8464\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 21.0764 - mse: 21.0764 - val_loss: 61.8629 - val_mse: 61.8629\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 24.4843 - mse: 24.4843 - val_loss: 65.4119 - val_mse: 65.4119\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 20.7529 - mse: 20.7529 - val_loss: 56.1654 - val_mse: 56.1654\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 23.2109 - mse: 23.2109 - val_loss: 72.6747 - val_mse: 72.6747\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 24.0158 - mse: 24.0158 - val_loss: 75.6217 - val_mse: 75.6217\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 25.5927 - mse: 25.5927 - val_loss: 59.1423 - val_mse: 59.1423\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 18.8744 - mse: 18.8744 - val_loss: 89.1920 - val_mse: 89.1920\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 22.2626 - mse: 22.2626 - val_loss: 76.8607 - val_mse: 76.8607\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 23.9610 - mse: 23.9610 - val_loss: 60.2774 - val_mse: 60.2774\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 20.3564 - mse: 20.3564 - val_loss: 70.3110 - val_mse: 70.3110\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 21.8611 - mse: 21.8611 - val_loss: 77.2473 - val_mse: 77.2473\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 21.5893 - mse: 21.5893 - val_loss: 65.2524 - val_mse: 65.2524\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 20.0773 - mse: 20.0773 - val_loss: 60.7044 - val_mse: 60.7044\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 27.6893 - mse: 27.6893 - val_loss: 80.7295 - val_mse: 80.7295\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 21.1458 - mse: 21.1458 - val_loss: 69.1581 - val_mse: 69.1581\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 22.8645 - mse: 22.8645 - val_loss: 65.5378 - val_mse: 65.5378\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 20.7061 - mse: 20.7061 - val_loss: 71.1847 - val_mse: 71.1847\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 16.4731 - mse: 16.4731 - val_loss: 62.5440 - val_mse: 62.5440\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 23.5265 - mse: 23.5265 - val_loss: 77.7192 - val_mse: 77.7192\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 22.5086 - mse: 22.5086 - val_loss: 71.2537 - val_mse: 71.2537\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 19.7639 - mse: 19.7639 - val_loss: 74.0921 - val_mse: 74.0921\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 23.3204 - mse: 23.3204 - val_loss: 81.2413 - val_mse: 81.2413\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 17.5689 - mse: 17.5689 - val_loss: 53.4634 - val_mse: 53.4634\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19.9501 - mse: 19.9501 - val_loss: 52.8412 - val_mse: 52.8412\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 21.2709 - mse: 21.2709 - val_loss: 59.9236 - val_mse: 59.9236\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 20.2946 - mse: 20.2946 - val_loss: 65.9640 - val_mse: 65.9640\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 1s 131ms/step - loss: 19.2054 - mse: 19.2054 - val_loss: 57.9700 - val_mse: 57.9700\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 18.3296 - mse: 18.3296 - val_loss: 62.8895 - val_mse: 62.8895\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 18.7229 - mse: 18.7229 - val_loss: 81.0261 - val_mse: 81.0261\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 22.1756 - mse: 22.1756 - val_loss: 60.7643 - val_mse: 60.7643\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 18.9007 - mse: 18.9007 - val_loss: 58.5551 - val_mse: 58.5551\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 21.9060 - mse: 21.9060 - val_loss: 58.7367 - val_mse: 58.7367\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 17.6495 - mse: 17.6495 - val_loss: 70.9577 - val_mse: 70.9577\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 19.9784 - mse: 19.9784 - val_loss: 70.0864 - val_mse: 70.0864\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 17.5779 - mse: 17.5779 - val_loss: 55.6443 - val_mse: 55.6443\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 19.0240 - mse: 19.0240 - val_loss: 63.0326 - val_mse: 63.0326\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 21.6201 - mse: 21.6201 - val_loss: 55.5363 - val_mse: 55.5363\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 13.2921 - mse: 13.2921 - val_loss: 61.3940 - val_mse: 61.3940\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 19.1581 - mse: 19.1581 - val_loss: 58.6137 - val_mse: 58.6137\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 19.9385 - mse: 19.9385 - val_loss: 68.6453 - val_mse: 68.6453\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 15.2276 - mse: 15.2276 - val_loss: 84.9339 - val_mse: 84.9339\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 18.1113 - mse: 18.1113 - val_loss: 58.2234 - val_mse: 58.2234\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 20.6635 - mse: 20.6635 - val_loss: 77.0181 - val_mse: 77.0181\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 20.9184 - mse: 20.9184 - val_loss: 59.3405 - val_mse: 59.3405\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 14.0075 - mse: 14.0075 - val_loss: 66.6618 - val_mse: 66.6618\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 19.9274 - mse: 19.9274 - val_loss: 56.3137 - val_mse: 56.3137\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 20.0696 - mse: 20.0696 - val_loss: 67.0953 - val_mse: 67.0953\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.7451 - mse: 14.7451 - val_loss: 58.8144 - val_mse: 58.8144\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 14.8882 - mse: 14.8882 - val_loss: 90.2201 - val_mse: 90.2201\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 22.3508 - mse: 22.3508 - val_loss: 56.6304 - val_mse: 56.6304\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 17.8392 - mse: 17.8392 - val_loss: 77.0622 - val_mse: 77.0622\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 17.3587 - mse: 17.3587 - val_loss: 68.1030 - val_mse: 68.1030\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 17.1357 - mse: 17.1357 - val_loss: 54.7716 - val_mse: 54.7716\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 21.3431 - mse: 21.3431 - val_loss: 62.4888 - val_mse: 62.4888\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 17.9420 - mse: 17.9420 - val_loss: 61.0967 - val_mse: 61.0967\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 17.7715 - mse: 17.7715 - val_loss: 56.7840 - val_mse: 56.7840\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 13.9856 - mse: 13.9856 - val_loss: 73.5598 - val_mse: 73.5598\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 21.1218 - mse: 21.1218 - val_loss: 56.3455 - val_mse: 56.3455\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 20.2831 - mse: 20.2831 - val_loss: 56.4718 - val_mse: 56.4718\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 16.1096 - mse: 16.1096 - val_loss: 55.6966 - val_mse: 55.6966\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 17.3474 - mse: 17.3474 - val_loss: 60.3598 - val_mse: 60.3598\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 18.0784 - mse: 18.0784 - val_loss: 58.9723 - val_mse: 58.9723\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 17.0375 - mse: 17.0375 - val_loss: 65.3246 - val_mse: 65.3246\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 16.2015 - mse: 16.2015 - val_loss: 57.9344 - val_mse: 57.9344\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 18.6101 - mse: 18.6101 - val_loss: 63.6204 - val_mse: 63.6204\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 15.8497 - mse: 15.8497 - val_loss: 63.7624 - val_mse: 63.7624\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.8993 - mse: 13.8993 - val_loss: 63.5222 - val_mse: 63.5222\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 18.7888 - mse: 18.7888 - val_loss: 73.3720 - val_mse: 73.3720\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14.0599 - mse: 14.0599 - val_loss: 52.5186 - val_mse: 52.5186\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 18.0044 - mse: 18.0044 - val_loss: 73.9351 - val_mse: 73.9351\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.8815 - mse: 14.8815 - val_loss: 54.9508 - val_mse: 54.9508\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 19.8727 - mse: 19.8727 - val_loss: 54.6808 - val_mse: 54.6808\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14.2876 - mse: 14.2876 - val_loss: 87.2870 - val_mse: 87.2870\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 18.9977 - mse: 18.9977 - val_loss: 67.0961 - val_mse: 67.0961\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 15.4587 - mse: 15.4587 - val_loss: 67.4085 - val_mse: 67.4085\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 13.3958 - mse: 13.3958 - val_loss: 89.1857 - val_mse: 89.1857\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 17.6142 - mse: 17.6142 - val_loss: 56.7396 - val_mse: 56.7396\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 14.5856 - mse: 14.5856 - val_loss: 78.1722 - val_mse: 78.1722\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 17.1810 - mse: 17.1810 - val_loss: 58.0494 - val_mse: 58.0494\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 18.0950 - mse: 18.0950 - val_loss: 74.5788 - val_mse: 74.5788\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 15.2417 - mse: 15.2417 - val_loss: 58.4882 - val_mse: 58.4882\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 19.3273 - mse: 19.3273 - val_loss: 57.5546 - val_mse: 57.5546\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 15.1915 - mse: 15.1915 - val_loss: 53.2701 - val_mse: 53.2701\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 17.1333 - mse: 17.1333 - val_loss: 56.0726 - val_mse: 56.0726\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 16.3626 - mse: 16.3626 - val_loss: 54.6438 - val_mse: 54.6438\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 16.1565 - mse: 16.1565 - val_loss: 65.9615 - val_mse: 65.9615\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.3674 - mse: 11.3674 - val_loss: 53.3735 - val_mse: 53.3735\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 17.3515 - mse: 17.3515 - val_loss: 52.4622 - val_mse: 52.4622\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 15.8487 - mse: 15.8487 - val_loss: 56.6105 - val_mse: 56.6105\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.0845 - mse: 14.0845 - val_loss: 57.3672 - val_mse: 57.3672\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 17.8611 - mse: 17.8611 - val_loss: 56.8600 - val_mse: 56.8600\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 16.3611 - mse: 16.3611 - val_loss: 57.5659 - val_mse: 57.5659\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.0336 - mse: 14.0336 - val_loss: 86.2176 - val_mse: 86.2176\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 16.8535 - mse: 16.8535 - val_loss: 63.1033 - val_mse: 63.1033\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 14.9208 - mse: 14.9208 - val_loss: 55.1017 - val_mse: 55.1017\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 15.0160 - mse: 15.0160 - val_loss: 74.1972 - val_mse: 74.1972\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 13.4205 - mse: 13.4205 - val_loss: 73.0417 - val_mse: 73.0417\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 18.4942 - mse: 18.4942 - val_loss: 62.0481 - val_mse: 62.0481\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.8733 - mse: 14.8733 - val_loss: 60.4011 - val_mse: 60.4011\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 10.7239 - mse: 10.7239 - val_loss: 69.5984 - val_mse: 69.5984\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 16.8361 - mse: 16.8361 - val_loss: 59.2060 - val_mse: 59.2060\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 19.3544 - mse: 19.3544 - val_loss: 50.1260 - val_mse: 50.1260\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11.8341 - mse: 11.8341 - val_loss: 87.9920 - val_mse: 87.9920\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 15.6007 - mse: 15.6007 - val_loss: 56.6377 - val_mse: 56.6377\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 16.1699 - mse: 16.1699 - val_loss: 71.2214 - val_mse: 71.2214\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.4892 - mse: 12.4892 - val_loss: 68.8340 - val_mse: 68.8340\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 19.2401 - mse: 19.2401 - val_loss: 55.5487 - val_mse: 55.5487\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.1225 - mse: 12.1225 - val_loss: 66.2103 - val_mse: 66.2103\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.0377 - mse: 11.0377 - val_loss: 58.6022 - val_mse: 58.6022\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 16.4999 - mse: 16.4999 - val_loss: 60.0318 - val_mse: 60.0318\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 17.4247 - mse: 17.4247 - val_loss: 56.6924 - val_mse: 56.6924\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 18.2441 - mse: 18.2441 - val_loss: 55.7821 - val_mse: 55.7821\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.9331 - mse: 11.9331 - val_loss: 60.3094 - val_mse: 60.3094\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 12.0870 - mse: 12.0870 - val_loss: 59.1979 - val_mse: 59.1979\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 17.3327 - mse: 17.3327 - val_loss: 52.5490 - val_mse: 52.5490\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 14.9306 - mse: 14.9306 - val_loss: 59.7560 - val_mse: 59.7560\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 14.5061 - mse: 14.5061 - val_loss: 72.9689 - val_mse: 72.9689\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 19.8090 - mse: 19.8090 - val_loss: 54.2562 - val_mse: 54.2562\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 9.4623 - mse: 9.4623 - val_loss: 55.5267 - val_mse: 55.5267\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 16.1131 - mse: 16.1131 - val_loss: 52.3128 - val_mse: 52.3128\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 13.4071 - mse: 13.4071 - val_loss: 66.3479 - val_mse: 66.3479\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 15.2793 - mse: 15.2793 - val_loss: 55.8828 - val_mse: 55.8828\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.2155 - mse: 13.2155 - val_loss: 52.3293 - val_mse: 52.3293\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.6456 - mse: 12.6456 - val_loss: 62.7812 - val_mse: 62.7812\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 16.0144 - mse: 16.0144 - val_loss: 79.6008 - val_mse: 79.6008\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.7884 - mse: 13.7884 - val_loss: 75.1944 - val_mse: 75.1944\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 15.3541 - mse: 15.3541 - val_loss: 51.9771 - val_mse: 51.9771\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.1129 - mse: 14.1129 - val_loss: 61.2136 - val_mse: 61.2136\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 14.2582 - mse: 14.2582 - val_loss: 55.3145 - val_mse: 55.3145\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 16.3636 - mse: 16.3636 - val_loss: 76.9566 - val_mse: 76.9566\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 11.0316 - mse: 11.0316 - val_loss: 53.8715 - val_mse: 53.8715\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 15.7853 - mse: 15.7853 - val_loss: 52.3726 - val_mse: 52.3726\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 12.0139 - mse: 12.0139 - val_loss: 54.0469 - val_mse: 54.0469\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.7084 - mse: 13.7084 - val_loss: 57.7170 - val_mse: 57.7170\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.2192 - mse: 12.2192 - val_loss: 65.5872 - val_mse: 65.5872\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.0488 - mse: 13.0488 - val_loss: 67.9601 - val_mse: 67.9601\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.2863 - mse: 12.2863 - val_loss: 69.7315 - val_mse: 69.7315\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.0141 - mse: 15.0141 - val_loss: 53.1410 - val_mse: 53.1410\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 12.4364 - mse: 12.4364 - val_loss: 69.1246 - val_mse: 69.1246\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.5346 - mse: 11.5346 - val_loss: 76.1153 - val_mse: 76.1153\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 16.2220 - mse: 16.2220 - val_loss: 77.4943 - val_mse: 77.4943\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.8581 - mse: 12.8581 - val_loss: 75.4428 - val_mse: 75.4428\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 13.4066 - mse: 13.4066 - val_loss: 68.2480 - val_mse: 68.2480\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 14.3921 - mse: 14.3921 - val_loss: 58.4481 - val_mse: 58.4481\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.2527 - mse: 13.2527 - val_loss: 68.3156 - val_mse: 68.3156\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.6174 - mse: 12.6174 - val_loss: 63.4901 - val_mse: 63.4901\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.1496 - mse: 14.1496 - val_loss: 56.2506 - val_mse: 56.2506\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.4443 - mse: 12.4443 - val_loss: 51.7828 - val_mse: 51.7828\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.4505 - mse: 14.4505 - val_loss: 50.9615 - val_mse: 50.9615\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.3236 - mse: 13.3236 - val_loss: 58.6708 - val_mse: 58.6708\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 9.1673 - mse: 9.1673 - val_loss: 54.8291 - val_mse: 54.8291\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.6900 - mse: 15.6900 - val_loss: 54.8710 - val_mse: 54.8710\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.9715 - mse: 13.9715 - val_loss: 57.9504 - val_mse: 57.9504\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.8944 - mse: 9.8944 - val_loss: 57.1823 - val_mse: 57.1823\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.5740 - mse: 13.5740 - val_loss: 56.1558 - val_mse: 56.1558\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.5507 - mse: 14.5507 - val_loss: 53.5472 - val_mse: 53.5472\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.2469 - mse: 8.2469 - val_loss: 60.7583 - val_mse: 60.7583\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.8520 - mse: 15.8520 - val_loss: 52.9234 - val_mse: 52.9234\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 11.7128 - mse: 11.7128 - val_loss: 54.1046 - val_mse: 54.1046\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.7041 - mse: 11.7041 - val_loss: 92.6378 - val_mse: 92.6378\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.4191 - mse: 14.4191 - val_loss: 53.8958 - val_mse: 53.8958\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 12.5349 - mse: 12.5349 - val_loss: 53.0927 - val_mse: 53.0927\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 10.8845 - mse: 10.8845 - val_loss: 68.7836 - val_mse: 68.7836\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 11.3751 - mse: 11.3751 - val_loss: 57.2523 - val_mse: 57.2523\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.3720 - mse: 14.3720 - val_loss: 61.2406 - val_mse: 61.2406\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.4923 - mse: 13.4923 - val_loss: 56.8906 - val_mse: 56.8906\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.3147 - mse: 11.3147 - val_loss: 75.1375 - val_mse: 75.1375\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.8472 - mse: 9.8472 - val_loss: 55.4496 - val_mse: 55.4496\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.3830 - mse: 10.3830 - val_loss: 73.5471 - val_mse: 73.5471\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.8097 - mse: 12.8097 - val_loss: 71.8920 - val_mse: 71.8920\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 12.5698 - mse: 12.5698 - val_loss: 61.5728 - val_mse: 61.5728\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.7459 - mse: 10.7459 - val_loss: 80.0423 - val_mse: 80.0423\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.2592 - mse: 12.2592 - val_loss: 53.6063 - val_mse: 53.6063\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 13.1379 - mse: 13.1379 - val_loss: 66.1878 - val_mse: 66.1878\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.8670 - mse: 13.8670 - val_loss: 52.0760 - val_mse: 52.0760\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.3879 - mse: 11.3879 - val_loss: 80.9372 - val_mse: 80.9372\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.8256 - mse: 10.8256 - val_loss: 55.0944 - val_mse: 55.0944\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.0141 - mse: 9.0141 - val_loss: 83.1090 - val_mse: 83.1090\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 16.1221 - mse: 16.1221 - val_loss: 53.1731 - val_mse: 53.1731\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.5499 - mse: 12.5499 - val_loss: 54.5704 - val_mse: 54.5704\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.0492 - mse: 12.0492 - val_loss: 52.3815 - val_mse: 52.3815\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.6056 - mse: 9.6056 - val_loss: 53.0388 - val_mse: 53.0388\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.1746 - mse: 14.1746 - val_loss: 58.7755 - val_mse: 58.7755\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 8.6866 - mse: 8.6866 - val_loss: 54.3564 - val_mse: 54.3564\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 15.5701 - mse: 15.5701 - val_loss: 55.9174 - val_mse: 55.9174\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.6261 - mse: 10.6261 - val_loss: 53.1041 - val_mse: 53.1041\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.0672 - mse: 12.0672 - val_loss: 65.2926 - val_mse: 65.2926\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.6485 - mse: 12.6485 - val_loss: 55.5669 - val_mse: 55.5669\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.9391 - mse: 10.9391 - val_loss: 53.9452 - val_mse: 53.9452\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.2548 - mse: 12.2548 - val_loss: 54.6779 - val_mse: 54.6779\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.2018 - mse: 12.2018 - val_loss: 56.0320 - val_mse: 56.0320\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.0712 - mse: 11.0712 - val_loss: 55.2354 - val_mse: 55.2354\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.1878 - mse: 11.1878 - val_loss: 63.0193 - val_mse: 63.0193\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.1090 - mse: 11.1090 - val_loss: 82.8245 - val_mse: 82.8245\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.9127 - mse: 11.9127 - val_loss: 64.1616 - val_mse: 64.1616\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.1170 - mse: 10.1170 - val_loss: 80.8620 - val_mse: 80.8620\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.3342 - mse: 14.3342 - val_loss: 72.0059 - val_mse: 72.0059\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 7.9874 - mse: 7.9874 - val_loss: 59.3218 - val_mse: 59.3218\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 12.2121 - mse: 12.2121 - val_loss: 61.1317 - val_mse: 61.1317\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 12.9901 - mse: 12.9901 - val_loss: 58.4318 - val_mse: 58.4318\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 12.4732 - mse: 12.4732 - val_loss: 59.4506 - val_mse: 59.4506\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.3609 - mse: 9.3609 - val_loss: 87.7156 - val_mse: 87.7156\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.1007 - mse: 11.1007 - val_loss: 57.9929 - val_mse: 57.9929\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.6551 - mse: 12.6551 - val_loss: 57.2602 - val_mse: 57.2602\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.7814 - mse: 7.7814 - val_loss: 57.0441 - val_mse: 57.0441\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.7475 - mse: 13.7475 - val_loss: 54.3191 - val_mse: 54.3191\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.7491 - mse: 9.7491 - val_loss: 54.1618 - val_mse: 54.1618\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.0451 - mse: 12.0451 - val_loss: 53.6817 - val_mse: 53.6817\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9.8279 - mse: 9.8279 - val_loss: 54.7218 - val_mse: 54.7218\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.5400 - mse: 11.5400 - val_loss: 66.3897 - val_mse: 66.3897\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.9785 - mse: 11.9785 - val_loss: 65.1257 - val_mse: 65.1257\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.5887 - mse: 11.5887 - val_loss: 58.1576 - val_mse: 58.1576\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.8495 - mse: 7.8495 - val_loss: 73.9277 - val_mse: 73.9277\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.1352 - mse: 14.1352 - val_loss: 60.5805 - val_mse: 60.5805\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8.3788 - mse: 8.3788 - val_loss: 57.0329 - val_mse: 57.0329\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.6827 - mse: 11.6827 - val_loss: 68.5496 - val_mse: 68.5496\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.9777 - mse: 10.9777 - val_loss: 55.0798 - val_mse: 55.0798\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.5525 - mse: 13.5525 - val_loss: 56.0871 - val_mse: 56.0871\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 8.3182 - mse: 8.3182 - val_loss: 76.6017 - val_mse: 76.6017\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8.4472 - mse: 8.4472 - val_loss: 53.0144 - val_mse: 53.0144\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.6333 - mse: 12.6333 - val_loss: 55.2628 - val_mse: 55.2628\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.7186 - mse: 7.7186 - val_loss: 95.8834 - val_mse: 95.8834\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.7960 - mse: 11.7960 - val_loss: 64.0050 - val_mse: 64.0050\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.4731 - mse: 9.4731 - val_loss: 82.1895 - val_mse: 82.1895\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.8331 - mse: 12.8331 - val_loss: 57.5135 - val_mse: 57.5135\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.7382 - mse: 9.7382 - val_loss: 68.2473 - val_mse: 68.2473\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.0179 - mse: 7.0179 - val_loss: 63.7515 - val_mse: 63.7515\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.5391 - mse: 12.5391 - val_loss: 54.4602 - val_mse: 54.4602\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.7209 - mse: 10.7209 - val_loss: 71.4143 - val_mse: 71.4143\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.7191 - mse: 10.7191 - val_loss: 73.1478 - val_mse: 73.1478\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.1036 - mse: 9.1036 - val_loss: 69.4701 - val_mse: 69.4701\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 12.1879 - mse: 12.1879 - val_loss: 51.8894 - val_mse: 51.8894\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.6103 - mse: 11.6103 - val_loss: 57.5537 - val_mse: 57.5537\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.0177 - mse: 7.0177 - val_loss: 53.2975 - val_mse: 53.2975\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.1949 - mse: 14.1949 - val_loss: 54.1424 - val_mse: 54.1424\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.0598 - mse: 8.0598 - val_loss: 53.8769 - val_mse: 53.8769\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.0644 - mse: 9.0644 - val_loss: 79.2423 - val_mse: 79.2423\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.9836 - mse: 9.9836 - val_loss: 53.2958 - val_mse: 53.2958\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.6112 - mse: 13.6112 - val_loss: 50.4325 - val_mse: 50.4325\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.0689 - mse: 7.0689 - val_loss: 64.2591 - val_mse: 64.2591\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.0049 - mse: 12.0049 - val_loss: 56.1889 - val_mse: 56.1889\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.5569 - mse: 11.5569 - val_loss: 54.9435 - val_mse: 54.9435\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8.4070 - mse: 8.4070 - val_loss: 55.1899 - val_mse: 55.1899\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 10.6970 - mse: 10.6970 - val_loss: 54.7104 - val_mse: 54.7104\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 12.1337 - mse: 12.1337 - val_loss: 54.2481 - val_mse: 54.2481\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 9.6784 - mse: 9.6784 - val_loss: 59.6586 - val_mse: 59.6586\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.3259 - mse: 8.3259 - val_loss: 56.0088 - val_mse: 56.0088\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.4828 - mse: 12.4828 - val_loss: 53.9050 - val_mse: 53.9050\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.2887 - mse: 10.2887 - val_loss: 51.4336 - val_mse: 51.4336\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 10.3320 - mse: 10.3320 - val_loss: 57.3333 - val_mse: 57.3333\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.3479 - mse: 12.3479 - val_loss: 54.0126 - val_mse: 54.0126\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.6848 - mse: 9.6848 - val_loss: 54.9998 - val_mse: 54.9998\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.8231 - mse: 9.8231 - val_loss: 52.8640 - val_mse: 52.8640\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.3854 - mse: 9.3854 - val_loss: 52.4387 - val_mse: 52.4387\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.2033 - mse: 9.2033 - val_loss: 68.3357 - val_mse: 68.3357\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9984 - mse: 11.9984 - val_loss: 52.5584 - val_mse: 52.5584\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 9.4902 - mse: 9.4902 - val_loss: 61.7055 - val_mse: 61.7055\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.7787 - mse: 7.7787 - val_loss: 54.3321 - val_mse: 54.3321\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.2699 - mse: 11.2699 - val_loss: 56.9597 - val_mse: 56.9597\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.0413 - mse: 11.0413 - val_loss: 58.8525 - val_mse: 58.8525\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.1434 - mse: 9.1434 - val_loss: 64.4801 - val_mse: 64.4801\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 7.7588 - mse: 7.7588 - val_loss: 66.6879 - val_mse: 66.6879\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 9.7686 - mse: 9.7686 - val_loss: 51.8130 - val_mse: 51.8130\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.1483 - mse: 10.1483 - val_loss: 55.2485 - val_mse: 55.2485\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.4706 - mse: 9.4706 - val_loss: 51.4746 - val_mse: 51.4746\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.5715 - mse: 9.5715 - val_loss: 70.1156 - val_mse: 70.1156\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.1002 - mse: 10.1002 - val_loss: 55.4005 - val_mse: 55.4005\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.7479 - mse: 10.7479 - val_loss: 56.3041 - val_mse: 56.3041\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.7982 - mse: 7.7982 - val_loss: 55.2437 - val_mse: 55.2437\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8.3695 - mse: 8.3695 - val_loss: 54.7904 - val_mse: 54.7904\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.1692 - mse: 9.1692 - val_loss: 60.5993 - val_mse: 60.5993\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.9347 - mse: 6.9347 - val_loss: 53.7361 - val_mse: 53.7361\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.2143 - mse: 11.2143 - val_loss: 58.3691 - val_mse: 58.3691\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.2329 - mse: 9.2329 - val_loss: 54.9245 - val_mse: 54.9245\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.9478 - mse: 10.9478 - val_loss: 54.3544 - val_mse: 54.3544\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 7.0864 - mse: 7.0864 - val_loss: 66.6254 - val_mse: 66.6254\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.9488 - mse: 9.9488 - val_loss: 62.5948 - val_mse: 62.5948\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.9632 - mse: 9.9632 - val_loss: 53.9015 - val_mse: 53.9015\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.6847 - mse: 8.6847 - val_loss: 63.8427 - val_mse: 63.8427\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.3135 - mse: 8.3135 - val_loss: 67.4148 - val_mse: 67.4148\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 11.2992 - mse: 11.2992 - val_loss: 57.5367 - val_mse: 57.5367\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 7.4694 - mse: 7.4694 - val_loss: 52.3897 - val_mse: 52.3897\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.9045 - mse: 9.9045 - val_loss: 54.0802 - val_mse: 54.0802\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.4669 - mse: 10.4669 - val_loss: 83.7915 - val_mse: 83.7915\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.1196 - mse: 8.1196 - val_loss: 54.4492 - val_mse: 54.4492\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.6773 - mse: 8.6773 - val_loss: 60.4228 - val_mse: 60.4228\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5042 - mse: 8.5042 - val_loss: 52.7685 - val_mse: 52.7685\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.8769 - mse: 9.8769 - val_loss: 52.9357 - val_mse: 52.9357\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.9309 - mse: 8.9309 - val_loss: 52.1777 - val_mse: 52.1777\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.0546 - mse: 12.0546 - val_loss: 52.4481 - val_mse: 52.4481\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.5198 - mse: 9.5198 - val_loss: 57.3392 - val_mse: 57.3392\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.6912 - mse: 6.6912 - val_loss: 58.8796 - val_mse: 58.8796\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.6984 - mse: 11.6984 - val_loss: 56.4682 - val_mse: 56.4682\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.1838 - mse: 7.1838 - val_loss: 84.6690 - val_mse: 84.6690\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.8299 - mse: 9.8299 - val_loss: 63.8879 - val_mse: 63.8879\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.6166 - mse: 7.6166 - val_loss: 57.4905 - val_mse: 57.4905\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.1679 - mse: 10.1679 - val_loss: 57.5456 - val_mse: 57.5456\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.3365 - mse: 9.3365 - val_loss: 56.5135 - val_mse: 56.5135\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.7046 - mse: 9.7046 - val_loss: 67.2722 - val_mse: 67.2722\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.2497 - mse: 8.2497 - val_loss: 71.4206 - val_mse: 71.4206\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.0309 - mse: 11.0309 - val_loss: 61.5209 - val_mse: 61.5209\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9.7853 - mse: 9.7853 - val_loss: 58.1443 - val_mse: 58.1443\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 6.4966 - mse: 6.4966 - val_loss: 54.6511 - val_mse: 54.6511\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.9743 - mse: 10.9743 - val_loss: 58.4197 - val_mse: 58.4197\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.4589 - mse: 6.4589 - val_loss: 57.3789 - val_mse: 57.3789\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.1758 - mse: 9.1758 - val_loss: 57.6852 - val_mse: 57.6852\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.3565 - mse: 10.3565 - val_loss: 67.2018 - val_mse: 67.2018\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.0020 - mse: 7.0020 - val_loss: 54.1893 - val_mse: 54.1893\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.9053 - mse: 10.9053 - val_loss: 63.9882 - val_mse: 63.9882\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.6327 - mse: 8.6327 - val_loss: 53.6512 - val_mse: 53.6512\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 11.7623 - mse: 11.7623 - val_loss: 53.3206 - val_mse: 53.3206\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.1531 - mse: 5.1531 - val_loss: 53.6601 - val_mse: 53.6601\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.9328 - mse: 10.9328 - val_loss: 56.3700 - val_mse: 56.3700\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.2157 - mse: 8.2157 - val_loss: 60.3350 - val_mse: 60.3350\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.6102 - mse: 10.6102 - val_loss: 53.6466 - val_mse: 53.6466\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.3368 - mse: 7.3368 - val_loss: 61.9114 - val_mse: 61.9114\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.8318 - mse: 10.8318 - val_loss: 58.4336 - val_mse: 58.4336\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.0077 - mse: 7.0077 - val_loss: 57.2239 - val_mse: 57.2239\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.8960 - mse: 9.8960 - val_loss: 64.5995 - val_mse: 64.5995\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.9463 - mse: 5.9463 - val_loss: 54.6588 - val_mse: 54.6588\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.2827 - mse: 10.2827 - val_loss: 58.2102 - val_mse: 58.2102\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.7963 - mse: 8.7963 - val_loss: 53.6490 - val_mse: 53.6490\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.8897 - mse: 7.8897 - val_loss: 62.5508 - val_mse: 62.5508\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.3699 - mse: 8.3699 - val_loss: 54.8587 - val_mse: 54.8587\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.7553 - mse: 9.7553 - val_loss: 52.8594 - val_mse: 52.8594\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.9891 - mse: 9.9891 - val_loss: 53.4291 - val_mse: 53.4291\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 6.0363 - mse: 6.0363 - val_loss: 70.3908 - val_mse: 70.3908\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.9853 - mse: 9.9853 - val_loss: 58.3796 - val_mse: 58.3796\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.6879 - mse: 7.6879 - val_loss: 73.1223 - val_mse: 73.1223\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 10.3124 - mse: 10.3124 - val_loss: 58.2459 - val_mse: 58.2459\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 7.8577 - mse: 7.8577 - val_loss: 71.2824 - val_mse: 71.2824\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 7.7082 - mse: 7.7082 - val_loss: 52.4243 - val_mse: 52.4243\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.3820 - mse: 10.3820 - val_loss: 59.2631 - val_mse: 59.2631\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.5553 - mse: 7.5553 - val_loss: 52.4189 - val_mse: 52.4189\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 9.3235 - mse: 9.3235 - val_loss: 51.9912 - val_mse: 51.9912\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.5344 - mse: 9.5344 - val_loss: 54.2894 - val_mse: 54.2894\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 7.3572 - mse: 7.3572 - val_loss: 56.2651 - val_mse: 56.2651\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.9675 - mse: 7.9675 - val_loss: 54.1980 - val_mse: 54.1980\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.2784 - mse: 9.2784 - val_loss: 58.2805 - val_mse: 58.2805\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.9107 - mse: 6.9107 - val_loss: 54.8507 - val_mse: 54.8507\n",
      "Epoch 1/400\n",
      "12/12 [==============================] - 4s 73ms/step - loss: 1265.1562 - mse: 1265.1562 - val_loss: 674.7269 - val_mse: 674.7269\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 304.6584 - mse: 304.6584 - val_loss: 207.3302 - val_mse: 207.3302\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 170.7169 - mse: 170.7169 - val_loss: 191.0285 - val_mse: 191.0285\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 152.2390 - mse: 152.2390 - val_loss: 176.6979 - val_mse: 176.6979\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 148.0752 - mse: 148.0752 - val_loss: 165.5746 - val_mse: 165.5746\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 132.4603 - mse: 132.4603 - val_loss: 157.5170 - val_mse: 157.5170\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 127.8251 - mse: 127.8251 - val_loss: 147.5027 - val_mse: 147.5027\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 120.6824 - mse: 120.6824 - val_loss: 134.3355 - val_mse: 134.3355\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 113.6724 - mse: 113.6724 - val_loss: 128.8604 - val_mse: 128.8604\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 105.6934 - mse: 105.6934 - val_loss: 138.4377 - val_mse: 138.4377\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 100.6986 - mse: 100.6986 - val_loss: 113.0223 - val_mse: 113.0223\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 99.8943 - mse: 99.8943 - val_loss: 107.8297 - val_mse: 107.8297\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 91.3360 - mse: 91.3360 - val_loss: 105.8541 - val_mse: 105.8541\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 83.3573 - mse: 83.3573 - val_loss: 143.9413 - val_mse: 143.9413\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 81.1204 - mse: 81.1204 - val_loss: 88.0400 - val_mse: 88.0400\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 73.2495 - mse: 73.2495 - val_loss: 102.5990 - val_mse: 102.5990\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 76.5507 - mse: 76.5507 - val_loss: 80.6412 - val_mse: 80.6412\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 65.2176 - mse: 65.2176 - val_loss: 82.6630 - val_mse: 82.6630\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 65.7714 - mse: 65.7714 - val_loss: 73.5331 - val_mse: 73.5331\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 59.2155 - mse: 59.2155 - val_loss: 59.8368 - val_mse: 59.8368\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 59.3277 - mse: 59.3277 - val_loss: 60.3924 - val_mse: 60.3924\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 47.9288 - mse: 47.9288 - val_loss: 58.1858 - val_mse: 58.1858\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 55.1556 - mse: 55.1556 - val_loss: 50.0061 - val_mse: 50.0061\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 47.5516 - mse: 47.5516 - val_loss: 59.3153 - val_mse: 59.3153\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 43.2203 - mse: 43.2203 - val_loss: 43.3183 - val_mse: 43.3183\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 48.5196 - mse: 48.5196 - val_loss: 50.2715 - val_mse: 50.2715\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 44.6796 - mse: 44.6796 - val_loss: 42.7745 - val_mse: 42.7745\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 40.5136 - mse: 40.5136 - val_loss: 44.0343 - val_mse: 44.0343\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 42.7686 - mse: 42.7686 - val_loss: 43.3056 - val_mse: 43.3056\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 38.5807 - mse: 38.5807 - val_loss: 43.5435 - val_mse: 43.5435\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 38.1797 - mse: 38.1797 - val_loss: 39.0052 - val_mse: 39.0052\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 35.2679 - mse: 35.2679 - val_loss: 45.4149 - val_mse: 45.4149\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 37.6636 - mse: 37.6636 - val_loss: 53.1237 - val_mse: 53.1237\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 41.3623 - mse: 41.3623 - val_loss: 50.8440 - val_mse: 50.8440\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 44ms/step - loss: 38.5184 - mse: 38.5184 - val_loss: 36.1010 - val_mse: 36.1010\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 36.7491 - mse: 36.7491 - val_loss: 33.3543 - val_mse: 33.3543\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 28.4196 - mse: 28.4196 - val_loss: 34.0992 - val_mse: 34.0992\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 39.0226 - mse: 39.0226 - val_loss: 31.8718 - val_mse: 31.8718\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 33.4063 - mse: 33.4063 - val_loss: 30.8734 - val_mse: 30.8734\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 34.5988 - mse: 34.5988 - val_loss: 32.4430 - val_mse: 32.4430\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 32.7931 - mse: 32.7931 - val_loss: 32.4964 - val_mse: 32.4964\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 28.8004 - mse: 28.8004 - val_loss: 40.1544 - val_mse: 40.1544\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 31.4276 - mse: 31.4276 - val_loss: 38.5136 - val_mse: 38.5136\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 33.7695 - mse: 33.7695 - val_loss: 29.8383 - val_mse: 29.8383\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 34.3870 - mse: 34.3870 - val_loss: 51.8490 - val_mse: 51.8490\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 28.1706 - mse: 28.1706 - val_loss: 58.7360 - val_mse: 58.7360\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 30.2971 - mse: 30.2971 - val_loss: 32.3257 - val_mse: 32.3257\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 35.0529 - mse: 35.0529 - val_loss: 29.3885 - val_mse: 29.3885\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 24.7503 - mse: 24.7503 - val_loss: 43.1992 - val_mse: 43.1992\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 30.0229 - mse: 30.0229 - val_loss: 34.9591 - val_mse: 34.9591\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 27.4514 - mse: 27.4514 - val_loss: 35.5395 - val_mse: 35.5395\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 32.3681 - mse: 32.3681 - val_loss: 37.1955 - val_mse: 37.1955\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 24.9485 - mse: 24.9485 - val_loss: 43.5550 - val_mse: 43.5550\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 31.3238 - mse: 31.3238 - val_loss: 41.1460 - val_mse: 41.1460\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 29.2876 - mse: 29.2876 - val_loss: 30.4738 - val_mse: 30.4738\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 23.2382 - mse: 23.2382 - val_loss: 34.8256 - val_mse: 34.8256\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.5385 - mse: 25.5385 - val_loss: 34.6709 - val_mse: 34.6709\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 30.0597 - mse: 30.0597 - val_loss: 41.0138 - val_mse: 41.0138\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 31.8170 - mse: 31.8170 - val_loss: 33.4047 - val_mse: 33.4047\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 21.8543 - mse: 21.8543 - val_loss: 26.9420 - val_mse: 26.9420\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 26.5944 - mse: 26.5944 - val_loss: 32.8250 - val_mse: 32.8250\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 26.8245 - mse: 26.8245 - val_loss: 37.3671 - val_mse: 37.3671\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 29.3038 - mse: 29.3038 - val_loss: 35.4362 - val_mse: 35.4362\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 27.2036 - mse: 27.2036 - val_loss: 32.7021 - val_mse: 32.7021\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 27.1605 - mse: 27.1605 - val_loss: 34.9800 - val_mse: 34.9800\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.5077 - mse: 25.5077 - val_loss: 32.9281 - val_mse: 32.9281\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.8170 - mse: 25.8170 - val_loss: 29.5538 - val_mse: 29.5538\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 26.0275 - mse: 26.0275 - val_loss: 30.1914 - val_mse: 30.1914\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 19.5302 - mse: 19.5302 - val_loss: 34.9988 - val_mse: 34.9988\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 31.2009 - mse: 31.2009 - val_loss: 26.0875 - val_mse: 26.0875\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 22.3796 - mse: 22.3796 - val_loss: 38.5674 - val_mse: 38.5674\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 31.0934 - mse: 31.0934 - val_loss: 28.0206 - val_mse: 28.0206\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 18.0194 - mse: 18.0194 - val_loss: 30.7418 - val_mse: 30.7418\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 26.5338 - mse: 26.5338 - val_loss: 25.3850 - val_mse: 25.3850\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 19.0520 - mse: 19.0520 - val_loss: 30.5165 - val_mse: 30.5165\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 25.9724 - mse: 25.9724 - val_loss: 26.3535 - val_mse: 26.3535\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 23.6994 - mse: 23.6994 - val_loss: 43.0801 - val_mse: 43.0801\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 26.4984 - mse: 26.4984 - val_loss: 31.5754 - val_mse: 31.5754\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 22.2135 - mse: 22.2135 - val_loss: 54.7233 - val_mse: 54.7233\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 22.8028 - mse: 22.8028 - val_loss: 34.1394 - val_mse: 34.1394\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 21.8156 - mse: 21.8156 - val_loss: 29.7347 - val_mse: 29.7347\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 22.8659 - mse: 22.8659 - val_loss: 28.3717 - val_mse: 28.3717\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.1196 - mse: 25.1196 - val_loss: 29.4847 - val_mse: 29.4847\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 23.8285 - mse: 23.8285 - val_loss: 24.7079 - val_mse: 24.7079\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.6321 - mse: 17.6321 - val_loss: 40.5782 - val_mse: 40.5782\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 26.0525 - mse: 26.0525 - val_loss: 48.8362 - val_mse: 48.8362\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19.9299 - mse: 19.9299 - val_loss: 29.2865 - val_mse: 29.2865\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 27.9356 - mse: 27.9356 - val_loss: 36.4536 - val_mse: 36.4536\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.2363 - mse: 20.2363 - val_loss: 28.4768 - val_mse: 28.4768\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25.7910 - mse: 25.7910 - val_loss: 25.7064 - val_mse: 25.7064\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 20.5126 - mse: 20.5126 - val_loss: 27.4577 - val_mse: 27.4577\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 18.9903 - mse: 18.9903 - val_loss: 25.4057 - val_mse: 25.4057\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 25.8403 - mse: 25.8403 - val_loss: 26.5763 - val_mse: 26.5763\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 18.3073 - mse: 18.3073 - val_loss: 48.6087 - val_mse: 48.6087\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 22.3512 - mse: 22.3512 - val_loss: 25.7579 - val_mse: 25.7579\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 18.8941 - mse: 18.8941 - val_loss: 55.0900 - val_mse: 55.0900\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 25.5015 - mse: 25.5015 - val_loss: 27.1661 - val_mse: 27.1661\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 22.8343 - mse: 22.8343 - val_loss: 35.4177 - val_mse: 35.4177\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 22.1888 - mse: 22.1888 - val_loss: 28.0071 - val_mse: 28.0071\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 18.2344 - mse: 18.2344 - val_loss: 37.3158 - val_mse: 37.3158\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 23.8994 - mse: 23.8994 - val_loss: 34.4591 - val_mse: 34.4591\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 18.4526 - mse: 18.4526 - val_loss: 57.1356 - val_mse: 57.1356\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 18.2369 - mse: 18.2369 - val_loss: 26.6292 - val_mse: 26.6292\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 22.5127 - mse: 22.5127 - val_loss: 40.5801 - val_mse: 40.5801\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 16.7796 - mse: 16.7796 - val_loss: 49.0389 - val_mse: 49.0389\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 22.7297 - mse: 22.7297 - val_loss: 35.2995 - val_mse: 35.2995\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 23.8102 - mse: 23.8102 - val_loss: 24.8545 - val_mse: 24.8545\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 20.7560 - mse: 20.7560 - val_loss: 24.6878 - val_mse: 24.6878\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 18.9855 - mse: 18.9855 - val_loss: 38.0901 - val_mse: 38.0901\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.0339 - mse: 17.0339 - val_loss: 34.6458 - val_mse: 34.6458\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 24.7377 - mse: 24.7377 - val_loss: 27.2383 - val_mse: 27.2383\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 15.9168 - mse: 15.9168 - val_loss: 42.1701 - val_mse: 42.1701\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.1070 - mse: 20.1070 - val_loss: 74.2890 - val_mse: 74.2890\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 19.9336 - mse: 19.9336 - val_loss: 28.9094 - val_mse: 28.9094\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 21.7025 - mse: 21.7025 - val_loss: 35.0601 - val_mse: 35.0601\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.0129 - mse: 14.0129 - val_loss: 34.1982 - val_mse: 34.1982\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 21.1013 - mse: 21.1013 - val_loss: 52.6042 - val_mse: 52.6042\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 21.9743 - mse: 21.9743 - val_loss: 37.0345 - val_mse: 37.0345\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 18.8862 - mse: 18.8862 - val_loss: 40.4285 - val_mse: 40.4285\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 19.5858 - mse: 19.5858 - val_loss: 54.6337 - val_mse: 54.6337\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 17.1486 - mse: 17.1486 - val_loss: 28.1599 - val_mse: 28.1599\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 20.9029 - mse: 20.9029 - val_loss: 23.8235 - val_mse: 23.8235\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 20.1977 - mse: 20.1977 - val_loss: 38.5386 - val_mse: 38.5386\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.0183 - mse: 16.0183 - val_loss: 66.2417 - val_mse: 66.2417\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 20.4256 - mse: 20.4256 - val_loss: 27.8932 - val_mse: 27.8932\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 23.2261 - mse: 23.2261 - val_loss: 28.2893 - val_mse: 28.2893\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.2580 - mse: 15.2580 - val_loss: 29.7150 - val_mse: 29.7150\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.4748 - mse: 19.4748 - val_loss: 40.4288 - val_mse: 40.4288\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 20.7993 - mse: 20.7993 - val_loss: 27.7333 - val_mse: 27.7333\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 17.7818 - mse: 17.7818 - val_loss: 56.5363 - val_mse: 56.5363\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 21.7985 - mse: 21.7985 - val_loss: 25.2993 - val_mse: 25.2993\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 17.8584 - mse: 17.8584 - val_loss: 28.0286 - val_mse: 28.0286\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 18.3131 - mse: 18.3131 - val_loss: 31.3312 - val_mse: 31.3312\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 19.2888 - mse: 19.2888 - val_loss: 26.9366 - val_mse: 26.9366\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 21.7272 - mse: 21.7272 - val_loss: 28.1487 - val_mse: 28.1487\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 15.8189 - mse: 15.8189 - val_loss: 34.1882 - val_mse: 34.1882\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 16.4893 - mse: 16.4893 - val_loss: 28.7511 - val_mse: 28.7511\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.8803 - mse: 19.8803 - val_loss: 25.2696 - val_mse: 25.2696\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.4330 - mse: 19.4330 - val_loss: 39.8731 - val_mse: 39.8731\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.5433 - mse: 17.5433 - val_loss: 27.7237 - val_mse: 27.7237\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19.7768 - mse: 19.7768 - val_loss: 36.9292 - val_mse: 36.9292\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.3086 - mse: 14.3086 - val_loss: 27.2399 - val_mse: 27.2399\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.5830 - mse: 16.5830 - val_loss: 27.8504 - val_mse: 27.8504\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19.0285 - mse: 19.0285 - val_loss: 24.2849 - val_mse: 24.2849\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.2241 - mse: 19.2241 - val_loss: 24.1832 - val_mse: 24.1832\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.0934 - mse: 14.0934 - val_loss: 23.7519 - val_mse: 23.7519\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 20.1741 - mse: 20.1741 - val_loss: 24.2844 - val_mse: 24.2844\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.4135 - mse: 16.4135 - val_loss: 24.5631 - val_mse: 24.5631\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 17.1855 - mse: 17.1855 - val_loss: 26.7479 - val_mse: 26.7479\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.9438 - mse: 16.9438 - val_loss: 37.2109 - val_mse: 37.2109\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.0224 - mse: 22.0224 - val_loss: 38.2891 - val_mse: 38.2891\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.5387 - mse: 13.5387 - val_loss: 25.4784 - val_mse: 25.4784\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19.2851 - mse: 19.2851 - val_loss: 26.6613 - val_mse: 26.6613\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 20.0933 - mse: 20.0933 - val_loss: 37.3669 - val_mse: 37.3669\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.6742 - mse: 17.6742 - val_loss: 24.9268 - val_mse: 24.9268\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 16.9114 - mse: 16.9114 - val_loss: 32.1152 - val_mse: 32.1152\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 18.8698 - mse: 18.8698 - val_loss: 31.2140 - val_mse: 31.2140\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.0502 - mse: 11.0502 - val_loss: 26.1541 - val_mse: 26.1541\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 18.0508 - mse: 18.0508 - val_loss: 32.9370 - val_mse: 32.9370\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.5005 - mse: 19.5005 - val_loss: 27.8392 - val_mse: 27.8392\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.8756 - mse: 18.8756 - val_loss: 24.6157 - val_mse: 24.6157\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.3208 - mse: 17.3208 - val_loss: 24.1707 - val_mse: 24.1707\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.1738 - mse: 15.1738 - val_loss: 26.6168 - val_mse: 26.6168\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 18.3260 - mse: 18.3260 - val_loss: 40.2664 - val_mse: 40.2664\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 19.6248 - mse: 19.6248 - val_loss: 26.1475 - val_mse: 26.1475\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.5029 - mse: 18.5029 - val_loss: 28.9664 - val_mse: 28.9664\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.5287 - mse: 13.5287 - val_loss: 30.6925 - val_mse: 30.6925\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19.2219 - mse: 19.2219 - val_loss: 28.3130 - val_mse: 28.3130\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 17.4844 - mse: 17.4844 - val_loss: 23.0496 - val_mse: 23.0496\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.3751 - mse: 15.3751 - val_loss: 22.9572 - val_mse: 22.9572\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.0318 - mse: 12.0318 - val_loss: 58.5978 - val_mse: 58.5978\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.7911 - mse: 19.7911 - val_loss: 25.8855 - val_mse: 25.8855\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.8953 - mse: 17.8953 - val_loss: 30.1864 - val_mse: 30.1864\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.9773 - mse: 12.9773 - val_loss: 34.5571 - val_mse: 34.5571\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 19.7829 - mse: 19.7829 - val_loss: 27.4413 - val_mse: 27.4413\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 15.0826 - mse: 15.0826 - val_loss: 42.1524 - val_mse: 42.1524\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 18.4861 - mse: 18.4861 - val_loss: 27.8925 - val_mse: 27.8925\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.1955 - mse: 13.1955 - val_loss: 33.5199 - val_mse: 33.5199\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 15.7688 - mse: 15.7688 - val_loss: 27.7171 - val_mse: 27.7171\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.8947 - mse: 16.8947 - val_loss: 40.7150 - val_mse: 40.7150\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.0786 - mse: 15.0786 - val_loss: 24.8138 - val_mse: 24.8138\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.0917 - mse: 16.0917 - val_loss: 25.8900 - val_mse: 25.8900\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 17.7670 - mse: 17.7670 - val_loss: 24.0231 - val_mse: 24.0231\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.0606 - mse: 10.0606 - val_loss: 24.7913 - val_mse: 24.7913\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 20.1235 - mse: 20.1235 - val_loss: 25.2014 - val_mse: 25.2014\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.6208 - mse: 12.6208 - val_loss: 25.2932 - val_mse: 25.2932\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 18.6305 - mse: 18.6305 - val_loss: 33.0697 - val_mse: 33.0697\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 17.0258 - mse: 17.0258 - val_loss: 24.5979 - val_mse: 24.5979\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 10.0606 - mse: 10.0606 - val_loss: 24.4838 - val_mse: 24.4838\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.8448 - mse: 18.8448 - val_loss: 24.6462 - val_mse: 24.6462\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.8078 - mse: 14.8078 - val_loss: 29.8256 - val_mse: 29.8256\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.7548 - mse: 13.7548 - val_loss: 31.0574 - val_mse: 31.0574\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.4535 - mse: 16.4535 - val_loss: 50.2880 - val_mse: 50.2880\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 13.8296 - mse: 13.8296 - val_loss: 23.7880 - val_mse: 23.7880\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 17.4996 - mse: 17.4996 - val_loss: 33.8526 - val_mse: 33.8526\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.0420 - mse: 11.0420 - val_loss: 24.7205 - val_mse: 24.7205\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 21.1302 - mse: 21.1302 - val_loss: 25.3827 - val_mse: 25.3827\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.4339 - mse: 16.4339 - val_loss: 30.3701 - val_mse: 30.3701\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 11.6882 - mse: 11.6882 - val_loss: 32.2342 - val_mse: 32.2342\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.6459 - mse: 16.6459 - val_loss: 31.8153 - val_mse: 31.8153\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.8078 - mse: 15.8078 - val_loss: 31.4740 - val_mse: 31.4740\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 16.2689 - mse: 16.2689 - val_loss: 26.5055 - val_mse: 26.5055\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.4945 - mse: 12.4945 - val_loss: 41.6302 - val_mse: 41.6302\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 15.1897 - mse: 15.1897 - val_loss: 25.1058 - val_mse: 25.1058\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 18.6867 - mse: 18.6867 - val_loss: 34.7281 - val_mse: 34.7281\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.5928 - mse: 11.5928 - val_loss: 34.9426 - val_mse: 34.9426\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.7350 - mse: 18.7350 - val_loss: 25.8861 - val_mse: 25.8861\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.3887 - mse: 13.3887 - val_loss: 27.5332 - val_mse: 27.5332\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.8493 - mse: 15.8493 - val_loss: 26.8735 - val_mse: 26.8735\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 19.0431 - mse: 19.0431 - val_loss: 24.0929 - val_mse: 24.0929\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.5893 - mse: 9.5893 - val_loss: 47.9867 - val_mse: 47.9867\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 18.6403 - mse: 18.6403 - val_loss: 25.3451 - val_mse: 25.3451\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 13.3636 - mse: 13.3636 - val_loss: 28.7122 - val_mse: 28.7122\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 14.2718 - mse: 14.2718 - val_loss: 44.9949 - val_mse: 44.9949\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 16.3225 - mse: 16.3225 - val_loss: 31.3334 - val_mse: 31.3334\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 15.3917 - mse: 15.3917 - val_loss: 34.0380 - val_mse: 34.0380\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.5574 - mse: 14.5574 - val_loss: 37.3811 - val_mse: 37.3811\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.5077 - mse: 14.5077 - val_loss: 44.9811 - val_mse: 44.9811\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.8029 - mse: 14.8029 - val_loss: 37.2733 - val_mse: 37.2733\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.7788 - mse: 13.7788 - val_loss: 27.7159 - val_mse: 27.7159\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.4507 - mse: 18.4507 - val_loss: 25.9523 - val_mse: 25.9523\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.1688 - mse: 12.1688 - val_loss: 35.2775 - val_mse: 35.2775\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 15.2498 - mse: 15.2498 - val_loss: 24.9459 - val_mse: 24.9459\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 15.8831 - mse: 15.8831 - val_loss: 30.2634 - val_mse: 30.2634\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.5017 - mse: 13.5017 - val_loss: 26.1066 - val_mse: 26.1066\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.0167 - mse: 18.0167 - val_loss: 28.3668 - val_mse: 28.3668\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14.2096 - mse: 14.2096 - val_loss: 46.3860 - val_mse: 46.3860\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.3527 - mse: 11.3527 - val_loss: 24.3529 - val_mse: 24.3529\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.4218 - mse: 14.4218 - val_loss: 27.8229 - val_mse: 27.8229\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 17.1049 - mse: 17.1049 - val_loss: 26.7553 - val_mse: 26.7553\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.7551 - mse: 13.7551 - val_loss: 28.2513 - val_mse: 28.2513\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.2875 - mse: 13.2875 - val_loss: 37.9941 - val_mse: 37.9941\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.9595 - mse: 13.9595 - val_loss: 32.0928 - val_mse: 32.0928\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.9046 - mse: 14.9046 - val_loss: 33.1264 - val_mse: 33.1264\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 16.0664 - mse: 16.0664 - val_loss: 35.6879 - val_mse: 35.6879\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.0345 - mse: 11.0345 - val_loss: 50.8213 - val_mse: 50.8213\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 14.0059 - mse: 14.0059 - val_loss: 40.2761 - val_mse: 40.2761\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 15.9981 - mse: 15.9981 - val_loss: 43.7027 - val_mse: 43.7027\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.0947 - mse: 13.0947 - val_loss: 42.1586 - val_mse: 42.1586\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 14.7174 - mse: 14.7174 - val_loss: 41.6186 - val_mse: 41.6186\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.0368 - mse: 13.0368 - val_loss: 28.4290 - val_mse: 28.4290\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 12.7091 - mse: 12.7091 - val_loss: 44.7854 - val_mse: 44.7854\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.3796 - mse: 12.3796 - val_loss: 30.4960 - val_mse: 30.4960\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.0644 - mse: 17.0644 - val_loss: 22.7692 - val_mse: 22.7692\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.6771 - mse: 11.6771 - val_loss: 38.9519 - val_mse: 38.9519\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.1328 - mse: 12.1328 - val_loss: 50.1586 - val_mse: 50.1586\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.4886 - mse: 14.4886 - val_loss: 30.8873 - val_mse: 30.8873\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.0167 - mse: 16.0167 - val_loss: 35.2108 - val_mse: 35.2108\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.6737 - mse: 13.6737 - val_loss: 36.5217 - val_mse: 36.5217\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.9490 - mse: 13.9490 - val_loss: 33.9199 - val_mse: 33.9199\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.6751 - mse: 13.6751 - val_loss: 26.7960 - val_mse: 26.7960\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.3090 - mse: 14.3090 - val_loss: 28.5419 - val_mse: 28.5419\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.6851 - mse: 13.6851 - val_loss: 32.6847 - val_mse: 32.6847\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.0335 - mse: 11.0335 - val_loss: 27.9115 - val_mse: 27.9115\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.9905 - mse: 14.9905 - val_loss: 27.1378 - val_mse: 27.1378\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.1501 - mse: 9.1501 - val_loss: 30.4905 - val_mse: 30.4905\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 17.7215 - mse: 17.7215 - val_loss: 24.5448 - val_mse: 24.5448\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.8458 - mse: 9.8458 - val_loss: 30.8746 - val_mse: 30.8746\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 15.2707 - mse: 15.2707 - val_loss: 28.3681 - val_mse: 28.3681\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.1389 - mse: 10.1389 - val_loss: 51.2786 - val_mse: 51.2786\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 16.0070 - mse: 16.0070 - val_loss: 28.5587 - val_mse: 28.5587\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.4415 - mse: 13.4415 - val_loss: 37.4606 - val_mse: 37.4606\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.8640 - mse: 10.8640 - val_loss: 28.1279 - val_mse: 28.1279\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.6123 - mse: 13.6123 - val_loss: 23.6823 - val_mse: 23.6823\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 17.1605 - mse: 17.1605 - val_loss: 27.6039 - val_mse: 27.6039\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.2999 - mse: 10.2999 - val_loss: 36.6650 - val_mse: 36.6650\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 15.5224 - mse: 15.5224 - val_loss: 28.9701 - val_mse: 28.9701\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.2899 - mse: 11.2899 - val_loss: 29.4317 - val_mse: 29.4317\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 15.6720 - mse: 15.6720 - val_loss: 27.4508 - val_mse: 27.4508\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.9064 - mse: 10.9064 - val_loss: 49.8855 - val_mse: 49.8855\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.0856 - mse: 13.0856 - val_loss: 28.8757 - val_mse: 28.8757\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.7628 - mse: 11.7628 - val_loss: 35.8636 - val_mse: 35.8636\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.6015 - mse: 12.6015 - val_loss: 49.2492 - val_mse: 49.2492\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 15.7890 - mse: 15.7890 - val_loss: 38.8807 - val_mse: 38.8807\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 12.3796 - mse: 12.3796 - val_loss: 23.7360 - val_mse: 23.7360\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 12.5424 - mse: 12.5424 - val_loss: 35.8415 - val_mse: 35.8415\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11.3581 - mse: 11.3581 - val_loss: 34.8067 - val_mse: 34.8067\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.1100 - mse: 13.1100 - val_loss: 27.7333 - val_mse: 27.7333\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.9831 - mse: 10.9831 - val_loss: 28.8938 - val_mse: 28.8938\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.8537 - mse: 16.8537 - val_loss: 29.7560 - val_mse: 29.7560\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.4774 - mse: 9.4774 - val_loss: 34.2370 - val_mse: 34.2370\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.9222 - mse: 9.9222 - val_loss: 27.9803 - val_mse: 27.9803\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 15.4268 - mse: 15.4268 - val_loss: 25.6708 - val_mse: 25.6708\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 12.8101 - mse: 12.8101 - val_loss: 40.1885 - val_mse: 40.1885\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.1613 - mse: 12.1613 - val_loss: 26.2525 - val_mse: 26.2525\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 13.9357 - mse: 13.9357 - val_loss: 32.5061 - val_mse: 32.5061\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.5605 - mse: 12.5605 - val_loss: 36.7414 - val_mse: 36.7414\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.6007 - mse: 12.6007 - val_loss: 29.2443 - val_mse: 29.2443\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.4190 - mse: 13.4190 - val_loss: 28.3970 - val_mse: 28.3970\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.8733 - mse: 13.8733 - val_loss: 24.3033 - val_mse: 24.3033\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 6.6632 - mse: 6.6632 - val_loss: 31.3312 - val_mse: 31.3312\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.6819 - mse: 14.6819 - val_loss: 49.8427 - val_mse: 49.8427\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.3020 - mse: 12.3020 - val_loss: 27.6706 - val_mse: 27.6706\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.1197 - mse: 15.1197 - val_loss: 25.4530 - val_mse: 25.4530\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.0287 - mse: 13.0287 - val_loss: 25.9171 - val_mse: 25.9171\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12.0827 - mse: 12.0827 - val_loss: 26.8946 - val_mse: 26.8946\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.1924 - mse: 10.1924 - val_loss: 24.0666 - val_mse: 24.0666\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.6910 - mse: 12.6910 - val_loss: 25.1383 - val_mse: 25.1383\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.0068 - mse: 17.0068 - val_loss: 27.1114 - val_mse: 27.1114\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.9508 - mse: 7.9508 - val_loss: 23.7825 - val_mse: 23.7825\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.9768 - mse: 11.9768 - val_loss: 26.7543 - val_mse: 26.7543\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.6903 - mse: 11.6903 - val_loss: 30.1701 - val_mse: 30.1701\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.6821 - mse: 12.6821 - val_loss: 30.1125 - val_mse: 30.1125\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.5641 - mse: 11.5641 - val_loss: 27.0665 - val_mse: 27.0665\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 11.3306 - mse: 11.3306 - val_loss: 30.0801 - val_mse: 30.0801\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.1255 - mse: 12.1255 - val_loss: 22.7050 - val_mse: 22.7050\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.6769 - mse: 12.6769 - val_loss: 26.3282 - val_mse: 26.3282\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 12.3757 - mse: 12.3757 - val_loss: 28.8903 - val_mse: 28.8903\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.1732 - mse: 12.1732 - val_loss: 29.0886 - val_mse: 29.0886\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.6693 - mse: 10.6693 - val_loss: 25.3559 - val_mse: 25.3559\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.4633 - mse: 13.4633 - val_loss: 36.1013 - val_mse: 36.1013\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.8264 - mse: 9.8264 - val_loss: 31.0651 - val_mse: 31.0651\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.5671 - mse: 14.5671 - val_loss: 24.8396 - val_mse: 24.8396\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.8901 - mse: 11.8901 - val_loss: 26.1826 - val_mse: 26.1826\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8.2719 - mse: 8.2719 - val_loss: 30.4036 - val_mse: 30.4036\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.4916 - mse: 15.4916 - val_loss: 29.3382 - val_mse: 29.3382\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.4874 - mse: 10.4874 - val_loss: 27.0602 - val_mse: 27.0602\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.7909 - mse: 11.7909 - val_loss: 31.7235 - val_mse: 31.7235\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11.9195 - mse: 11.9195 - val_loss: 26.1898 - val_mse: 26.1898\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.5588 - mse: 12.5588 - val_loss: 25.1847 - val_mse: 25.1847\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.2680 - mse: 12.2680 - val_loss: 35.4435 - val_mse: 35.4435\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.0712 - mse: 9.0712 - val_loss: 29.7407 - val_mse: 29.7407\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.2973 - mse: 13.2973 - val_loss: 26.1283 - val_mse: 26.1283\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 13.0313 - mse: 13.0313 - val_loss: 26.4994 - val_mse: 26.4994\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.2132 - mse: 10.2132 - val_loss: 25.7261 - val_mse: 25.7261\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.6183 - mse: 11.6183 - val_loss: 26.9632 - val_mse: 26.9633\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.1050 - mse: 10.1050 - val_loss: 36.7428 - val_mse: 36.7428\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 13.0892 - mse: 13.0892 - val_loss: 33.4072 - val_mse: 33.4072\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.8127 - mse: 9.8127 - val_loss: 23.7252 - val_mse: 23.7252\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 15.1145 - mse: 15.1145 - val_loss: 23.9174 - val_mse: 23.9174\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.8585 - mse: 7.8585 - val_loss: 23.3385 - val_mse: 23.3385\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.7872 - mse: 9.7872 - val_loss: 33.8198 - val_mse: 33.8198\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.3185 - mse: 12.3185 - val_loss: 24.2766 - val_mse: 24.2766\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.5812 - mse: 12.5812 - val_loss: 25.7380 - val_mse: 25.7380\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.7043 - mse: 11.7043 - val_loss: 23.3544 - val_mse: 23.3544\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.5054 - mse: 14.5054 - val_loss: 25.3518 - val_mse: 25.3518\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.1962 - mse: 7.1962 - val_loss: 25.2397 - val_mse: 25.2397\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.1181 - mse: 12.1181 - val_loss: 28.4412 - val_mse: 28.4412\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.4918 - mse: 12.4918 - val_loss: 31.8395 - val_mse: 31.8395\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.2672 - mse: 9.2672 - val_loss: 39.0775 - val_mse: 39.0775\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.6828 - mse: 10.6828 - val_loss: 27.2106 - val_mse: 27.2106\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.6231 - mse: 11.6231 - val_loss: 31.3819 - val_mse: 31.3819\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 11.2412 - mse: 11.2412 - val_loss: 34.5228 - val_mse: 34.5228\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.7320 - mse: 8.7320 - val_loss: 23.8448 - val_mse: 23.8448\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.8146 - mse: 11.8146 - val_loss: 24.5908 - val_mse: 24.5908\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.3544 - mse: 11.3544 - val_loss: 30.2748 - val_mse: 30.2748\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.3040 - mse: 11.3040 - val_loss: 23.2062 - val_mse: 23.2062\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.1605 - mse: 9.1605 - val_loss: 52.3764 - val_mse: 52.3764\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 13.0525 - mse: 13.0525 - val_loss: 27.3465 - val_mse: 27.3465\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.2135 - mse: 10.2135 - val_loss: 29.1597 - val_mse: 29.1597\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.9942 - mse: 8.9942 - val_loss: 36.7850 - val_mse: 36.7850\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.8927 - mse: 11.8927 - val_loss: 27.9359 - val_mse: 27.9359\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.1767 - mse: 10.1767 - val_loss: 25.2275 - val_mse: 25.2275\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11.9840 - mse: 11.9840 - val_loss: 24.7733 - val_mse: 24.7733\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8.4440 - mse: 8.4440 - val_loss: 26.6683 - val_mse: 26.6683\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.2659 - mse: 14.2659 - val_loss: 24.9537 - val_mse: 24.9537\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.3160 - mse: 12.3160 - val_loss: 24.1097 - val_mse: 24.1097\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 8.4948 - mse: 8.4948 - val_loss: 26.9558 - val_mse: 26.9558\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.5405 - mse: 12.5405 - val_loss: 24.3975 - val_mse: 24.3975\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.6335 - mse: 11.6335 - val_loss: 26.2699 - val_mse: 26.2699\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.2039 - mse: 9.2039 - val_loss: 22.7391 - val_mse: 22.7391\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.2985 - mse: 10.2985 - val_loss: 23.1675 - val_mse: 23.1675\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.4210 - mse: 13.4210 - val_loss: 29.2227 - val_mse: 29.2227\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.6132 - mse: 10.6132 - val_loss: 34.3323 - val_mse: 34.3323\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.6899 - mse: 9.6899 - val_loss: 25.3205 - val_mse: 25.3205\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.6159 - mse: 10.6159 - val_loss: 26.6759 - val_mse: 26.6759\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8.9907 - mse: 8.9907 - val_loss: 35.2000 - val_mse: 35.2000\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.7183 - mse: 9.7183 - val_loss: 24.3623 - val_mse: 24.3623\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.1696 - mse: 10.1696 - val_loss: 24.2690 - val_mse: 24.2690\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.2489 - mse: 11.2489 - val_loss: 25.2265 - val_mse: 25.2265\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.7414 - mse: 11.7414 - val_loss: 26.7997 - val_mse: 26.7997\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.4036 - mse: 9.4036 - val_loss: 24.3298 - val_mse: 24.3298\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.1790 - mse: 11.1790 - val_loss: 29.8076 - val_mse: 29.8076\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.7893 - mse: 9.7893 - val_loss: 26.8532 - val_mse: 26.8532\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.0056 - mse: 10.0056 - val_loss: 27.0075 - val_mse: 27.0075\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 9.9698 - mse: 9.9698 - val_loss: 28.9808 - val_mse: 28.9808\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 12.7903 - mse: 12.7903 - val_loss: 26.4317 - val_mse: 26.4317\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5281 - mse: 8.5281 - val_loss: 27.2528 - val_mse: 27.2528\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.7107 - mse: 12.7107 - val_loss: 26.4364 - val_mse: 26.4365\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.8807 - mse: 9.8807 - val_loss: 38.0206 - val_mse: 38.0206\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.5668 - mse: 12.5668 - val_loss: 24.7198 - val_mse: 24.7198\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.0502 - mse: 9.0502 - val_loss: 36.8670 - val_mse: 36.8670\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.3877 - mse: 14.3877 - val_loss: 26.3523 - val_mse: 26.3523\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.7884 - mse: 7.7884 - val_loss: 32.8906 - val_mse: 32.8906\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.6309 - mse: 11.6309 - val_loss: 30.9934 - val_mse: 30.9934\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.1929 - mse: 6.1929 - val_loss: 26.5143 - val_mse: 26.5143\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 14.5905 - mse: 14.5905 - val_loss: 28.5475 - val_mse: 28.5475\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 8.9098 - mse: 8.9098 - val_loss: 27.4081 - val_mse: 27.4081\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 9.0907 - mse: 9.0907 - val_loss: 25.8736 - val_mse: 25.8736\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 14.1278 - mse: 14.1278 - val_loss: 28.7036 - val_mse: 28.7036\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.2803 - mse: 7.2803 - val_loss: 35.0075 - val_mse: 35.0075\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 10.3371 - mse: 10.3371 - val_loss: 32.7821 - val_mse: 32.7821\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 10.7754 - mse: 10.7754 - val_loss: 29.6237 - val_mse: 29.6237\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 9.7006 - mse: 9.7006 - val_loss: 25.8387 - val_mse: 25.8387\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.7107 - mse: 9.7107 - val_loss: 27.5980 - val_mse: 27.5980\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 6.1452 - mse: 6.1452 - val_loss: 27.6984 - val_mse: 27.6984\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9918 - mse: 11.9918 - val_loss: 27.0397 - val_mse: 27.0397\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 10.5626 - mse: 10.5626 - val_loss: 32.9741 - val_mse: 32.9741\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.5405 - mse: 10.5405 - val_loss: 30.7062 - val_mse: 30.7062\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.5694 - mse: 6.5694 - val_loss: 26.7789 - val_mse: 26.7789\n",
      "Epoch 1/400\n",
      "12/12 [==============================] - 3s 57ms/step - loss: 1304.5300 - mse: 1304.5300 - val_loss: 526.2928 - val_mse: 526.2927\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 322.5230 - mse: 322.5230 - val_loss: 172.9868 - val_mse: 172.9868\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 193.7355 - mse: 193.7355 - val_loss: 136.4532 - val_mse: 136.4532\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 167.9427 - mse: 167.9427 - val_loss: 129.2386 - val_mse: 129.2386\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 157.7731 - mse: 157.7731 - val_loss: 115.6681 - val_mse: 115.6681\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 143.0021 - mse: 143.0021 - val_loss: 111.2032 - val_mse: 111.2032\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 133.4167 - mse: 133.4167 - val_loss: 96.6043 - val_mse: 96.6043\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 128.9074 - mse: 128.9074 - val_loss: 104.5186 - val_mse: 104.5186\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 120.6182 - mse: 120.6182 - val_loss: 83.8465 - val_mse: 83.8465\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 112.1592 - mse: 112.1592 - val_loss: 121.5104 - val_mse: 121.5104\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 113.1316 - mse: 113.1316 - val_loss: 86.1072 - val_mse: 86.1072\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 101.6674 - mse: 101.6674 - val_loss: 73.0907 - val_mse: 73.0907\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 93.6794 - mse: 93.6794 - val_loss: 92.3363 - val_mse: 92.3363\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 92.0219 - mse: 92.0219 - val_loss: 67.1917 - val_mse: 67.1917\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 82.9870 - mse: 82.9870 - val_loss: 62.4294 - val_mse: 62.4294\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 81.7923 - mse: 81.7923 - val_loss: 55.9947 - val_mse: 55.9947\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 75.2934 - mse: 75.2934 - val_loss: 53.9207 - val_mse: 53.9207\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 72.5289 - mse: 72.5289 - val_loss: 51.1203 - val_mse: 51.1203\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 63.1799 - mse: 63.1799 - val_loss: 50.9232 - val_mse: 50.9232\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 59.6771 - mse: 59.6771 - val_loss: 91.2820 - val_mse: 91.2820\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 44ms/step - loss: 55.7927 - mse: 55.7927 - val_loss: 48.7630 - val_mse: 48.7630\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 56.6972 - mse: 56.6972 - val_loss: 49.0438 - val_mse: 49.0438\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 48.3384 - mse: 48.3384 - val_loss: 40.4949 - val_mse: 40.4949\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 51.8376 - mse: 51.8376 - val_loss: 39.2435 - val_mse: 39.2435\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 47.9880 - mse: 47.9880 - val_loss: 40.3162 - val_mse: 40.3162\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 42.2058 - mse: 42.2058 - val_loss: 62.9593 - val_mse: 62.9593\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 45.3751 - mse: 45.3751 - val_loss: 40.0597 - val_mse: 40.0597\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 41.8520 - mse: 41.8520 - val_loss: 37.7133 - val_mse: 37.7133\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 43.6086 - mse: 43.6086 - val_loss: 37.0979 - val_mse: 37.0979\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 39.2524 - mse: 39.2524 - val_loss: 35.9708 - val_mse: 35.9708\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 38.1553 - mse: 38.1553 - val_loss: 53.0571 - val_mse: 53.0571\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 43.9664 - mse: 43.9664 - val_loss: 34.2800 - val_mse: 34.2800\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 37.1379 - mse: 37.1379 - val_loss: 33.5941 - val_mse: 33.5941\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 38.5916 - mse: 38.5916 - val_loss: 49.5015 - val_mse: 49.5015\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 35.5499 - mse: 35.5499 - val_loss: 36.2734 - val_mse: 36.2734\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 34.1490 - mse: 34.1490 - val_loss: 35.6158 - val_mse: 35.6158\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 41.0130 - mse: 41.0130 - val_loss: 33.2892 - val_mse: 33.2892\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 31.1569 - mse: 31.1569 - val_loss: 34.7141 - val_mse: 34.7141\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 35.5495 - mse: 35.5495 - val_loss: 31.9141 - val_mse: 31.9141\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 34.1055 - mse: 34.1055 - val_loss: 31.3343 - val_mse: 31.3343\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 33.6178 - mse: 33.6178 - val_loss: 34.0384 - val_mse: 34.0384\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 33.2904 - mse: 33.2904 - val_loss: 39.9923 - val_mse: 39.9923\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 33.5636 - mse: 33.5636 - val_loss: 44.3638 - val_mse: 44.3638\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 32.6745 - mse: 32.6745 - val_loss: 33.3650 - val_mse: 33.3650\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 32.6076 - mse: 32.6076 - val_loss: 30.4521 - val_mse: 30.4521\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 32.4351 - mse: 32.4351 - val_loss: 34.8433 - val_mse: 34.8433\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 26.3683 - mse: 26.3683 - val_loss: 32.3210 - val_mse: 32.3210\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 32.0850 - mse: 32.0850 - val_loss: 29.1396 - val_mse: 29.1396\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 28.5643 - mse: 28.5643 - val_loss: 34.9858 - val_mse: 34.9858\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 33.6958 - mse: 33.6958 - val_loss: 31.3813 - val_mse: 31.3813\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 27.4077 - mse: 27.4077 - val_loss: 49.8657 - val_mse: 49.8657\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 26.3655 - mse: 26.3655 - val_loss: 33.3751 - val_mse: 33.3751\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 32.9236 - mse: 32.9236 - val_loss: 31.8468 - val_mse: 31.8468\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 27.5353 - mse: 27.5353 - val_loss: 29.1281 - val_mse: 29.1281\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 31.0124 - mse: 31.0124 - val_loss: 29.0548 - val_mse: 29.0548\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 27.8033 - mse: 27.8033 - val_loss: 32.6919 - val_mse: 32.6919\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 26.9550 - mse: 26.9550 - val_loss: 31.9008 - val_mse: 31.9008\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 30.7558 - mse: 30.7558 - val_loss: 29.8757 - val_mse: 29.8757\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 27.4127 - mse: 27.4127 - val_loss: 32.2367 - val_mse: 32.2367\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 23.0064 - mse: 23.0064 - val_loss: 30.8745 - val_mse: 30.8745\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 29.2499 - mse: 29.2499 - val_loss: 33.5096 - val_mse: 33.5096\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 26.4622 - mse: 26.4622 - val_loss: 45.3494 - val_mse: 45.3494\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 26.4019 - mse: 26.4019 - val_loss: 28.8435 - val_mse: 28.8435\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 28.1241 - mse: 28.1241 - val_loss: 27.7206 - val_mse: 27.7206\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.8048 - mse: 21.8048 - val_loss: 58.2845 - val_mse: 58.2845\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 28.6116 - mse: 28.6116 - val_loss: 27.8417 - val_mse: 27.8417\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 27.1359 - mse: 27.1359 - val_loss: 27.5517 - val_mse: 27.5517\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 27.2868 - mse: 27.2868 - val_loss: 29.8152 - val_mse: 29.8152\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 26.7614 - mse: 26.7614 - val_loss: 28.7045 - val_mse: 28.7045\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 22.3540 - mse: 22.3540 - val_loss: 58.9940 - val_mse: 58.9940\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 31.1994 - mse: 31.1994 - val_loss: 40.6037 - val_mse: 40.6037\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 23.7076 - mse: 23.7076 - val_loss: 28.4372 - val_mse: 28.4372\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 25.9086 - mse: 25.9086 - val_loss: 31.3739 - val_mse: 31.3739\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.6269 - mse: 22.6269 - val_loss: 28.6366 - val_mse: 28.6366\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 25.0717 - mse: 25.0717 - val_loss: 43.5694 - val_mse: 43.5694\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 24.8424 - mse: 24.8424 - val_loss: 36.1587 - val_mse: 36.1587\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 20.0406 - mse: 20.0406 - val_loss: 28.1821 - val_mse: 28.1821\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 27.9044 - mse: 27.9044 - val_loss: 31.3879 - val_mse: 31.3879\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 27.3072 - mse: 27.3072 - val_loss: 27.4748 - val_mse: 27.4748\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 21.8259 - mse: 21.8259 - val_loss: 42.4338 - val_mse: 42.4338\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 24.1883 - mse: 24.1883 - val_loss: 46.4965 - val_mse: 46.4965\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.7443 - mse: 18.7443 - val_loss: 33.8507 - val_mse: 33.8507\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 26.0175 - mse: 26.0175 - val_loss: 26.3362 - val_mse: 26.3362\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 22.4331 - mse: 22.4331 - val_loss: 26.1732 - val_mse: 26.1732\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 25.4444 - mse: 25.4444 - val_loss: 29.3522 - val_mse: 29.3522\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 27.1769 - mse: 27.1769 - val_loss: 27.7208 - val_mse: 27.7208\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.8681 - mse: 17.8681 - val_loss: 46.6906 - val_mse: 46.6906\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 25.4900 - mse: 25.4900 - val_loss: 28.6065 - val_mse: 28.6065\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 23.4794 - mse: 23.4794 - val_loss: 47.8955 - val_mse: 47.8955\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 21.9561 - mse: 21.9561 - val_loss: 39.4371 - val_mse: 39.4371\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 25.6320 - mse: 25.6320 - val_loss: 36.2663 - val_mse: 36.2663\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.6934 - mse: 22.6934 - val_loss: 39.0326 - val_mse: 39.0326\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.9864 - mse: 21.9864 - val_loss: 29.5433 - val_mse: 29.5433\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 18.7436 - mse: 18.7436 - val_loss: 36.8511 - val_mse: 36.8511\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 22.0655 - mse: 22.0655 - val_loss: 28.1544 - val_mse: 28.1544\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.7961 - mse: 24.7961 - val_loss: 28.6654 - val_mse: 28.6654\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 26.7293 - mse: 26.7293 - val_loss: 25.4025 - val_mse: 25.4025\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.4880 - mse: 21.4880 - val_loss: 36.3602 - val_mse: 36.3602\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 21.8125 - mse: 21.8125 - val_loss: 41.3744 - val_mse: 41.3744\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 20.3580 - mse: 20.3580 - val_loss: 38.0397 - val_mse: 38.0397\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 23.1579 - mse: 23.1579 - val_loss: 27.6611 - val_mse: 27.6611\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.4727 - mse: 21.4727 - val_loss: 24.3953 - val_mse: 24.3953\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.0428 - mse: 20.0428 - val_loss: 24.7057 - val_mse: 24.7057\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 24.2586 - mse: 24.2586 - val_loss: 28.5278 - val_mse: 28.5278\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 21.1412 - mse: 21.1412 - val_loss: 26.7840 - val_mse: 26.7840\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.9382 - mse: 24.9382 - val_loss: 30.5406 - val_mse: 30.5406\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.6727 - mse: 16.6727 - val_loss: 28.1881 - val_mse: 28.1881\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 24.3347 - mse: 24.3347 - val_loss: 26.1288 - val_mse: 26.1288\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.6554 - mse: 17.6554 - val_loss: 33.4667 - val_mse: 33.4667\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 22.9944 - mse: 22.9944 - val_loss: 27.2062 - val_mse: 27.2062\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 19.8689 - mse: 19.8689 - val_loss: 25.2685 - val_mse: 25.2685\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 23.3839 - mse: 23.3839 - val_loss: 25.1520 - val_mse: 25.1520\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 18.1715 - mse: 18.1715 - val_loss: 25.9634 - val_mse: 25.9634\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 23.1267 - mse: 23.1267 - val_loss: 27.8881 - val_mse: 27.8881\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.7303 - mse: 25.7303 - val_loss: 23.3517 - val_mse: 23.3517\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.5438 - mse: 15.5438 - val_loss: 25.4266 - val_mse: 25.4266\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 22.0043 - mse: 22.0043 - val_loss: 30.1361 - val_mse: 30.1361\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 20.3651 - mse: 20.3651 - val_loss: 34.3867 - val_mse: 34.3867\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.7727 - mse: 22.7727 - val_loss: 25.3149 - val_mse: 25.3149\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 20.1241 - mse: 20.1241 - val_loss: 26.3106 - val_mse: 26.3106\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 22.3803 - mse: 22.3803 - val_loss: 22.4041 - val_mse: 22.4041\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 20.9443 - mse: 20.9443 - val_loss: 27.9192 - val_mse: 27.9192\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.1536 - mse: 14.1536 - val_loss: 32.0605 - val_mse: 32.0605\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 19.3617 - mse: 19.3617 - val_loss: 35.2949 - val_mse: 35.2949\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 22.1224 - mse: 22.1224 - val_loss: 27.0010 - val_mse: 27.0010\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.4689 - mse: 17.4689 - val_loss: 23.5366 - val_mse: 23.5366\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 21.7055 - mse: 21.7055 - val_loss: 24.7809 - val_mse: 24.7809\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 15.7755 - mse: 15.7755 - val_loss: 31.0190 - val_mse: 31.0190\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.7923 - mse: 18.7923 - val_loss: 24.8649 - val_mse: 24.8649\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 20.3590 - mse: 20.3590 - val_loss: 25.2674 - val_mse: 25.2674\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.9496 - mse: 19.9496 - val_loss: 23.5973 - val_mse: 23.5973\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.8531 - mse: 14.8531 - val_loss: 44.0769 - val_mse: 44.0769\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 19.2555 - mse: 19.2555 - val_loss: 22.4028 - val_mse: 22.4028\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 23.3408 - mse: 23.3408 - val_loss: 24.4708 - val_mse: 24.4708\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 20.0405 - mse: 20.0405 - val_loss: 22.4480 - val_mse: 22.4480\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 15.5283 - mse: 15.5283 - val_loss: 45.1396 - val_mse: 45.1396\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 19.3966 - mse: 19.3966 - val_loss: 44.9336 - val_mse: 44.9336\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 22.1778 - mse: 22.1778 - val_loss: 25.8274 - val_mse: 25.8274\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.8633 - mse: 13.8633 - val_loss: 40.9401 - val_mse: 40.9401\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 17.1199 - mse: 17.1199 - val_loss: 21.8509 - val_mse: 21.8509\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.1023 - mse: 22.1023 - val_loss: 24.0100 - val_mse: 24.0100\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.1912 - mse: 17.1912 - val_loss: 22.6014 - val_mse: 22.6014\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.6728 - mse: 16.6728 - val_loss: 26.3210 - val_mse: 26.3210\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 18.0263 - mse: 18.0263 - val_loss: 22.1938 - val_mse: 22.1938\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 19.2515 - mse: 19.2515 - val_loss: 49.9850 - val_mse: 49.9850\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 21.5980 - mse: 21.5980 - val_loss: 27.3327 - val_mse: 27.3327\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 19.5813 - mse: 19.5813 - val_loss: 26.7410 - val_mse: 26.7410\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 15.9069 - mse: 15.9069 - val_loss: 27.5548 - val_mse: 27.5548\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 19.6619 - mse: 19.6619 - val_loss: 47.5474 - val_mse: 47.5474\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 17.3237 - mse: 17.3237 - val_loss: 20.8374 - val_mse: 20.8374\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 15.7941 - mse: 15.7941 - val_loss: 61.7822 - val_mse: 61.7822\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 21.0221 - mse: 21.0221 - val_loss: 24.9324 - val_mse: 24.9324\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.3379 - mse: 16.3379 - val_loss: 26.9185 - val_mse: 26.9185\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 21.4468 - mse: 21.4468 - val_loss: 24.9847 - val_mse: 24.9847\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.2049 - mse: 16.2049 - val_loss: 35.6464 - val_mse: 35.6464\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.8263 - mse: 18.8263 - val_loss: 25.6546 - val_mse: 25.6546\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.7222 - mse: 19.7222 - val_loss: 28.5200 - val_mse: 28.5200\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.8933 - mse: 14.8933 - val_loss: 21.4338 - val_mse: 21.4338\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.3694 - mse: 17.3694 - val_loss: 24.5886 - val_mse: 24.5886\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.2830 - mse: 18.2830 - val_loss: 27.3841 - val_mse: 27.3841\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.5332 - mse: 16.5332 - val_loss: 28.7160 - val_mse: 28.7160\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.3958 - mse: 18.3958 - val_loss: 24.6359 - val_mse: 24.6359\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 16.8118 - mse: 16.8118 - val_loss: 32.5651 - val_mse: 32.5651\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 14.5241 - mse: 14.5241 - val_loss: 24.8610 - val_mse: 24.8610\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 23.9738 - mse: 23.9738 - val_loss: 22.6643 - val_mse: 22.6643\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.7203 - mse: 18.7203 - val_loss: 21.3439 - val_mse: 21.3439\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.4143 - mse: 13.4143 - val_loss: 29.1590 - val_mse: 29.1590\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 15.6615 - mse: 15.6615 - val_loss: 20.1770 - val_mse: 20.1770\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 22.5101 - mse: 22.5101 - val_loss: 28.1226 - val_mse: 28.1226\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.3715 - mse: 12.3715 - val_loss: 28.3303 - val_mse: 28.3303\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 20.9875 - mse: 20.9875 - val_loss: 28.6253 - val_mse: 28.6253\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 14.2532 - mse: 14.2532 - val_loss: 31.1749 - val_mse: 31.1749\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.1010 - mse: 19.1010 - val_loss: 27.9936 - val_mse: 27.9936\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.8386 - mse: 16.8386 - val_loss: 19.7331 - val_mse: 19.7331\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 15.0326 - mse: 15.0326 - val_loss: 21.0216 - val_mse: 21.0216\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.1495 - mse: 18.1495 - val_loss: 20.7062 - val_mse: 20.7062\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.1405 - mse: 14.1405 - val_loss: 40.4625 - val_mse: 40.4625\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.5842 - mse: 16.5842 - val_loss: 24.3825 - val_mse: 24.3825\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.8092 - mse: 18.8092 - val_loss: 30.2200 - val_mse: 30.2200\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.2369 - mse: 19.2369 - val_loss: 19.8185 - val_mse: 19.8185\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 17.8016 - mse: 17.8016 - val_loss: 23.7185 - val_mse: 23.7185\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.9624 - mse: 11.9624 - val_loss: 23.2708 - val_mse: 23.2708\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.5420 - mse: 18.5420 - val_loss: 21.7944 - val_mse: 21.7944\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.6164 - mse: 15.6164 - val_loss: 36.0451 - val_mse: 36.0451\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 17.6142 - mse: 17.6142 - val_loss: 29.7304 - val_mse: 29.7304\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.1906 - mse: 12.1906 - val_loss: 26.9891 - val_mse: 26.9891\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.9577 - mse: 17.9577 - val_loss: 20.2037 - val_mse: 20.2037\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.3084 - mse: 17.3084 - val_loss: 49.8579 - val_mse: 49.8579\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.8486 - mse: 15.8486 - val_loss: 24.6194 - val_mse: 24.6194\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.0599 - mse: 17.0599 - val_loss: 19.9466 - val_mse: 19.9466\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.7530 - mse: 13.7530 - val_loss: 20.8169 - val_mse: 20.8169\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.3884 - mse: 16.3884 - val_loss: 42.0589 - val_mse: 42.0589\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 16.7338 - mse: 16.7338 - val_loss: 29.0237 - val_mse: 29.0237\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.2612 - mse: 16.2612 - val_loss: 20.8928 - val_mse: 20.8928\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.3740 - mse: 17.3740 - val_loss: 19.8878 - val_mse: 19.8878\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 16.9453 - mse: 16.9453 - val_loss: 24.5893 - val_mse: 24.5893\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.5847 - mse: 11.5847 - val_loss: 23.6166 - val_mse: 23.6166\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 15.0507 - mse: 15.0507 - val_loss: 19.1099 - val_mse: 19.1099\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19.3417 - mse: 19.3417 - val_loss: 21.4847 - val_mse: 21.4847\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.5395 - mse: 12.5395 - val_loss: 30.5903 - val_mse: 30.5903\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 16.6518 - mse: 16.6518 - val_loss: 29.6315 - val_mse: 29.6315\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 16.1850 - mse: 16.1850 - val_loss: 22.0699 - val_mse: 22.0699\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.2451 - mse: 14.2451 - val_loss: 21.7416 - val_mse: 21.7416\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.4779 - mse: 19.4779 - val_loss: 19.9179 - val_mse: 19.9179\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 13.7251 - mse: 13.7251 - val_loss: 24.1250 - val_mse: 24.1250\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 16.7952 - mse: 16.7952 - val_loss: 27.8034 - val_mse: 27.8034\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 13.4800 - mse: 13.4800 - val_loss: 32.6661 - val_mse: 32.6661\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.5091 - mse: 15.5091 - val_loss: 20.6437 - val_mse: 20.6437\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.0465 - mse: 13.0465 - val_loss: 23.9356 - val_mse: 23.9356\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.3069 - mse: 14.3069 - val_loss: 28.0450 - val_mse: 28.0450\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 18.7302 - mse: 18.7302 - val_loss: 20.0494 - val_mse: 20.0494\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9.5464 - mse: 9.5464 - val_loss: 28.2323 - val_mse: 28.2323\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 17.4587 - mse: 17.4587 - val_loss: 22.7932 - val_mse: 22.7932\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.1383 - mse: 12.1383 - val_loss: 35.5904 - val_mse: 35.5904\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 15.9090 - mse: 15.9090 - val_loss: 20.2110 - val_mse: 20.2110\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 11.3695 - mse: 11.3695 - val_loss: 30.1279 - val_mse: 30.1279\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 18.4901 - mse: 18.4901 - val_loss: 21.2735 - val_mse: 21.2735\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 18.0184 - mse: 18.0184 - val_loss: 32.5089 - val_mse: 32.5089\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.9129 - mse: 11.9129 - val_loss: 23.2452 - val_mse: 23.2452\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 14.7152 - mse: 14.7152 - val_loss: 37.8581 - val_mse: 37.8581\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 15.0229 - mse: 15.0229 - val_loss: 19.6776 - val_mse: 19.6776\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.2363 - mse: 14.2363 - val_loss: 24.1043 - val_mse: 24.1043\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 12.6141 - mse: 12.6141 - val_loss: 19.1506 - val_mse: 19.1506\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 16.5563 - mse: 16.5563 - val_loss: 33.7545 - val_mse: 33.7545\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 14.1890 - mse: 14.1890 - val_loss: 33.6053 - val_mse: 33.6053\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.4861 - mse: 16.4861 - val_loss: 24.0584 - val_mse: 24.0584\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.9245 - mse: 11.9245 - val_loss: 30.6336 - val_mse: 30.6336\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 14.5349 - mse: 14.5349 - val_loss: 23.6463 - val_mse: 23.6463\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.9169 - mse: 16.9169 - val_loss: 36.0937 - val_mse: 36.0937\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.0131 - mse: 15.0131 - val_loss: 31.9703 - val_mse: 31.9703\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 14.7884 - mse: 14.7884 - val_loss: 22.1202 - val_mse: 22.1202\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11.2686 - mse: 11.2686 - val_loss: 19.4927 - val_mse: 19.4927\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 17.8129 - mse: 17.8129 - val_loss: 22.3940 - val_mse: 22.3940\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 15.3421 - mse: 15.3421 - val_loss: 36.8581 - val_mse: 36.8581\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.5533 - mse: 13.5533 - val_loss: 21.5738 - val_mse: 21.5738\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 14.6046 - mse: 14.6046 - val_loss: 18.8085 - val_mse: 18.8085\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 17.5417 - mse: 17.5417 - val_loss: 23.4955 - val_mse: 23.4955\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.9042 - mse: 13.9042 - val_loss: 27.6683 - val_mse: 27.6683\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.4596 - mse: 10.4596 - val_loss: 19.5886 - val_mse: 19.5886\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.2885 - mse: 17.2885 - val_loss: 25.0202 - val_mse: 25.0202\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.7156 - mse: 13.7156 - val_loss: 30.2027 - val_mse: 30.2027\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.2800 - mse: 14.2800 - val_loss: 19.3913 - val_mse: 19.3913\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.8914 - mse: 12.8914 - val_loss: 19.8952 - val_mse: 19.8952\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 13.7115 - mse: 13.7115 - val_loss: 21.3144 - val_mse: 21.3144\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 15.6396 - mse: 15.6396 - val_loss: 19.2548 - val_mse: 19.2548\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.7076 - mse: 12.7076 - val_loss: 34.9772 - val_mse: 34.9772\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.5992 - mse: 11.5992 - val_loss: 26.1900 - val_mse: 26.1900\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.5284 - mse: 13.5284 - val_loss: 30.4330 - val_mse: 30.4330\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 19.0645 - mse: 19.0645 - val_loss: 18.7533 - val_mse: 18.7533\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.0147 - mse: 9.0147 - val_loss: 39.1001 - val_mse: 39.1001\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 17.0116 - mse: 17.0116 - val_loss: 17.8533 - val_mse: 17.8533\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 13.1278 - mse: 13.1278 - val_loss: 18.2586 - val_mse: 18.2586\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 14.4461 - mse: 14.4461 - val_loss: 32.9291 - val_mse: 32.9291\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 15.9697 - mse: 15.9697 - val_loss: 22.8792 - val_mse: 22.8792\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 9.2963 - mse: 9.2963 - val_loss: 24.3122 - val_mse: 24.3122\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 14.4529 - mse: 14.4529 - val_loss: 21.1295 - val_mse: 21.1295\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 12.8478 - mse: 12.8478 - val_loss: 23.8196 - val_mse: 23.8196\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.2602 - mse: 14.2602 - val_loss: 22.1245 - val_mse: 22.1245\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 13.0679 - mse: 13.0679 - val_loss: 18.2704 - val_mse: 18.2704\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.6591 - mse: 13.6591 - val_loss: 18.9553 - val_mse: 18.9553\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 14.2409 - mse: 14.2409 - val_loss: 18.0231 - val_mse: 18.0231\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.0924 - mse: 10.0924 - val_loss: 18.5133 - val_mse: 18.5133\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 14.7954 - mse: 14.7954 - val_loss: 18.6013 - val_mse: 18.6013\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 16.2749 - mse: 16.2749 - val_loss: 17.8526 - val_mse: 17.8526\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 9.5814 - mse: 9.5814 - val_loss: 24.0889 - val_mse: 24.0889\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.6699 - mse: 14.6699 - val_loss: 31.1408 - val_mse: 31.1408\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 15.4512 - mse: 15.4512 - val_loss: 24.0876 - val_mse: 24.0876\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.0095 - mse: 9.0095 - val_loss: 17.9908 - val_mse: 17.9908\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 16.6966 - mse: 16.6966 - val_loss: 22.3317 - val_mse: 22.3317\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 11.3533 - mse: 11.3533 - val_loss: 30.1420 - val_mse: 30.1420\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 16.7932 - mse: 16.7932 - val_loss: 21.3125 - val_mse: 21.3125\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 8.5161 - mse: 8.5161 - val_loss: 19.4184 - val_mse: 19.4184\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 17.3679 - mse: 17.3679 - val_loss: 22.5829 - val_mse: 22.5829\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 12.0845 - mse: 12.0845 - val_loss: 23.3421 - val_mse: 23.3421\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 11.2350 - mse: 11.2350 - val_loss: 19.7501 - val_mse: 19.7501\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 16.9812 - mse: 16.9812 - val_loss: 17.7702 - val_mse: 17.7702\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 10.0044 - mse: 10.0044 - val_loss: 25.5827 - val_mse: 25.5827\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 13.1476 - mse: 13.1476 - val_loss: 22.2392 - val_mse: 22.2392\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 15.5307 - mse: 15.5307 - val_loss: 20.2665 - val_mse: 20.2665\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 9.8899 - mse: 9.8899 - val_loss: 21.5785 - val_mse: 21.5785\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.5535 - mse: 14.5535 - val_loss: 20.4523 - val_mse: 20.4523\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 14.1168 - mse: 14.1168 - val_loss: 17.8940 - val_mse: 17.8940\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.6654 - mse: 11.6654 - val_loss: 21.4442 - val_mse: 21.4442\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.4423 - mse: 13.4423 - val_loss: 17.6711 - val_mse: 17.6711\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 9.5021 - mse: 9.5021 - val_loss: 21.3657 - val_mse: 21.3657\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 15.0059 - mse: 15.0059 - val_loss: 19.2985 - val_mse: 19.2986\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 11.6871 - mse: 11.6871 - val_loss: 18.1512 - val_mse: 18.1512\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.4332 - mse: 10.4332 - val_loss: 17.1776 - val_mse: 17.1776\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 13.1372 - mse: 13.1372 - val_loss: 26.1250 - val_mse: 26.1250\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 13.3573 - mse: 13.3573 - val_loss: 31.1734 - val_mse: 31.1734\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.1858 - mse: 13.1858 - val_loss: 17.4492 - val_mse: 17.4492\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9225 - mse: 11.9225 - val_loss: 20.1198 - val_mse: 20.1198\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 10.7899 - mse: 10.7899 - val_loss: 26.3294 - val_mse: 26.3294\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.4469 - mse: 13.4469 - val_loss: 17.5827 - val_mse: 17.5827\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.4655 - mse: 12.4655 - val_loss: 19.1979 - val_mse: 19.1979\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.3047 - mse: 13.3047 - val_loss: 20.2466 - val_mse: 20.2466\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.8213 - mse: 10.8213 - val_loss: 20.2199 - val_mse: 20.2199\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 12.6582 - mse: 12.6582 - val_loss: 24.1957 - val_mse: 24.1957\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.6039 - mse: 12.6039 - val_loss: 22.7265 - val_mse: 22.7265\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 12.1616 - mse: 12.1616 - val_loss: 35.2949 - val_mse: 35.2949\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.1255 - mse: 12.1255 - val_loss: 22.2749 - val_mse: 22.2749\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.2501 - mse: 11.2501 - val_loss: 22.4550 - val_mse: 22.4550\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.8809 - mse: 13.8809 - val_loss: 19.5624 - val_mse: 19.5624\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8.7694 - mse: 8.7694 - val_loss: 20.5247 - val_mse: 20.5247\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 13.5021 - mse: 13.5021 - val_loss: 19.9405 - val_mse: 19.9405\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.5740 - mse: 13.5740 - val_loss: 23.3830 - val_mse: 23.3830\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.3586 - mse: 9.3586 - val_loss: 20.9042 - val_mse: 20.9042\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 15.4261 - mse: 15.4261 - val_loss: 21.9380 - val_mse: 21.9380\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.6311 - mse: 9.6311 - val_loss: 22.4427 - val_mse: 22.4427\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 11.4271 - mse: 11.4271 - val_loss: 21.7086 - val_mse: 21.7086\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 13.9485 - mse: 13.9485 - val_loss: 19.6327 - val_mse: 19.6327\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.9881 - mse: 8.9881 - val_loss: 22.6417 - val_mse: 22.6417\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 14.6880 - mse: 14.6880 - val_loss: 21.0003 - val_mse: 21.0003\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 11.1572 - mse: 11.1572 - val_loss: 25.4505 - val_mse: 25.4505\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.9002 - mse: 12.9002 - val_loss: 19.5956 - val_mse: 19.5956\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 11.8169 - mse: 11.8169 - val_loss: 17.7399 - val_mse: 17.7399\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.9613 - mse: 11.9613 - val_loss: 19.5272 - val_mse: 19.5272\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9.8015 - mse: 9.8015 - val_loss: 30.3530 - val_mse: 30.3530\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.7090 - mse: 10.7090 - val_loss: 20.7630 - val_mse: 20.7630\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.8135 - mse: 13.8135 - val_loss: 17.3812 - val_mse: 17.3812\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 11.9046 - mse: 11.9046 - val_loss: 22.3086 - val_mse: 22.3086\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12.5092 - mse: 12.5092 - val_loss: 16.2479 - val_mse: 16.2479\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.1630 - mse: 11.1630 - val_loss: 18.3160 - val_mse: 18.3160\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.0720 - mse: 10.0720 - val_loss: 21.7500 - val_mse: 21.7500\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.8479 - mse: 11.8479 - val_loss: 17.7376 - val_mse: 17.7376\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.8799 - mse: 10.8799 - val_loss: 20.4407 - val_mse: 20.4407\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 11.0636 - mse: 11.0636 - val_loss: 19.3594 - val_mse: 19.3594\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.1731 - mse: 13.1731 - val_loss: 20.7332 - val_mse: 20.7332\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.9901 - mse: 9.9901 - val_loss: 19.9716 - val_mse: 19.9716\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.6443 - mse: 11.6443 - val_loss: 28.1212 - val_mse: 28.1212\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12.1540 - mse: 12.1540 - val_loss: 24.9081 - val_mse: 24.9081\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9979 - mse: 11.9979 - val_loss: 23.3637 - val_mse: 23.3637\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.5603 - mse: 10.5603 - val_loss: 17.7119 - val_mse: 17.7119\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 13.3391 - mse: 13.3391 - val_loss: 18.7075 - val_mse: 18.7075\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 11.0625 - mse: 11.0625 - val_loss: 19.2812 - val_mse: 19.2812\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.6906 - mse: 10.6906 - val_loss: 18.2375 - val_mse: 18.2375\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.0826 - mse: 12.0826 - val_loss: 18.0537 - val_mse: 18.0537\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.1584 - mse: 10.1584 - val_loss: 21.2334 - val_mse: 21.2334\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.2865 - mse: 13.2865 - val_loss: 17.4641 - val_mse: 17.4641\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.4532 - mse: 9.4532 - val_loss: 28.9708 - val_mse: 28.9708\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.9281 - mse: 8.9281 - val_loss: 29.3533 - val_mse: 29.3533\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.0069 - mse: 12.0069 - val_loss: 16.8647 - val_mse: 16.8647\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.7312 - mse: 11.7312 - val_loss: 16.6978 - val_mse: 16.6978\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.2863 - mse: 12.2863 - val_loss: 20.3510 - val_mse: 20.3510\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 10.2616 - mse: 10.2616 - val_loss: 18.8181 - val_mse: 18.8181\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.6108 - mse: 10.6108 - val_loss: 34.3244 - val_mse: 34.3244\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.1975 - mse: 10.1975 - val_loss: 25.5782 - val_mse: 25.5782\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.9852 - mse: 10.9852 - val_loss: 24.0652 - val_mse: 24.0652\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 11.2144 - mse: 11.2144 - val_loss: 17.4668 - val_mse: 17.4668\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8.2898 - mse: 8.2898 - val_loss: 35.2357 - val_mse: 35.2357\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 13.1400 - mse: 13.1400 - val_loss: 18.8029 - val_mse: 18.8029\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.7167 - mse: 11.7167 - val_loss: 16.5876 - val_mse: 16.5876\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 12.0812 - mse: 12.0812 - val_loss: 27.0569 - val_mse: 27.0569\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.6276 - mse: 7.6276 - val_loss: 19.2161 - val_mse: 19.2161\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.0599 - mse: 10.0599 - val_loss: 19.5341 - val_mse: 19.5341\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.7054 - mse: 12.7054 - val_loss: 22.6456 - val_mse: 22.6456\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 10.1965 - mse: 10.1965 - val_loss: 17.1552 - val_mse: 17.1552\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.1682 - mse: 11.1682 - val_loss: 28.7251 - val_mse: 28.7251\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.7649 - mse: 7.7649 - val_loss: 16.9923 - val_mse: 16.9923\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.2431 - mse: 11.2431 - val_loss: 18.6772 - val_mse: 18.6772\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.6818 - mse: 10.6818 - val_loss: 23.1877 - val_mse: 23.1877\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 8.9866 - mse: 8.9866 - val_loss: 26.6007 - val_mse: 26.6007\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.9847 - mse: 12.9847 - val_loss: 26.7570 - val_mse: 26.7570\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.4324 - mse: 9.4324 - val_loss: 22.4716 - val_mse: 22.4716\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.8299 - mse: 11.8299 - val_loss: 32.4125 - val_mse: 32.4125\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.1674 - mse: 12.1674 - val_loss: 20.7683 - val_mse: 20.7683\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.4986 - mse: 7.4986 - val_loss: 21.7199 - val_mse: 21.7199\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.0552 - mse: 13.0552 - val_loss: 17.4341 - val_mse: 17.4341\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.6321 - mse: 10.6321 - val_loss: 18.2934 - val_mse: 18.2934\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.8794 - mse: 8.8794 - val_loss: 24.2231 - val_mse: 24.2231\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 10.6865 - mse: 10.6865 - val_loss: 17.8722 - val_mse: 17.8722\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.7062 - mse: 12.7062 - val_loss: 18.9422 - val_mse: 18.9422\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 7.6682 - mse: 7.6682 - val_loss: 21.4284 - val_mse: 21.4284\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 9.4480 - mse: 9.4480 - val_loss: 22.8084 - val_mse: 22.8084\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.6988 - mse: 10.6988 - val_loss: 17.2602 - val_mse: 17.2602\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.7339 - mse: 11.7339 - val_loss: 19.2274 - val_mse: 19.2274\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.6450 - mse: 10.6450 - val_loss: 27.0685 - val_mse: 27.0685\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.2220 - mse: 7.2220 - val_loss: 18.5798 - val_mse: 18.5798\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.4529 - mse: 13.4529 - val_loss: 20.0989 - val_mse: 20.0989\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.7593 - mse: 9.7593 - val_loss: 18.2417 - val_mse: 18.2417\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.1699 - mse: 9.1699 - val_loss: 19.4594 - val_mse: 19.4594\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12.7463 - mse: 12.7463 - val_loss: 18.7509 - val_mse: 18.7509\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.9288 - mse: 9.9288 - val_loss: 18.0876 - val_mse: 18.0876\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.3895 - mse: 11.3895 - val_loss: 20.0202 - val_mse: 20.0202\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5910 - mse: 8.5910 - val_loss: 18.5191 - val_mse: 18.5191\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.3843 - mse: 9.3843 - val_loss: 30.5809 - val_mse: 30.5809\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.4990 - mse: 9.4990 - val_loss: 18.3594 - val_mse: 18.3594\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.4340 - mse: 11.4340 - val_loss: 16.8309 - val_mse: 16.8309\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 11.1092 - mse: 11.1092 - val_loss: 19.1516 - val_mse: 19.1516\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.6738 - mse: 10.6738 - val_loss: 18.3079 - val_mse: 18.3079\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.0011 - mse: 7.0011 - val_loss: 17.5616 - val_mse: 17.5616\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 13.6886 - mse: 13.6886 - val_loss: 15.9093 - val_mse: 15.9093\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.7233 - mse: 11.7233 - val_loss: 18.8379 - val_mse: 18.8379\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.0067 - mse: 7.0067 - val_loss: 18.9670 - val_mse: 18.9670\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.8147 - mse: 12.8147 - val_loss: 17.5945 - val_mse: 17.5945\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 5.7970 - mse: 5.7970 - val_loss: 35.2738 - val_mse: 35.2738\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.1500 - mse: 12.1500 - val_loss: 18.4924 - val_mse: 18.4924\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.2192 - mse: 10.2192 - val_loss: 20.0316 - val_mse: 20.0316\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 5.7422 - mse: 5.7422 - val_loss: 21.3311 - val_mse: 21.3311\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.9510 - mse: 13.9510 - val_loss: 16.9569 - val_mse: 16.9569\n",
      "Epoch 1/400\n",
      "12/12 [==============================] - 4s 89ms/step - loss: 1192.0345 - mse: 1192.0345 - val_loss: 348.9015 - val_mse: 348.9015\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 247.6861 - mse: 247.6861 - val_loss: 178.5261 - val_mse: 178.5261\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 172.3826 - mse: 172.3826 - val_loss: 159.4694 - val_mse: 159.4694\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 156.6415 - mse: 156.6415 - val_loss: 143.6415 - val_mse: 143.6415\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 142.5016 - mse: 142.5016 - val_loss: 132.2184 - val_mse: 132.2184\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 134.3398 - mse: 134.3398 - val_loss: 130.3434 - val_mse: 130.3434\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 120.2421 - mse: 120.2421 - val_loss: 126.0802 - val_mse: 126.0802\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 114.4234 - mse: 114.4234 - val_loss: 118.6433 - val_mse: 118.6433\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 104.3817 - mse: 104.3817 - val_loss: 123.9125 - val_mse: 123.9125\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 101.0731 - mse: 101.0731 - val_loss: 113.6612 - val_mse: 113.6612\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 98.9458 - mse: 98.9458 - val_loss: 97.5957 - val_mse: 97.5957\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 89.0548 - mse: 89.0548 - val_loss: 110.0210 - val_mse: 110.0210\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 85.1754 - mse: 85.1754 - val_loss: 91.7294 - val_mse: 91.7294\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 73.7156 - mse: 73.7156 - val_loss: 83.3244 - val_mse: 83.3244\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 71.4356 - mse: 71.4356 - val_loss: 82.1117 - val_mse: 82.1117\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 69.6110 - mse: 69.6110 - val_loss: 107.5018 - val_mse: 107.5018\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 63.8987 - mse: 63.8987 - val_loss: 88.0463 - val_mse: 88.0463\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 62.0067 - mse: 62.0067 - val_loss: 79.1804 - val_mse: 79.1804\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 60.4323 - mse: 60.4323 - val_loss: 74.8494 - val_mse: 74.8494\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 55.3542 - mse: 55.3542 - val_loss: 69.0102 - val_mse: 69.0102\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 54.2694 - mse: 54.2694 - val_loss: 64.2984 - val_mse: 64.2984\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 54.1175 - mse: 54.1175 - val_loss: 74.9135 - val_mse: 74.9135\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 47.6810 - mse: 47.6810 - val_loss: 67.5973 - val_mse: 67.5973\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 53.0372 - mse: 53.0372 - val_loss: 82.5106 - val_mse: 82.5106\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 40.8908 - mse: 40.8908 - val_loss: 65.1429 - val_mse: 65.1429\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 38.4994 - mse: 38.4994 - val_loss: 56.2252 - val_mse: 56.2252\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 39.5939 - mse: 39.5939 - val_loss: 62.5058 - val_mse: 62.5058\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 47.4657 - mse: 47.4657 - val_loss: 53.3739 - val_mse: 53.3739\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 37.6635 - mse: 37.6635 - val_loss: 52.7839 - val_mse: 52.7839\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 36.9157 - mse: 36.9157 - val_loss: 51.5129 - val_mse: 51.5129\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 34.9968 - mse: 34.9968 - val_loss: 57.0932 - val_mse: 57.0932\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 40.3105 - mse: 40.3105 - val_loss: 47.7026 - val_mse: 47.7026\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 30.3373 - mse: 30.3373 - val_loss: 46.2155 - val_mse: 46.2155\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 39.6784 - mse: 39.6784 - val_loss: 65.9024 - val_mse: 65.9024\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 30.6652 - mse: 30.6652 - val_loss: 51.3883 - val_mse: 51.3883\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 38.5693 - mse: 38.5693 - val_loss: 43.6703 - val_mse: 43.6703\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29.5057 - mse: 29.5057 - val_loss: 49.7769 - val_mse: 49.7769\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 34.7729 - mse: 34.7729 - val_loss: 49.3845 - val_mse: 49.3845\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 27.8700 - mse: 27.8700 - val_loss: 84.2057 - val_mse: 84.2057\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 37.6774 - mse: 37.6774 - val_loss: 42.9131 - val_mse: 42.9131\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 33.1528 - mse: 33.1528 - val_loss: 65.7472 - val_mse: 65.7472\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 35.8073 - mse: 35.8073 - val_loss: 44.4932 - val_mse: 44.4932\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 25.7964 - mse: 25.7964 - val_loss: 50.3701 - val_mse: 50.3701\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 31.7301 - mse: 31.7300 - val_loss: 70.9335 - val_mse: 70.9335\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29.6702 - mse: 29.6702 - val_loss: 48.0849 - val_mse: 48.0849\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25.5593 - mse: 25.5593 - val_loss: 42.6135 - val_mse: 42.6135\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 31.3966 - mse: 31.3966 - val_loss: 82.3745 - val_mse: 82.3745\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 28.0625 - mse: 28.0625 - val_loss: 42.4839 - val_mse: 42.4839\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 30.5716 - mse: 30.5716 - val_loss: 42.0836 - val_mse: 42.0836\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 35.3309 - mse: 35.3309 - val_loss: 48.0406 - val_mse: 48.0406\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 27.8428 - mse: 27.8428 - val_loss: 42.2642 - val_mse: 42.2642\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29.5553 - mse: 29.5553 - val_loss: 46.8078 - val_mse: 46.8078\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.7853 - mse: 24.7853 - val_loss: 41.1861 - val_mse: 41.1861\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29.0502 - mse: 29.0502 - val_loss: 45.2691 - val_mse: 45.2691\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 27.9940 - mse: 27.9940 - val_loss: 73.8000 - val_mse: 73.8000\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 24.6830 - mse: 24.6830 - val_loss: 48.5975 - val_mse: 48.5975\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 30.4133 - mse: 30.4133 - val_loss: 64.5397 - val_mse: 64.5397\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 26.5953 - mse: 26.5953 - val_loss: 64.8846 - val_mse: 64.8846\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 26.0866 - mse: 26.0866 - val_loss: 41.8721 - val_mse: 41.8721\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25.2061 - mse: 25.2061 - val_loss: 69.9174 - val_mse: 69.9174\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 25.0597 - mse: 25.0597 - val_loss: 44.1923 - val_mse: 44.1923\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 30.7651 - mse: 30.7651 - val_loss: 43.2666 - val_mse: 43.2666\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 23.8193 - mse: 23.8193 - val_loss: 38.2674 - val_mse: 38.2674\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.3288 - mse: 22.3288 - val_loss: 72.4650 - val_mse: 72.4650\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 27.9614 - mse: 27.9614 - val_loss: 40.4299 - val_mse: 40.4299\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 23.5076 - mse: 23.5076 - val_loss: 39.1458 - val_mse: 39.1458\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 28.3127 - mse: 28.3127 - val_loss: 59.0586 - val_mse: 59.0586\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 17.9534 - mse: 17.9534 - val_loss: 42.5298 - val_mse: 42.5298\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 25.7483 - mse: 25.7483 - val_loss: 52.4007 - val_mse: 52.4007\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 21.9109 - mse: 21.9109 - val_loss: 96.3336 - val_mse: 96.3336\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.7868 - mse: 22.7868 - val_loss: 39.9817 - val_mse: 39.9817\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 26.7330 - mse: 26.7330 - val_loss: 40.1832 - val_mse: 40.1832\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 20.0142 - mse: 20.0142 - val_loss: 48.2936 - val_mse: 48.2936\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 25.8335 - mse: 25.8335 - val_loss: 72.2173 - val_mse: 72.2173\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 25.7982 - mse: 25.7982 - val_loss: 40.4734 - val_mse: 40.4734\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 26.0077 - mse: 26.0077 - val_loss: 47.2074 - val_mse: 47.2074\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.6061 - mse: 16.6061 - val_loss: 49.2009 - val_mse: 49.2009\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 23.6665 - mse: 23.6665 - val_loss: 63.2387 - val_mse: 63.2387\n",
      "Epoch 79/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 21.7061 - mse: 21.7061 - val_loss: 60.2279 - val_mse: 60.2279\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 22.3699 - mse: 22.3699 - val_loss: 37.2746 - val_mse: 37.2746\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.9962 - mse: 22.9962 - val_loss: 54.2406 - val_mse: 54.2406\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 22.2510 - mse: 22.2510 - val_loss: 72.3020 - val_mse: 72.3020\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 22.0624 - mse: 22.0624 - val_loss: 46.8011 - val_mse: 46.8011\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 22.6113 - mse: 22.6113 - val_loss: 49.6837 - val_mse: 49.6837\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.9710 - mse: 19.9710 - val_loss: 42.6955 - val_mse: 42.6955\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.2714 - mse: 18.2714 - val_loss: 63.1478 - val_mse: 63.1478\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25.2633 - mse: 25.2633 - val_loss: 50.0711 - val_mse: 50.0711\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 21.5813 - mse: 21.5813 - val_loss: 40.3401 - val_mse: 40.3401\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.6195 - mse: 19.6195 - val_loss: 39.3511 - val_mse: 39.3511\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 21.6006 - mse: 21.6006 - val_loss: 43.6271 - val_mse: 43.6271\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 21.1566 - mse: 21.1566 - val_loss: 60.9301 - val_mse: 60.9301\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 20.4849 - mse: 20.4849 - val_loss: 40.7823 - val_mse: 40.7823\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 22.5945 - mse: 22.5945 - val_loss: 50.5846 - val_mse: 50.5846\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 18.7114 - mse: 18.7114 - val_loss: 48.8264 - val_mse: 48.8264\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 24.5552 - mse: 24.5552 - val_loss: 38.1307 - val_mse: 38.1307\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.9358 - mse: 13.9358 - val_loss: 57.5102 - val_mse: 57.5102\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 25.9419 - mse: 25.9419 - val_loss: 39.4537 - val_mse: 39.4537\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 21.6775 - mse: 21.6775 - val_loss: 39.4845 - val_mse: 39.4845\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 18.5736 - mse: 18.5736 - val_loss: 39.5016 - val_mse: 39.5016\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 21.4971 - mse: 21.4971 - val_loss: 56.8884 - val_mse: 56.8884\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 23.2439 - mse: 23.2439 - val_loss: 56.0753 - val_mse: 56.0753\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.3863 - mse: 14.3863 - val_loss: 37.4572 - val_mse: 37.4571\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 25.5317 - mse: 25.5317 - val_loss: 36.9638 - val_mse: 36.9637\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 15.2205 - mse: 15.2205 - val_loss: 41.7607 - val_mse: 41.7607\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 27.9181 - mse: 27.9181 - val_loss: 51.4656 - val_mse: 51.4656\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 13.8962 - mse: 13.8962 - val_loss: 41.4132 - val_mse: 41.4132\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 20.0989 - mse: 20.0989 - val_loss: 39.9398 - val_mse: 39.9398\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 19.7740 - mse: 19.7740 - val_loss: 46.4650 - val_mse: 46.4650\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 17.8757 - mse: 17.8757 - val_loss: 52.0123 - val_mse: 52.0123\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 17.9324 - mse: 17.9324 - val_loss: 48.1613 - val_mse: 48.1613\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.2352 - mse: 19.2352 - val_loss: 86.5804 - val_mse: 86.5804\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.8590 - mse: 17.8590 - val_loss: 38.9394 - val_mse: 38.9394\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 21.4069 - mse: 21.4069 - val_loss: 34.3328 - val_mse: 34.3328\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 18.5738 - mse: 18.5738 - val_loss: 43.8593 - val_mse: 43.8593\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 20.4122 - mse: 20.4122 - val_loss: 41.3264 - val_mse: 41.3264\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.8401 - mse: 16.8401 - val_loss: 39.6978 - val_mse: 39.6978\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.6935 - mse: 16.6935 - val_loss: 59.7934 - val_mse: 59.7934\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.6269 - mse: 20.6269 - val_loss: 42.5466 - val_mse: 42.5466\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 20.8370 - mse: 20.8370 - val_loss: 43.3368 - val_mse: 43.3368\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 14.5306 - mse: 14.5306 - val_loss: 37.2495 - val_mse: 37.2495\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 18.1662 - mse: 18.1662 - val_loss: 46.0143 - val_mse: 46.0143\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.4814 - mse: 15.4814 - val_loss: 42.6993 - val_mse: 42.6993\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.2148 - mse: 19.2148 - val_loss: 60.7456 - val_mse: 60.7456\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.7457 - mse: 15.7457 - val_loss: 50.3867 - val_mse: 50.3867\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 20.7046 - mse: 20.7046 - val_loss: 38.7319 - val_mse: 38.7319\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.2622 - mse: 16.2622 - val_loss: 38.4305 - val_mse: 38.4305\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 19.9989 - mse: 19.9989 - val_loss: 45.7649 - val_mse: 45.7649\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.9219 - mse: 13.9219 - val_loss: 62.8151 - val_mse: 62.8151\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.8405 - mse: 14.8405 - val_loss: 47.4886 - val_mse: 47.4886\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.3854 - mse: 19.3854 - val_loss: 39.1483 - val_mse: 39.1483\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 19.1764 - mse: 19.1764 - val_loss: 48.6748 - val_mse: 48.6748\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 15.5668 - mse: 15.5668 - val_loss: 46.8406 - val_mse: 46.8406\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.9416 - mse: 17.9416 - val_loss: 56.7756 - val_mse: 56.7756\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 16.3144 - mse: 16.3144 - val_loss: 58.7549 - val_mse: 58.7549\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.4636 - mse: 15.4636 - val_loss: 38.6811 - val_mse: 38.6811\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.3513 - mse: 16.3513 - val_loss: 43.3037 - val_mse: 43.3037\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 20.0790 - mse: 20.0790 - val_loss: 40.4991 - val_mse: 40.4991\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.1198 - mse: 16.1198 - val_loss: 40.2226 - val_mse: 40.2226\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.2777 - mse: 13.2777 - val_loss: 51.2092 - val_mse: 51.2092\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.3749 - mse: 17.3749 - val_loss: 88.6539 - val_mse: 88.6539\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 19.5614 - mse: 19.5614 - val_loss: 44.3762 - val_mse: 44.3762\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.6900 - mse: 14.6900 - val_loss: 35.6962 - val_mse: 35.6962\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.4248 - mse: 17.4248 - val_loss: 48.9499 - val_mse: 48.9499\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 14.7552 - mse: 14.7552 - val_loss: 42.7781 - val_mse: 42.7781\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 17.9809 - mse: 17.9809 - val_loss: 38.9707 - val_mse: 38.9707\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 18.6292 - mse: 18.6292 - val_loss: 47.4310 - val_mse: 47.4310\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 13.1693 - mse: 13.1693 - val_loss: 38.7944 - val_mse: 38.7944\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 15.4992 - mse: 15.4992 - val_loss: 55.0374 - val_mse: 55.0374\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.0139 - mse: 16.0139 - val_loss: 55.6678 - val_mse: 55.6678\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.1510 - mse: 10.1510 - val_loss: 64.0740 - val_mse: 64.0740\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 22.5966 - mse: 22.5966 - val_loss: 40.9191 - val_mse: 40.9191\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 16.2439 - mse: 16.2439 - val_loss: 46.9778 - val_mse: 46.9778\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 10.0402 - mse: 10.0402 - val_loss: 40.0322 - val_mse: 40.0322\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 19.1892 - mse: 19.1892 - val_loss: 36.9251 - val_mse: 36.9251\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 16.9263 - mse: 16.9263 - val_loss: 50.2635 - val_mse: 50.2635\n",
      "Epoch 156/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.9472 - mse: 13.9472 - val_loss: 36.8553 - val_mse: 36.8553\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 15.6804 - mse: 15.6804 - val_loss: 35.4406 - val_mse: 35.4406\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 16.9980 - mse: 16.9980 - val_loss: 51.8161 - val_mse: 51.8161\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.2501 - mse: 13.2501 - val_loss: 81.7040 - val_mse: 81.7040\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.0543 - mse: 15.0543 - val_loss: 41.9532 - val_mse: 41.9532\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.4513 - mse: 13.4513 - val_loss: 42.4856 - val_mse: 42.4856\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 18.7556 - mse: 18.7556 - val_loss: 39.3926 - val_mse: 39.3926\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.5111 - mse: 13.5111 - val_loss: 42.2699 - val_mse: 42.2699\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.0386 - mse: 14.0386 - val_loss: 40.2592 - val_mse: 40.2592\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 13.2687 - mse: 13.2687 - val_loss: 39.6018 - val_mse: 39.6018\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.0960 - mse: 12.0960 - val_loss: 55.5838 - val_mse: 55.5838\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.3467 - mse: 18.3467 - val_loss: 40.7174 - val_mse: 40.7174\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.0862 - mse: 14.0862 - val_loss: 39.6152 - val_mse: 39.6152\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.0775 - mse: 17.0775 - val_loss: 41.8884 - val_mse: 41.8884\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 14.7898 - mse: 14.7898 - val_loss: 56.7737 - val_mse: 56.7737\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.6942 - mse: 12.6942 - val_loss: 72.1374 - val_mse: 72.1374\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.3108 - mse: 16.3108 - val_loss: 50.4916 - val_mse: 50.4916\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.3697 - mse: 12.3697 - val_loss: 37.6121 - val_mse: 37.6121\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.8654 - mse: 13.8654 - val_loss: 43.9096 - val_mse: 43.9096\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 15.3942 - mse: 15.3942 - val_loss: 40.8812 - val_mse: 40.8812\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.6348 - mse: 14.6348 - val_loss: 43.1802 - val_mse: 43.1802\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 14.5255 - mse: 14.5255 - val_loss: 75.0156 - val_mse: 75.0156\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 14.3867 - mse: 14.3867 - val_loss: 41.9200 - val_mse: 41.9200\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.5400 - mse: 12.5400 - val_loss: 38.6782 - val_mse: 38.6782\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 13.5990 - mse: 13.5990 - val_loss: 44.5079 - val_mse: 44.5079\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.3919 - mse: 12.3919 - val_loss: 36.5841 - val_mse: 36.5841\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 16.2142 - mse: 16.2142 - val_loss: 44.9301 - val_mse: 44.9301\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 15.7599 - mse: 15.7599 - val_loss: 46.3228 - val_mse: 46.3228\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.1358 - mse: 8.1358 - val_loss: 39.4599 - val_mse: 39.4599\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.0910 - mse: 14.0910 - val_loss: 40.8763 - val_mse: 40.8763\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.8728 - mse: 11.8728 - val_loss: 39.6048 - val_mse: 39.6048\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.8464 - mse: 16.8464 - val_loss: 44.2910 - val_mse: 44.2910\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 13.2591 - mse: 13.2591 - val_loss: 43.7042 - val_mse: 43.7042\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.9564 - mse: 10.9564 - val_loss: 41.0766 - val_mse: 41.0766\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.7977 - mse: 16.7977 - val_loss: 48.2879 - val_mse: 48.2879\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 10.6594 - mse: 10.6594 - val_loss: 58.8308 - val_mse: 58.8308\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 13.2300 - mse: 13.2300 - val_loss: 39.8270 - val_mse: 39.8270\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 12.7327 - mse: 12.7327 - val_loss: 56.7294 - val_mse: 56.7294\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.9102 - mse: 11.9102 - val_loss: 37.5913 - val_mse: 37.5913\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 13.0566 - mse: 13.0566 - val_loss: 36.9152 - val_mse: 36.9152\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 12.7876 - mse: 12.7876 - val_loss: 62.4055 - val_mse: 62.4055\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 13.6803 - mse: 13.6803 - val_loss: 67.7817 - val_mse: 67.7817\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 13.1533 - mse: 13.1533 - val_loss: 37.4271 - val_mse: 37.4271\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 12.5674 - mse: 12.5674 - val_loss: 39.2035 - val_mse: 39.2035\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.6941 - mse: 13.6941 - val_loss: 40.5301 - val_mse: 40.5301\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9687 - mse: 11.9687 - val_loss: 36.0446 - val_mse: 36.0446\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.9552 - mse: 10.9552 - val_loss: 53.3856 - val_mse: 53.3856\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 15.4495 - mse: 15.4495 - val_loss: 42.7021 - val_mse: 42.7021\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.0046 - mse: 10.0046 - val_loss: 36.6217 - val_mse: 36.6217\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.5989 - mse: 11.5989 - val_loss: 37.6628 - val_mse: 37.6628\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 15.6014 - mse: 15.6014 - val_loss: 37.4633 - val_mse: 37.4633\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 13.1844 - mse: 13.1844 - val_loss: 39.7997 - val_mse: 39.7997\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.4919 - mse: 12.4919 - val_loss: 33.8486 - val_mse: 33.8486\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.2887 - mse: 12.2887 - val_loss: 44.7129 - val_mse: 44.7129\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 14.4787 - mse: 14.4787 - val_loss: 45.4874 - val_mse: 45.4874\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.9635 - mse: 12.9635 - val_loss: 56.3305 - val_mse: 56.3305\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 12.0563 - mse: 12.0563 - val_loss: 44.7957 - val_mse: 44.7957\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 10.4245 - mse: 10.4245 - val_loss: 49.2475 - val_mse: 49.2475\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 14.5738 - mse: 14.5738 - val_loss: 41.5159 - val_mse: 41.5159\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 8.6786 - mse: 8.6786 - val_loss: 43.5670 - val_mse: 43.5670\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 15.4601 - mse: 15.4601 - val_loss: 45.2628 - val_mse: 45.2628\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.6437 - mse: 9.6437 - val_loss: 86.4323 - val_mse: 86.4323\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 11.8861 - mse: 11.8861 - val_loss: 38.9782 - val_mse: 38.9782\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 15.7072 - mse: 15.7072 - val_loss: 39.7781 - val_mse: 39.7781\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 8.1457 - mse: 8.1457 - val_loss: 47.2830 - val_mse: 47.2830\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 11.0686 - mse: 11.0686 - val_loss: 41.5491 - val_mse: 41.5491\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.7936 - mse: 9.7936 - val_loss: 46.7331 - val_mse: 46.7331\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 14.6565 - mse: 14.6565 - val_loss: 40.5841 - val_mse: 40.5841\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 13.2875 - mse: 13.2875 - val_loss: 37.0436 - val_mse: 37.0436\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.6378 - mse: 8.6378 - val_loss: 36.1865 - val_mse: 36.1865\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.0836 - mse: 11.0836 - val_loss: 37.1905 - val_mse: 37.1905\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.8793 - mse: 11.8793 - val_loss: 40.8088 - val_mse: 40.8088\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12.7588 - mse: 12.7588 - val_loss: 75.4407 - val_mse: 75.4407\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.5471 - mse: 10.5471 - val_loss: 37.2989 - val_mse: 37.2989\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.8595 - mse: 11.8595 - val_loss: 42.9399 - val_mse: 42.9399\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.3686 - mse: 10.3686 - val_loss: 34.4334 - val_mse: 34.4334\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 44ms/step - loss: 12.3845 - mse: 12.3845 - val_loss: 34.7894 - val_mse: 34.7894\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 9.9658 - mse: 9.9658 - val_loss: 58.2117 - val_mse: 58.2117\n",
      "Epoch 234/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.5065 - mse: 10.5065 - val_loss: 45.5957 - val_mse: 45.5957\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.6917 - mse: 9.6917 - val_loss: 58.3425 - val_mse: 58.3425\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 14.1331 - mse: 14.1331 - val_loss: 64.9193 - val_mse: 64.9193\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 12.5334 - mse: 12.5334 - val_loss: 62.2531 - val_mse: 62.2531\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.7192 - mse: 7.7192 - val_loss: 68.9152 - val_mse: 68.9152\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.9358 - mse: 12.9358 - val_loss: 58.4801 - val_mse: 58.4801\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 10.0713 - mse: 10.0713 - val_loss: 37.0248 - val_mse: 37.0248\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.9331 - mse: 11.9331 - val_loss: 44.3276 - val_mse: 44.3276\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 12.0739 - mse: 12.0739 - val_loss: 44.2398 - val_mse: 44.2398\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 5.7670 - mse: 5.7670 - val_loss: 41.0872 - val_mse: 41.0872\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 13.3307 - mse: 13.3307 - val_loss: 41.3741 - val_mse: 41.3741\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.4158 - mse: 10.4158 - val_loss: 57.7379 - val_mse: 57.7379\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.4057 - mse: 9.4057 - val_loss: 40.4189 - val_mse: 40.4189\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.0321 - mse: 11.0321 - val_loss: 73.9434 - val_mse: 73.9434\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 12.4309 - mse: 12.4309 - val_loss: 51.5573 - val_mse: 51.5573\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.4190 - mse: 13.4190 - val_loss: 48.3973 - val_mse: 48.3973\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.8591 - mse: 8.8591 - val_loss: 36.7375 - val_mse: 36.7375\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.6340 - mse: 11.6340 - val_loss: 37.5420 - val_mse: 37.5420\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.3089 - mse: 9.3089 - val_loss: 35.3711 - val_mse: 35.3711\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 10.8017 - mse: 10.8017 - val_loss: 36.2335 - val_mse: 36.2335\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 13.5413 - mse: 13.5413 - val_loss: 37.8148 - val_mse: 37.8148\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.7683 - mse: 9.7683 - val_loss: 38.6524 - val_mse: 38.6524\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 8.6559 - mse: 8.6559 - val_loss: 37.0331 - val_mse: 37.0331\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 13.1976 - mse: 13.1976 - val_loss: 35.3546 - val_mse: 35.3546\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 11.7840 - mse: 11.7840 - val_loss: 37.7620 - val_mse: 37.7620\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.6072 - mse: 10.6072 - val_loss: 35.8584 - val_mse: 35.8584\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 10.9002 - mse: 10.9002 - val_loss: 36.1244 - val_mse: 36.1244\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.0836 - mse: 10.0836 - val_loss: 35.7329 - val_mse: 35.7329\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.9937 - mse: 8.9937 - val_loss: 34.4531 - val_mse: 34.4531\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 14.1148 - mse: 14.1148 - val_loss: 38.2634 - val_mse: 38.2634\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.7167 - mse: 6.7167 - val_loss: 71.8009 - val_mse: 71.8009\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 10.2897 - mse: 10.2897 - val_loss: 36.6581 - val_mse: 36.6581\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 11.8607 - mse: 11.8607 - val_loss: 47.3422 - val_mse: 47.3422\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 11.7527 - mse: 11.7527 - val_loss: 41.7901 - val_mse: 41.7901\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.5546 - mse: 5.5546 - val_loss: 40.8775 - val_mse: 40.8775\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.4251 - mse: 13.4251 - val_loss: 38.0755 - val_mse: 38.0755\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11.1912 - mse: 11.1912 - val_loss: 38.6093 - val_mse: 38.6093\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 7.6948 - mse: 7.6948 - val_loss: 44.8969 - val_mse: 44.8969\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 10.2720 - mse: 10.2720 - val_loss: 33.5721 - val_mse: 33.5721\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.1015 - mse: 11.1015 - val_loss: 43.0625 - val_mse: 43.0625\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 10.8535 - mse: 10.8535 - val_loss: 43.3217 - val_mse: 43.3217\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.7621 - mse: 11.7621 - val_loss: 39.6946 - val_mse: 39.6946\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.3233 - mse: 9.3233 - val_loss: 45.2881 - val_mse: 45.2881\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.5455 - mse: 7.5455 - val_loss: 32.6671 - val_mse: 32.6671\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 13.0273 - mse: 13.0273 - val_loss: 38.6302 - val_mse: 38.6302\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 9.4725 - mse: 9.4725 - val_loss: 36.5716 - val_mse: 36.5716\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 6.3599 - mse: 6.3599 - val_loss: 41.5058 - val_mse: 41.5058\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 12.6531 - mse: 12.6531 - val_loss: 51.5228 - val_mse: 51.5228\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.7385 - mse: 9.7385 - val_loss: 60.8350 - val_mse: 60.8350\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 12.3649 - mse: 12.3649 - val_loss: 45.5637 - val_mse: 45.5637\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 9.1580 - mse: 9.1580 - val_loss: 50.9753 - val_mse: 50.9753\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.7276 - mse: 7.7276 - val_loss: 41.1083 - val_mse: 41.1083\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 12.7466 - mse: 12.7466 - val_loss: 34.7522 - val_mse: 34.7522\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 8.9252 - mse: 8.9252 - val_loss: 34.0687 - val_mse: 34.0687\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 11.6452 - mse: 11.6452 - val_loss: 34.6178 - val_mse: 34.6178\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.9815 - mse: 9.9815 - val_loss: 34.7652 - val_mse: 34.7652\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.0429 - mse: 8.0429 - val_loss: 40.0144 - val_mse: 40.0144\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.0307 - mse: 9.0307 - val_loss: 35.8964 - val_mse: 35.8964\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.2713 - mse: 9.2713 - val_loss: 51.9790 - val_mse: 51.9790\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.7516 - mse: 10.7516 - val_loss: 60.2260 - val_mse: 60.2260\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.2288 - mse: 10.2288 - val_loss: 37.6765 - val_mse: 37.6765\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5288 - mse: 8.5288 - val_loss: 59.2155 - val_mse: 59.2155\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 5.8161 - mse: 5.8161 - val_loss: 51.6121 - val_mse: 51.6121\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 11.8668 - mse: 11.8668 - val_loss: 42.2383 - val_mse: 42.2383\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.3091 - mse: 10.3091 - val_loss: 59.0966 - val_mse: 59.0966\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.4474 - mse: 7.4474 - val_loss: 40.1644 - val_mse: 40.1644\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 12.0089 - mse: 12.0089 - val_loss: 42.7625 - val_mse: 42.7625\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.2358 - mse: 9.2358 - val_loss: 42.1976 - val_mse: 42.1976\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.2498 - mse: 8.2498 - val_loss: 51.9304 - val_mse: 51.9304\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.0675 - mse: 7.0675 - val_loss: 47.6162 - val_mse: 47.6162\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.4619 - mse: 10.4619 - val_loss: 47.5378 - val_mse: 47.5378\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.8521 - mse: 10.8521 - val_loss: 40.2202 - val_mse: 40.2202\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 6.5771 - mse: 6.5771 - val_loss: 68.4054 - val_mse: 68.4054\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.5658 - mse: 7.5658 - val_loss: 81.6499 - val_mse: 81.6499\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.3934 - mse: 7.3934 - val_loss: 38.6899 - val_mse: 38.6899\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.9197 - mse: 9.9197 - val_loss: 36.9986 - val_mse: 36.9986\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 12.0381 - mse: 12.0381 - val_loss: 68.0733 - val_mse: 68.0733\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.8360 - mse: 7.8360 - val_loss: 45.3704 - val_mse: 45.3704\n",
      "Epoch 312/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 8.4564 - mse: 8.4564 - val_loss: 41.0317 - val_mse: 41.0317\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 12.7270 - mse: 12.7270 - val_loss: 37.7379 - val_mse: 37.7379\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 4.8123 - mse: 4.8123 - val_loss: 36.5066 - val_mse: 36.5066\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 10.8718 - mse: 10.8718 - val_loss: 35.5323 - val_mse: 35.5323\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 8.0699 - mse: 8.0699 - val_loss: 40.2170 - val_mse: 40.2170\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.2118 - mse: 9.2118 - val_loss: 35.7391 - val_mse: 35.7391\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.2181 - mse: 10.2181 - val_loss: 37.7906 - val_mse: 37.7906\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.1862 - mse: 9.1862 - val_loss: 50.2503 - val_mse: 50.2503\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.7098 - mse: 8.7098 - val_loss: 39.0723 - val_mse: 39.0723\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.5145 - mse: 7.5145 - val_loss: 39.1325 - val_mse: 39.1325\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.3061 - mse: 10.3061 - val_loss: 36.0760 - val_mse: 36.0760\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 9.9200 - mse: 9.9200 - val_loss: 39.8465 - val_mse: 39.8465\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.3903 - mse: 10.3903 - val_loss: 35.4213 - val_mse: 35.4213\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.7448 - mse: 6.7448 - val_loss: 48.8340 - val_mse: 48.8340\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.9962 - mse: 9.9962 - val_loss: 42.4524 - val_mse: 42.4524\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.8106 - mse: 7.8106 - val_loss: 45.7305 - val_mse: 45.7305\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.2420 - mse: 7.2420 - val_loss: 57.8731 - val_mse: 57.8731\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.2076 - mse: 9.2076 - val_loss: 37.9564 - val_mse: 37.9564\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.0786 - mse: 9.0786 - val_loss: 41.0540 - val_mse: 41.0540\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.3849 - mse: 7.3849 - val_loss: 33.9187 - val_mse: 33.9187\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 10.6458 - mse: 10.6458 - val_loss: 40.7342 - val_mse: 40.7342\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.8190 - mse: 9.8190 - val_loss: 53.4838 - val_mse: 53.4838\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.8662 - mse: 4.8662 - val_loss: 38.6537 - val_mse: 38.6537\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.1166 - mse: 8.1166 - val_loss: 36.1329 - val_mse: 36.1329\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.2042 - mse: 9.2042 - val_loss: 41.1120 - val_mse: 41.1120\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.4319 - mse: 10.4319 - val_loss: 36.9176 - val_mse: 36.9176\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 7.3047 - mse: 7.3047 - val_loss: 68.5619 - val_mse: 68.5619\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.6012 - mse: 8.6012 - val_loss: 57.5427 - val_mse: 57.5427\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.5999 - mse: 11.5999 - val_loss: 58.2019 - val_mse: 58.2019\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 6.5147 - mse: 6.5147 - val_loss: 58.9186 - val_mse: 58.9186\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 7.7887 - mse: 7.7887 - val_loss: 41.3489 - val_mse: 41.3489\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 9.7778 - mse: 9.7778 - val_loss: 35.9454 - val_mse: 35.9454\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.9054 - mse: 10.9054 - val_loss: 35.1405 - val_mse: 35.1405\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 6.3319 - mse: 6.3319 - val_loss: 50.8799 - val_mse: 50.8799\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.0607 - mse: 8.0607 - val_loss: 39.7211 - val_mse: 39.7211\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.6085 - mse: 7.6085 - val_loss: 35.1762 - val_mse: 35.1762\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 7.5653 - mse: 7.5653 - val_loss: 44.8399 - val_mse: 44.8399\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 10.6945 - mse: 10.6945 - val_loss: 38.8239 - val_mse: 38.8239\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 7.5515 - mse: 7.5515 - val_loss: 51.6347 - val_mse: 51.6347\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.2561 - mse: 9.2561 - val_loss: 36.4377 - val_mse: 36.4377\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.1032 - mse: 7.1032 - val_loss: 41.4215 - val_mse: 41.4215\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 10.1080 - mse: 10.1080 - val_loss: 41.6748 - val_mse: 41.6748\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 4.0709 - mse: 4.0709 - val_loss: 51.8986 - val_mse: 51.8986\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 10.2317 - mse: 10.2317 - val_loss: 34.7553 - val_mse: 34.7553\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.4263 - mse: 9.4263 - val_loss: 39.5998 - val_mse: 39.5998\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.2780 - mse: 7.2780 - val_loss: 34.3640 - val_mse: 34.3640\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 9.3782 - mse: 9.3782 - val_loss: 35.5363 - val_mse: 35.5363\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.3888 - mse: 9.3888 - val_loss: 40.3203 - val_mse: 40.3203\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.4007 - mse: 8.4007 - val_loss: 37.2215 - val_mse: 37.2215\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 6.8280 - mse: 6.8280 - val_loss: 35.4952 - val_mse: 35.4952\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 8.7165 - mse: 8.7165 - val_loss: 34.0943 - val_mse: 34.0943\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.9082 - mse: 7.9082 - val_loss: 38.3183 - val_mse: 38.3183\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.6540 - mse: 8.6540 - val_loss: 36.9431 - val_mse: 36.9431\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.5494 - mse: 7.5494 - val_loss: 37.9805 - val_mse: 37.9805\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 9.8814 - mse: 9.8814 - val_loss: 59.3626 - val_mse: 59.3626\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.8389 - mse: 5.8389 - val_loss: 38.4655 - val_mse: 38.4655\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 9.4888 - mse: 9.4888 - val_loss: 43.3673 - val_mse: 43.3673\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.0022 - mse: 7.0022 - val_loss: 34.7382 - val_mse: 34.7382\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 7.8971 - mse: 7.8971 - val_loss: 66.9953 - val_mse: 66.9953\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 7.1709 - mse: 7.1709 - val_loss: 70.5909 - val_mse: 70.5909\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 9.3253 - mse: 9.3253 - val_loss: 34.9503 - val_mse: 34.9503\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 8.6176 - mse: 8.6176 - val_loss: 37.6605 - val_mse: 37.6605\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 8.2030 - mse: 8.2030 - val_loss: 52.0667 - val_mse: 52.0667\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 4.0158 - mse: 4.0158 - val_loss: 40.4016 - val_mse: 40.4016\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 9.4231 - mse: 9.4231 - val_loss: 39.6607 - val_mse: 39.6607\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.4409 - mse: 7.4409 - val_loss: 44.8820 - val_mse: 44.8820\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.3944 - mse: 8.3944 - val_loss: 43.3237 - val_mse: 43.3237\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.5565 - mse: 5.5565 - val_loss: 63.3290 - val_mse: 63.3290\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.6916 - mse: 9.6916 - val_loss: 39.3380 - val_mse: 39.3380\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 9.1990 - mse: 9.1990 - val_loss: 38.3613 - val_mse: 38.3613\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 5.5180 - mse: 5.5180 - val_loss: 38.5380 - val_mse: 38.5380\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 7.9204 - mse: 7.9204 - val_loss: 36.8745 - val_mse: 36.8745\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 5.9416 - mse: 5.9416 - val_loss: 44.8178 - val_mse: 44.8178\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.8889 - mse: 9.8889 - val_loss: 56.3262 - val_mse: 56.3262\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.8786 - mse: 6.8786 - val_loss: 42.7357 - val_mse: 42.7357\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.8682 - mse: 6.8682 - val_loss: 35.4547 - val_mse: 35.4547\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.9072 - mse: 8.9072 - val_loss: 36.7013 - val_mse: 36.7013\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 8.8451 - mse: 8.8451 - val_loss: 36.9676 - val_mse: 36.9676\n",
      "Epoch 390/400\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.3141 - mse: 6.3141 - val_loss: 56.9236 - val_mse: 56.9236\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.5179 - mse: 7.5179 - val_loss: 36.4142 - val_mse: 36.4142\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5015 - mse: 8.5015 - val_loss: 37.7858 - val_mse: 37.7858\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.5992 - mse: 6.5992 - val_loss: 40.5037 - val_mse: 40.5037\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 7.1490 - mse: 7.1490 - val_loss: 35.9062 - val_mse: 35.9062\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 8.5460 - mse: 8.5460 - val_loss: 35.8300 - val_mse: 35.8300\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 5.8861 - mse: 5.8861 - val_loss: 38.5275 - val_mse: 38.5275\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 9.3450 - mse: 9.3450 - val_loss: 39.2599 - val_mse: 39.2599\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 9.1271 - mse: 9.1271 - val_loss: 37.4801 - val_mse: 37.4801\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.6892 - mse: 6.6892 - val_loss: 38.2825 - val_mse: 38.2825\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.2286 - mse: 6.2286 - val_loss: 39.3574 - val_mse: 39.3574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.65964279174805"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only scaling training data\n",
    "\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits=n_splits,\n",
    "              shuffle=True,\n",
    "              random_state=411)\n",
    "scale = StandardScaler(copy=True)\n",
    "\n",
    "X_train, y_train = scale.fit_transform(concrete_train[features]), concrete_train['strength']\n",
    "\n",
    "n_epochs = 400\n",
    "mses = np.zeros(n_splits)\n",
    "best_epochs = np.zeros(n_splits)\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(concrete_train):\n",
    "\n",
    "\n",
    "\n",
    "    X_tt, y_tt = X_train[train_index], y_train.iloc[train_index]\n",
    "    X_ho, y_ho = X_train[test_index], y_train.iloc[test_index]\n",
    "\n",
    "    model1 = Sequential()\n",
    "    model1.add(layers.Dense(150, activation='relu', input_shape=(X_tt.shape[1],)))\n",
    "    model1.add(layers.Dense(100, activation='relu'))\n",
    "    model1.add(layers.Dense(100, activation='relu'))\n",
    "    model1.add(layers.Dense(100, activation='relu'))\n",
    "    model1.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "    model1.compile(optimizer = 'rmsprop',\n",
    "                    loss = 'mean_squared_error',\n",
    "                    metrics = ['mse'])\n",
    "    history1 = model1.fit(X_tt,\n",
    "                        y_tt,\n",
    "                        epochs = n_epochs,\n",
    "                        batch_size = 50,\n",
    "                        # verbose=0,\n",
    "                        validation_data = (X_ho, \n",
    "                                            y_ho))\n",
    "\n",
    "    mses[i] = np.min(history1.history['val_mse'])\n",
    "    best_epochs[i] = np.argmin(history1.history['val_mse'])\n",
    "\n",
    "\n",
    "    i +=1\n",
    "\n",
    "np.mean(mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cement',\n",
       " 'ash',\n",
       " 'slag',\n",
       " 'water',\n",
       " 'superplastic',\n",
       " 'coarseagg',\n",
       " 'fineagg',\n",
       " 'exp_age']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([310.24919739,  27.11318283,  25.07059288, 317.39542046,\n",
       "        26.73327141,  26.21896706])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_range = np.arange(50, 310, 50)\n",
    "n_splits = 5\n",
    "\n",
    "kfold = KFold(n_splits=n_splits,\n",
    "              shuffle=True,\n",
    "              random_state=409)\n",
    "scale = StandardScaler(copy=True)\n",
    "\n",
    "n_epochs = 400\n",
    "keras_mses = np.zeros((n_splits, len(n_range)))\n",
    "best_epochs = np.zeros((n_splits, len(n_range)))\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(concrete_train):\n",
    "\n",
    "    concrete_tt, concrete_ho = concrete_train.iloc[train_index], concrete_train.iloc[test_index]\n",
    "\n",
    "    X_tt, y_tt = scale.fit_transform(concrete_tt[features]), concrete_tt['strength']\n",
    "    X_ho, y_ho = scale.fit_transform(concrete_ho[features]), concrete_ho['strength']\n",
    "    j = 0\n",
    "    for n in n_range:\n",
    "        print(j)\n",
    "        model1 = Sequential()\n",
    "        model1.add(layers.Dense(n, activation='relu', input_shape=(X_tt.shape[1],)))\n",
    "        model1.add(layers.Dense(n, activation='relu'))\n",
    "        model1.add(layers.Dense(n, activation='relu'))\n",
    "        model1.add(layers.Dense(n, activation='relu'))\n",
    "        model1.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "        model1.compile(optimizer = 'rmsprop',\n",
    "                        loss = 'mean_squared_error',\n",
    "                        metrics = ['mse'])\n",
    "        history1 = model1.fit(X_tt,\n",
    "                            y_tt,\n",
    "                            epochs = n_epochs,\n",
    "                            batch_size = 50,\n",
    "                            verbose=0,\n",
    "                            validation_data = (X_ho, \n",
    "                                                y_ho))\n",
    "\n",
    "        keras_mses[i, j] = np.min(history1.history['val_mse'])\n",
    "        best_epochs[i, j] = np.argmin(history1.history['val_mse'])\n",
    "        j += 1\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "np.mean(keras_mses, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([384., 349., 261., 348., 396.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.23081779, 18.6203022 , 29.45568848, 26.09188843, 29.358675  ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
